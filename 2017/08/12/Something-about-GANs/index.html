<!DOCTYPE html><html class="theme-next pisces use-motion" lang="en"><head><!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta name="theme-color" content="#222"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta name="google-site-verification" content="BGEL63KNRW25AkpCy3shpRdMWDHE9LZTAFS3XSHtFK8"><link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css"><link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css"><link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css"><link href="/css/main.css?v=5.1.2" rel="stylesheet" type="text/css"><meta name="keywords" content="Deep Learning,Generative Adversarial Networks,GANs,DCGAN,WGAN,WGAN-GP,"><link rel="alternate" href="/atom.xml" title="Yuthon's blog" type="application/atom+xml"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.2"><meta name="description" content="最近在看关于GANs的论文，并且自己动手用PyTorch写了一些经典文章的实现，想要稍微总结一下，故有此文。在最后我总结了我自己看过的有关GANs的一些比较好的资源，希望对读者有所帮助。 （待填坑……）"><meta name="keywords" content="Deep Learning,Generative Adversarial Networks,GANs,DCGAN,WGAN,WGAN-GP"><meta property="og:type" content="article"><meta property="og:title" content="Something about GAN"><meta property="og:url" content="http://www.yuthon.com/2017/08/12/Something-about-GANs/index.html"><meta property="og:site_name" content="Yuthon&#39;s blog"><meta property="og:description" content="最近在看关于GANs的论文，并且自己动手用PyTorch写了一些经典文章的实现，想要稍微总结一下，故有此文。在最后我总结了我自己看过的有关GANs的一些比较好的资源，希望对读者有所帮助。 （待填坑……）"><meta property="og:locale" content="en"><meta property="og:image" content="http://www.yuthon.com/images/taxonomy_for_generative_models.png"><meta property="og:image" content="http://www.yuthon.com/images/the-GAN-framework.png"><meta property="og:image" content="http://www.yuthon.com/images/cost_functions_of_GANs.png"><meta property="og:image" content="http://www.yuthon.com/images/GAN_real_images.png"><meta property="og:image" content="http://www.yuthon.com/images/GAN_fake_images-300.png"><meta property="og:image" content="http://www.yuthon.com/images/DCGAN-fake-20-700.png"><meta property="og:image" content="http://www.yuthon.com/images/DCGAN-fake-24-300.png"><meta property="og:updated_time" content="2017-08-13T13:23:28.000Z"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="Something about GAN"><meta name="twitter:description" content="最近在看关于GANs的论文，并且自己动手用PyTorch写了一些经典文章的实现，想要稍微总结一下，故有此文。在最后我总结了我自己看过的有关GANs的一些比较好的资源，希望对读者有所帮助。 （待填坑……）"><meta name="twitter:image" content="http://www.yuthon.com/images/taxonomy_for_generative_models.png"><script type="text/javascript" id="hexo.configurations">var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    sidebar: {"position":"left","display":"hide","offset":12,"offset_float":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };</script><link rel="canonical" href="http://www.yuthon.com/2017/08/12/Something-about-GANs/"><title>Something about GAN | Yuthon's blog</title><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
            (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-76233259-1', 'auto');
  ga('send', 'pageview');</script><!-- hexo-inject:begin --><!-- hexo-inject:end --></head><body itemscope itemtype="http://schema.org/WebPage" lang="en"><!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail"><div class="headband"></div><header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-wrapper"><div class="site-meta"><div class="custom-logo-site-title"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span> <span class="site-title">Yuthon's blog</span> <span class="logo-line-after"><i></i></span></a></div><p class="site-subtitle"></p></div><div class="site-nav-toggle"><button><span class="btn-bar"></span> <span class="btn-bar"></span> <span class="btn-bar"></span></button></div></div><nav class="site-nav"><ul id="menu" class="menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i><br>Home</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i><br>Archives</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i><br>Tags</a></li><li class="menu-item menu-item-search"><a href="javascript:;" class="popup-trigger"><i class="menu-item-icon fa fa-search fa-fw"></i><br>Search</a></li></ul><div class="site-search"><div class="popup search-popup local-search-popup"><div class="local-search-header clearfix"><span class="search-icon"><i class="fa fa-search"></i> </span><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span><div class="local-search-input-wrapper"><input autocomplete="off" placeholder="Searching..." spellcheck="false" type="text" id="local-search-input"></div></div><div id="local-search-result"></div></div></div></nav></div></header><main id="main" class="main"><div class="main-inner"><div class="content-wrap"><div id="content" class="content"><div id="posts" class="posts-expand"><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><div class="post-block"><link itemprop="mainEntityOfPage" href="http://www.yuthon.com/2017/08/12/Something-about-GANs/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="Yusu Pan"><meta itemprop="description" content=""><meta itemprop="image" content="/uploads/avatar.png"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Yuthon's blog"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">Something about GAN</h1><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">Posted on</span> <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-08-12T19:24:14+08:00">2017-08-12 </time><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-calendar-check-o"></i> </span><span class="post-meta-item-text">Post modified</span> <time title="Post modified" itemprop="dateModified" datetime="2017-08-13T21:23:28+08:00">2017-08-13 </time></span><span class="post-category"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-folder-o"></i> </span><span class="post-meta-item-text">In</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Thesis-Notes/" itemprop="url" rel="index"><span itemprop="name">Thesis Notes</span> </a></span></span><span class="post-comments-count"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-comment-o"></i> </span><a href="/2017/08/12/Something-about-GANs/#comments" itemprop="discussionUrl"><span class="post-comments-count disqus-comment-count" data-disqus-identifier="2017/08/12/Something-about-GANs/" itemprop="commentCount"></span></a></span></div></header><div class="post-body" itemprop="articleBody"><p>最近在看关于GANs的论文，并且自己动手用PyTorch写了一些经典文章的实现，想要稍微总结一下，故有此文。在最后我总结了我自己看过的有关GANs的一些比较好的资源，希望对读者有所帮助。</p><p>（待填坑……）</p><a id="more"></a><h2 id="Before-Reading-PyTorch"><a href="#Before-Reading-PyTorch" class="headerlink" title="Before Reading: PyTorch"></a>Before Reading: PyTorch</h2><p>在讲GANs之前，首先推一波PyTorch。就我的使用体验来说，PyTorch是远远超过TensorFlow的。PyTorch作为一个动态图计算的框架，与Python结合得非常好，写出来的代码非常<em>Pythonic</em>（反例就是TF的<code>tf.while_loop</code>）。同时PyTorch与NumPy结合得非常好，不用在<code>Tensor</code>与<code>ndarray</code>之间转换来转换去。</p><p>总而言之，PyTorch非常适合我这样需要快速开发与快速验证，并且对于运行速度要求并不高的DL研究（讲真，TF的速度也不怎么快，还是吃内存大户）。</p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p><strong>GANs（Generative Adversarial Networks，生成对抗网络）是Generative Models（生成模型）的一种。</strong>所谓生成模型，就是能在一个含有真实数据分布$p_{data}$样本（samples）的训练集上，学习到真实数据分布的估计的表示$p_{model}$的模型。学习到的这个表示可以是显式的（explicit），比如说直接就给出了$p_{model}$；也可以是隐式的（implicit），比如说能够生成符合$p_{model}$分布的样本。<strong>一般来说，GANs属于第二种，能够进行样本生成。</strong>不过在设计上，GANs其实是两者皆可的。</p><p><strong>那为什么要搞这个生成模型呢？</strong>原因也是有很多的。比如说，训练生成样本是一个用来测试我们表示高维概率分布的能力的好方法，而现实世界的物体往往是具有高维概率分布的，这就对我们用DL来表示与解释现实世界有帮助。同时，很多DL相关的任务也是很需要样本生成的，比如说超分辨率（super resolution）、风格迁移（style transfer）之类的。此外，生成模型对于某些标签甚至是数据缺失的数据集也很有用，比如说可以用在半监督学习（semi-supervised learning）上，不过我倒是没见到过相关的论文。总之，生成模型是很有用的，也是目前DL领域的一大热门方向。</p><p>那么问题又来了，<strong>还有哪些生成模型，GANs相比于其他的生成模型有什么优势</strong>，特别是在去年和它几乎同时火起来的VAE？首先谈谈生成模型的分类。说起这个，就不得不谈<strong>极大似然估计（maximum likelihood estimation）</strong>，几乎所有的生成模型都使用了或者可以转换为使用极大似然来进行估计。极大似然估计的基本思想是，定义一个含有参数$\theta$的模型，用它来提供对于一个概率分布的估计，然后寻找一组最优的参数$\theta$来使得模型的概率分布$p_{model}$最贴合实际数据的概率分布$p_{data}$。具体地说，对于一个具有$m$个样本$x^{(i)}$的数据集来说，可以用似然（likelihood）来表示模型与数据集中数据的契合概率$\prod^m_{i=1} p_{model} (x^{(i)};\theta)$，而我们的最终目的就是找到使得似然最大的参数$\theta$。由于对数函数的优良性质，我们可以将似然取对数。<br>$$<br>\begin{align}<br>\theta ^* &amp;= \underset{\theta}{\operatorname{argmax}} \prod ^m _{i=1} p_{model} (x^{(i)};\theta) \\<br>&amp;= \underset{\theta}{\operatorname{argmax}} \log \prod ^m _{i=1} p_{model} (x^{(i)};\theta) \\<br>&amp;= \underset{\theta}{\operatorname{argmax}} \sum ^m _{i=1} \log p_{model} (x^{(i)};\theta) \\<br>\end{align}<br>$$</p><p>另外一方面，我们也可以将极大似然估计看成是一种最小化真实概率分布与模型概率分布之间的<strong>KL散度（Kullback–Leibler divergence）</strong>的方法。虽然我们通常在实践中并不能直接接触到$p_{data}$，而是只能够获得服从其分布的$m$个采样。我们可以用这些采样组成的数据集来定义$\hat{p} _{data}$这么一个经验分布（empirical distribution）来近似$p_{data}$。可以证明，最小化$\hat{p} _{data}$与$p _{model}$之间的KL散度，等价于在数据集上最大化对数似然。<br>$$<br>\theta ^*= \underset{\theta}{\operatorname{argmin}} D_{KL} (p_{data} (x) \parallel p_{model} (x;\theta))<br>$$</p><p>好了，说了这么多，让我们再把话题转向生成模型的分类。生成模型可以根据其计算似然及其梯度，或者近似估计这些值的方法来进行分类。其中值得注意的有FBVNs、VAE以及GANs。GANs属于右边的那一类，能够隐式地得到概率密度，并直接从中生成样本。</p><p><img src="/images/taxonomy_for_generative_models.png" alt="taxonomy_for_generative_models"></p><p>GANs相对于其他的生成模型，其优点主要在于：</p><ul><li>GANs能够并行地生成样本，而非FBVNs那样只能串行；</li><li>GANs在设计上的约束很少，不像玻尔兹曼机（Boltzmann Machine）那样只能用少数几种概率分布，也不像非线性ICA那样，要求生成器必须可逆并且隐式编码（latent code）$z$必须与数据集中的样本$x$具有相同的维度；</li><li>GANs不需要马尔科夫链（Markov chains），这点不同于玻尔兹曼机以及GSNs；</li><li>GANs不需要使用微分边界（variational bound），并且GANs里面用到的模型早已被证明是万能逼近器（universial approximators），因此GANs能够保证渐进一致（asymptotically consistent）。相比而言，某些VAEs虽然推测是渐进一致的，但是没有得到证明；</li><li>最后一点，GANs就目前的效果来说，其生成出来的样本的质量比用其他生成模型得到的要好。</li></ul><p>当然，原始的GANs有一点是非常让人头疼的，就是它的训练过程本质上是寻找一场比赛的纳什均衡（Nash equilibrium）的过程，这导致GANs很难稳定的训练。当然，之后要提到的WGAN在一定程度上解决了这问题。</p><h2 id="How-do-GANs-Work"><a href="#How-do-GANs-Work" class="headerlink" title="How do GANs Work?"></a>How do GANs Work?</h2><h3 id="The-GAN-framework"><a href="#The-GAN-framework" class="headerlink" title="The GAN framework"></a>The GAN framework</h3><p>GANs由两个部分组成：一个是<strong>生成器（generator）</strong>，负责生成样本，并且尽力与原始数据集中的分布一致；另一个是<strong>判别器（discriminator）</strong>，负责检验输入的样本是来自真实数据分布还是生成器生成的。这两者都可以表现为可微的函数（其实最后就是表现为神经网络），生成器是以$z$为输入，$\theta^{(G)}$为参数的函数$G$，而判别器是以$x$为输入，$\theta^{(D)}$为参数的函数$D$。生成器的目的是在只能控制$\theta^{(G)}$的情况下，最小化$J^{(G)} (\theta ^{(D)}, \theta ^{(G)})$；而判别器则是在只能改变$\theta^{(D)}$的情况下，最小化$J^{(D)} (\theta ^{(D)}, \theta ^{(G)})$。通俗地说就是，生成器想要生成出的样本能够让判别器区分不出这是来自真实数据还是生成的（$D(G(z))=1$），而判别器则是想要尽可能地将这些区分开来（$D(G(z))=0$）。这么一来，这场比赛的<strong>解就是一个纳什均衡</strong>。也就是说，这个解$(\theta ^{(D)}, \theta ^{(G)})$不但能在$J^{(G)}$上取到局部最小值（local minimum），而且在$J^{(D)}$上也取到局部最小值。如果两者均具有足够的容量（capacity），则$\forall x, D(x)=D(G(z))=\frac{1}{2}$。</p><p><img src="/images/the-GAN-framework.png" alt="the-GAN-framework"></p><p>生成器就是一个简单的可微分的函数$G$，一般来说我们用DNN来表示。生成器接受一个来自先验分布（比如说高斯分布）的采样$z$，然后对其进行处理，得到一个来自$p_{model}$分布的采样$G(z)$。值得注意的是，我们并不一定要把$z$作为DNN第一层的输入。比如说我们可以把$z$一刀切成两部分，$z^{(1)}$和$z^{(2)}$，$z^{(1)}$作为DNN首层的输入，而$z^{(2)}$则加在DNN末层的输出上。还有一种操作是，我们可以在DNN的隐藏层上搞加性噪声（additive noise）或者乘性噪声（multiplicative noise），或者直接在隐藏层输出上串（concatenate）一个噪声。总而言之，生成器网络在设计上的约束是很少的，可以任意开脑洞，只要<strong>保证$z$的维度不低于$x$，并且整个网络是可微的</strong>就可以了。</p><p>判别器就是一个简单的二分类的DNN，在此就不赘述了。</p><h3 id="Cost-function"><a href="#Cost-function" class="headerlink" title="Cost function"></a>Cost function</h3><p><strong>判别器的代价函数就是简单的交叉熵（cross-entropy cost）</strong>，如下所示。唯一的区别是，判别器的一次训练由两个mini-batches组成，一部分是来自于数据集的真实样本，标签为1；另一部分是来自生成器所生成的样本，标签为0。一般来说，所有的GANs的判别器都是用下述公式作为代价函数的。<br>$$<br>J^{(D)} (\theta ^{(D)}, \theta ^{(G)}) = -\frac{1}{2} \mathbb{E}_{x\sim p_{data}} \log D(x) - \frac{1}{2} \mathbb{E}_{z} \log (1-D(G(z)))<br>$$<br>生成器的代价函数的可选择范围就稍微多了一些，主要有minimax、heuristic以及maximum likelihood三种，其中前两种比较常见。</p><ul><li><p><strong>Minimax</strong>：其实就是零和游戏（zero-sum game），生成器的代价函数等于判别器代价函数的负值。可以证明，这等价于最小化数据与模型之间的JS散度（Jenson-Shannon divergence）。但是这个代价函数其实是存在着隐患的。一般来说，判别器训练的收敛速度比生成器快得多，因此判别器很快就能以较高的置信度将生成器生成的假样本给拒绝掉，从而造成生成器的梯度消失的问题。这一缺陷可以用下面的方法来解决。<br>$$<br>J^{(G)} = -J^{(D)} \\<br>V (\theta ^{(D)}, \theta ^{(G)}) = J^{(D)} (\theta ^{(D)}, \theta ^{(G)}) \\<br>\theta ^{(G)*} = \underset{\theta ^{(G)}}{\operatorname{argmin}} \underset{\theta ^{(D)}}{\operatorname{max}} V (\theta ^{(D)}, \theta ^{(G)})<br>$$</p></li><li><p><strong>Heuristic, non-saturating game</strong>：我们可以换种方式来思考问题：在minimax game中，我们是让生成器最小化判别器判对的对数概率，这会导致一些问题；那么可不可以让生成器来最大化判别器判错的对数概率呢？显然也是可以的，并且这也能避免生成器梯度消失的问题。这是一种启发式的方法，其动机是为了让玩家（也就是生成器）在“输掉”游戏的时候能得到比较强的梯度。<br>$$<br>J^{(G)} = - \frac{1}{2} \mathbb{E}_{z} \log (D(G(z)))<br>$$</p></li></ul><p>从下图可以看出，heuristicly designed non-saturating cost在$D(G(z))$变化的时候，其方差较小，因此是比较合适作为生成器代价函数的选择的。</p><p><img src="/images/cost_functions_of_GANs.png" alt="cost_functions_of_GANs"></p><h2 id="DCGAN"><a href="#DCGAN" class="headerlink" title="DCGAN"></a>DCGAN</h2><p>DCGAN即使用了全卷积网络的GANs，一般特指<a href="https://arxiv.org/abs/1511.06434" target="_blank" rel="external">这篇paper</a>中的网络结构。目前几乎所有的GANs都或多或少地借鉴了DCGAN的架构。DCGAN的主要创新点在于：</p><ul><li><strong>同时在判别器与生成器网络中使用了Batch Normalization层。</strong>当然，为了能够学到真实数据分布正确的均值（mean）与规模（scale），判别器的首层与生成器的末层没有加BN层。</li><li><strong>整个网络架构借鉴了the all-convolutional net</strong>（不是FCN），不含pooling和“unpooling”层，增加表示维度是靠<code>stride=1</code>的转置卷积（transposed convolition）实现的。</li></ul><p>总而言之，就是换了原始的GAN中的网络架构，把FC层都换成了带BN层的卷积层。</p><h2 id="WGAN-amp-WGAN-GP"><a href="#WGAN-amp-WGAN-GP" class="headerlink" title="WGAN &amp; WGAN-GP"></a>WGAN &amp; WGAN-GP</h2><h3 id="What-does-it-mean-to-learn-a-probability-distribution"><a href="#What-does-it-mean-to-learn-a-probability-distribution" class="headerlink" title="What does it mean to learn a probability distribution?"></a>What does it mean to learn a probability distribution?</h3><p>WGAN在<a href="https://arxiv.org/abs/1701.07875" target="_blank" rel="external">paper</a>开头就直截了当地提出了一个问题，<strong>我们怎么样才算是学到了一个概率分布呢？</strong>如果按照本文开头的说法，我们的做法是先定义一个参数化的概率密度族$(P_\theta )_{\theta \in \mathbb{R}}$，然后通过在已有的数据集${x^{(i)}} ^m_{i=1}$上最大化似然的方法来找到一个最佳的参数，并将这个参数对应的那个概率密度$P_{\theta}$视为我们所学习到的模型。<br>$$<br>\underset{\theta \in \mathbb{R}}{\max} \frac{1}{m} \sum ^m_{i=1} \log P_{\theta} (x^{(i)})<br>$$<br>如果真实的数据分布$\mathbb{P}_r$存在密度，而我们学习到的概率密度$P_{\theta}$所对应的概率分布为$\mathbb{P}_{\theta}$，则<strong>上述学习过程实际上等价于最小化$\mathbb{P}_r$与$\mathbb{P}_{\theta}$之间的KL散度$KL(\mathbb{P}_r \parallel \mathbb{P}_{\theta})$。</strong>这也是上文提到过的。</p><p>是不是看起来有理有据令人信服？但是，这上面的推理过程有一个很重要很显而易见但是又常常为人所忽视的条件，那就是<strong>首先$\mathbb{P}_r$与$\mathbb{P}_{\theta}$之间的KL散度必须存在，然后我们才能去最小化这个KL散度，来获取最优$\theta$</strong>。你TM在逗我，KL散度还能不存在？事实上，这是很常见的。比如说我们用GANs生成样本的时候，输入的随机噪声通常就是一个64维的向量，然后经过生成器网络来生成一个$64<em>64=4096$维的图片，其本质还是决定于开始的那个64维的随即向量。64维相对于4096维来说实在是微不足道，<em>*也就是说，生成样本分布的支撑集（support）构成了高维空间上的低维流形（manifold），撑不满整个高维空间。那么该模型的流形与真实分布的支撑集之间很有可能就没有不可忽视的交集（non-negligible intersection），以致两者间的KL散度不存在，或者说是$\infty$。</em></em></p><p>KL散度都不存在了，那还优化个毛？不过这难不倒千千万万机智的研究者。<strong>你不是要让这两个概率分布有交集吗，那我就往$\mathbb{P}_{\theta}$上加噪声，加个大点的噪声总是能让这两个分布碰在一起的，那KL散度不是就有了？</strong>这也是几乎所有的生成模型都包含了噪声项的原因。一般来说，在训练开始的时候加的噪声要大一点，让含有噪声的两个分布能够够得着。随着训练过程的深入，两个分布的主体开始慢慢靠近，这时候噪声就需要慢慢减小了。最后两个分布开始真正有了不可忽视的交集，那么此时加不加噪声也没什么关系了。</p><p>不过这种方法也是存在着一些问题的，加噪声很可能使得生成出来的样本比较模糊（blurry）。如果加的是<code>mean=0.1</code>的高斯噪声，而像素值本身又已经归一化到了$[0,1]$，那么很显然，这个噪声相对于像素值来说太大了。于是机智的研究者在论文里展示生成的样本的时候，不像他们在训练过程中干的那样，是不怎么加噪声的。换句话说，加噪声虽然在一定程度上保证了KL散度的存在，也就是使得极大似然方法能够奏效，但是这对于问题本质上来说并没有改善，并非解决问题的正确方法（走上了邪路^_^）。</p><p>与其显式地估计有可能并不存在的$\mathbb{P}_r$的密度，不如<strong>直接将来自先验分布$p(z)$的随机变量$\mathcal{Z}$通过参数化的映射$g_\theta : \mathcal{Z} \to \mathcal{X}$来生成样本$\mathcal{X}$，只要这个映射出来的样本$\mathcal{X}$的分布服从或者接近$\mathbb{P}_r$</strong>，那不就是学到了真实的概率分布？VAEs和GANs就是这么做的。这么做有两个好处，首先其与直接估计密度的方法不同，能够表示被约束在低维流形的概率分布；同时直接生成样本有时候比得到一个干巴巴的概率密度更加有用。</p><p>那么问题又转移到了，<strong>如何衡量生成样本分布$\mathbb{P}_{\theta}$与真实样本分布$\mathbb{P}_r$之间的相似性或者说距离$\rho(\mathbb{P}_{\theta}, \mathbb{P}_r)$？</strong>这个距离度量需要有比较好的性质，不能两个分布没有交集就直接歇菜了（说的就是KL散度你这个大坑货）。WGAN论文之后的部分就在讲如何定义一个好的距离度量，并将其应用在GANs中。</p><p>各个距离度量的一个基本的差异在于它们对于成序列的概率分布的收敛性的影响。一个概率分布的序列$(\mathbb{P}_t)_{t\in\mathbb{R}}$能够收敛，当且仅当存在一个$\mathbb{P}_\infty$使得$\rho(\mathbb{P}_{\theta}, \mathbb{P}_r)$趋向于零，也就是说取决于$\rho$的定义。一般来说，如果$\rho$在拓扑（topology）上越弱，则序列越容易收敛。</p><p>为了优化生成模型的参数$\theta$，我们希望定义的模型能够使得映射$\theta \mapsto \mathbb{P_\theta}$连续。这里的连续指的是当一连串的参数$\theta_t$收敛于一个值$\theta$，概率$\mathbb{P}_{\theta_t}$也能收敛于$\mathbb{P}_\theta$。不过这种连续性取决于我们选择的距离度量。距离度量越弱，概率分布越容易瘦脸，则越容易定义一个从$\theta$空间到$\mathbb{P}_\theta$空间的连续的映射。我们这里关注映射$\theta \mapsto \mathbb{P_\theta}$连续性的原因是，<strong>我们希望$\theta \mapsto \rho(\mathbb{P}_{\theta}, \mathbb{P}_r)$的损失函数是连续的（方便梯度下降训练），而这等价于在使用距离度量$\rho$的情况下映射$\theta \mapsto \mathbb{P_\theta}$连续。</strong></p><h3 id="Different-Disrances"><a href="#Different-Disrances" class="headerlink" title="Different Disrances"></a>Different Disrances</h3><p>（待填坑……）</p><h2 id="GANs-in-Practice"><a href="#GANs-in-Practice" class="headerlink" title="GANs in Practice"></a>GANs in Practice</h2><h3 id="MLP-GAN"><a href="#MLP-GAN" class="headerlink" title="MLP-GAN"></a>MLP-GAN</h3><p>使用多层感知机（MLP）来构建判别器与生成器的网络，可以说得上是最为简单的GANs了。可以根据这个来摸清楚GANs自身的一套工作流程到底是怎么样的，为之后实现复杂的GANs网络做个铺垫。本小节相关代码在<a href="https://github.com/corenel/GAN-Zoo/tree/master/GAN" target="_blank" rel="external">GAN-Zoo/GAN</a>中。</p><p>首先我们需要训练集，比如说我们这里用到的MNIST数据集。PyTorch在这点上做得很好，对于一些常用的数据集都自带有loader，不用自己写了。相关代码见<a href="https://github.com/corenel/GAN-Zoo/blob/master/GAN/data_loader.py" target="_blank" rel="external">GAN-Zoo/GAN/data_loader.py</a>。</p><p>有了数据集之后就需要自己定义模型的网络结构了，具体到GANs就是<a href="https://github.com/corenel/GAN-Zoo/blob/master/GAN/models.py#L6-L22" target="_blank" rel="external">判别器</a>与<a href="https://github.com/corenel/GAN-Zoo/blob/master/GAN/models.py#L25-L41" target="_blank" rel="external">生成器</a>的定义。这里贴一段判别器的定义，可以看出PyTorch在网络定义方面还是很方便的（和Keras差不多）。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Discriminator</span><span class="params">(nn.Module)</span>:</span></div><div class="line">    <span class="string">"""Model for Discriminator."""</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, input_size, hidden_size, output_size)</span>:</span></div><div class="line">        <span class="string">"""Init for Discriminator model."""</span></div><div class="line">        super(Discriminator, self).__init__()</div><div class="line">        self.layer = nn.Sequential(nn.Linear(input_size, hidden_size),</div><div class="line">                                   nn.LeakyReLU(<span class="number">0.2</span>),</div><div class="line">                                   nn.Linear(hidden_size, hidden_size),</div><div class="line">                                   nn.LeakyReLU(<span class="number">0.2</span>),</div><div class="line">                                   nn.Linear(hidden_size, output_size),</div><div class="line">                                   nn.Sigmoid())</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></div><div class="line">        <span class="string">"""Forward step for Discriminator model."""</span></div><div class="line">        out = self.layer(x)</div><div class="line">        <span class="keyword">return</span> out</div></pre></td></tr></table></figure><p>定义完模型，之后就是整个网络的训练过程了：</p><ul><li><a href="https://github.com/corenel/GAN-Zoo/blob/master/GAN/main.py#L17-L37" target="_blank" rel="external">初始化阶段</a>：初始化models、criterion（<code>nn.BCELoss()</code>）以及optimizer（<code>nn.optim.Adam()</code>），检查cuda是否可用（<code>nn.cuda.is_available()</code>），能用的话就上GPU跑。</li><li>网络训练阶段：<ul><li><a href="https://github.com/corenel/GAN-Zoo/blob/master/GAN/main.py#L49-L78" target="_blank" rel="external">训练判别器</a>：主要分为两个步骤，首先从数据集中读取样本，判别器forward一遍，然后和真实标签（<code>1</code>）做loss并backward；其次，生成随机噪声而后经过生成器的forward得到生成样本，再喂给判别器，与虚假标签（<code>0</code>）做loss并backward。最后由optimizer更新判别器网络的参数。</li><li><a href="https://github.com/corenel/GAN-Zoo/blob/master/GAN/main.py#L80-L105" target="_blank" rel="external">训练生成器</a>：首先生成随机噪声，而后通过生成器网络生成虚假样本，再通过判别器网络得到loss，并更新生成器网络。值得注意的是，<a href="https://github.com/corenel/GAN-Zoo/blob/master/GAN/main.py#L91" target="_blank" rel="external">生成器的loss的计算</a>用的是真实标签（<code>1</code>），也就是上述的heuristicly designed non-saturating cost。</li><li><a href="https://github.com/corenel/GAN-Zoo/blob/master/GAN/main.py#L107-L131" target="_blank" rel="external">输出log并保存model</a></li></ul></li></ul><p>非常简单的代码，但是生成出来的数字的效果还是很不错的。</p><p><img src="/images/GAN_real_images.png" alt="GAN_real_images"></p><p><img src="/images/GAN_fake_images-300.png" alt="GAN_fake_images-300"></p><p>第一张是MNIST数据集中的，第二张是通过GANs生成的（300次迭代）。虽然第二张还有些不尽如人意之处（迭代次数太少），但是总体上来说，已经非常接近真实的数字图片了。这就是GANs的威力！</p><h3 id="DCGAN-1"><a href="#DCGAN-1" class="headerlink" title="DCGAN"></a>DCGAN</h3><p>DCGAN与MLP-GAN的代码相差不多，基本上就是重新写一遍model的事。为了测试DCGAN的capacity，我将MNIST数据集换成了CIFAR-10数据集。相关代码见<a href="https://github.com/corenel/GAN-Zoo/tree/master/DCGAN" target="_blank" rel="external">GAN-Zoo/DCGAN</a>。</p><p>不过这次的结果只能说是差强人意，20次迭代后生成的图像还算不错（毕竟CIFAR-10的分辨率是<code>28*28</code>）：</p><p><img src="/images/DCGAN-fake-20-700.png" alt="DCGAN-fake-20-700"></p><p>但是继续训练的话，GANs训练不稳定的问题就出现了。到24次迭代的时候，由于判别器已经非常精准，导致生成器的loss固定在了27左右动弹不得，从而生成的图像变成了一团噪声：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">Epoch [24/25] Step [200/782]:d_loss=2.160674767992532e-07 g_loss=27.614051818847656 D(x)=2.160674767992532e-07 D(G(z))=0.0</div><div class="line">Epoch [24/25] Step [210/782]:d_loss=6.410500191122992e-06 g_loss=27.623014450073242 D(x)=6.410500191122992e-06 D(G(z))=0.0</div><div class="line">Epoch [24/25] Step [220/782]:d_loss=1.5441528375959024e-06 g_loss=27.62175750732422 D(x)=1.5441528375959024e-06 D(G(z))=0.0</div><div class="line">Epoch [24/25] Step [230/782]:d_loss=3.24100881243794e-07 g_loss=27.62472152709961 D(x)=3.24100881243794e-07 D(G(z))=0.0</div><div class="line">...</div></pre></td></tr></table></figure><p><img src="/images/DCGAN-fake-24-300.png" alt="DCGAN-fake-24-300"></p><p>不过到了第25次迭代，DCGAN似乎又略微恢复了正常：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">Epoch [25/25] Step [10/782]:d_loss=0.32297325134277344 g_loss=8.964262962341309 D(x)=0.3229268193244934 D(G(z))=4.6418874262599275e-05</div><div class="line">Epoch [25/25] Step [20/782]:d_loss=0.006471103988587856 g_loss=7.038626194000244 D(x)=0.0035153746139258146 D(G(z))=0.002955729141831398</div><div class="line">Epoch [25/25] Step [30/782]:d_loss=0.17143061757087708 g_loss=12.035135269165039 D(x)=0.17115993797779083 D(G(z))=0.0002706760715227574</div><div class="line">Epoch [25/25] Step [40/782]:d_loss=0.21678031980991364 g_loss=11.419050216674805 D(x)=0.004731819964945316 D(G(z))=0.2120485007762909</div></pre></td></tr></table></figure><p><a href="/images/DCGAN-fake-25-700.png">DCGAN-fake-25-700</a></p><p>当然，让GANs训练变得稳定的方法不是没有，<a href="https://github.com/soumith/ganhacks" target="_blank" rel="external">这里</a>就列举了不少tricks：</p><ul><li>避免稀疏的梯度：不要使用ReLU或者Max Pooling，尽量用LeakyReLU；</li><li>使用软标签（soft and noisy labels），也就是说真实标签与虚假标签不要是固定的<code>1</code>或者<code>0</code>，最好加点噪声上去；</li><li>在真实样本的输入上也加点随时间衰减的噪声</li><li>给生成器加Dropout层</li><li>……</li></ul><p>这样的trick是还有很多，有些我试过确实有用，还有些则不是很确定，属于玄学范畴。不过与其用一大堆额tricks，还不如直接简单粗暴地上WGAN吧！</p><p>（待填坑……）</p><!-- more --><h2 id="Further-Reading"><a href="#Further-Reading" class="headerlink" title="Further Reading"></a>Further Reading</h2><p>最后总结一些我在学习过程中看过的比较好的资料以及代码实现：</p><ul><li><a href="https://github.com/yunjey/pytorch-tutorial" target="_blank" rel="external">pytorch-tutorial</a>: 我见到的最好的PyTorch入门教程，简洁清晰明了，有其他DL框架使用经验以及Python基础的朋友适用。一上来看不懂的话，可以先看官方的60分钟入门教程之后，再看这个。</li><li><a href="http://arxiv.org/abs/1701.00160" target="_blank" rel="external">NIPS 2016 Tutorial: Generative Adversarial Networks</a>: Iran Goodfellow在NIPS2016上的教程演讲，很好地介绍了GANs的基本思想和应用。前面的数学推导看不懂的话，可以结合<a href="http://www.deeplearningbook.org/" target="_blank" rel="external">DeepLearningBook</a>（<a href="http://www.epubit.com.cn/book/details/4278" target="_blank" rel="external">中译版</a>已经上市，本人忝为校对之一）。同时，还可以结合slides看，slides上的都写得很简练，tutorial中则做了详细的说明。可惜的是，当时WGAN及其变种还没有出来，因此在这篇tutorial中没有提到。</li><li>几篇代表论文以及相关的代码实现：<ul><li>GAN: <a href="https://arxiv.org/abs/1406.2661" target="_blank" rel="external">paper</a>, <a href="https://github.com/yunjey/pytorch-tutorial/blob/master/tutorials/02-intermediate/generative_adversarial_network/main.py#L34-L50" target="_blank" rel="external">code (pytorch-tutorial)</a></li><li>DCGAN: <a href="https://arxiv.org/abs/1511.06434" target="_blank" rel="external">paper</a>, <a href="https://github.com/pytorch/examples/tree/master/dcgan" target="_blank" rel="external">code (PyTorch official example)</a>, <a href="https://github.com/yunjey/pytorch-tutorial/tree/master/tutorials/03-advanced/deep_convolutional_gan" target="_blank" rel="external">code (pytorch-tutorial)</a></li><li>WGAN: <a href="https://arxiv.org/abs/1701.07875" target="_blank" rel="external">paper</a>, <a href="https://github.com/martinarjovsky/WassersteinGAN" target="_blank" rel="external">code (PyTorch)</a></li><li>WGAN-GP: <a href="https://arxiv.org/abs/1704.00028" target="_blank" rel="external">https://arxiv.org/abs/1704.00028</a>, <a href="https://github.com/caogang/wgan-gp" target="_blank" rel="external">code (PyTorch)</a></li></ul></li><li>我自己对上述论文的代码实现，欢迎指正：<a href="https://github.com/corenel/GAN-Zoo" target="_blank" rel="external">GAN-Zoo</a></li><li>一些有趣的GANs应用<ul><li><a href="http://make.girls.moe/technical_report.pdf" target="_blank" rel="external">Create Anime Characters with A.I. !</a>：一篇非常有意思的技术文章，生成的头像插图质量非常高。（<a href="http://make.girls.moe/" target="_blank" rel="external">online demo</a>）</li></ul></li></ul></div><div><ul class="post-copyright"><li class="post-copyright-author"><strong>Post author:</strong> Yusu Pan</li><li class="post-copyright-link"><strong>Post link:</strong> <a href="http://www.yuthon.com/2017/08/12/Something-about-GANs/" title="Something about GAN">http://www.yuthon.com/2017/08/12/Something-about-GANs/</a></li><li class="post-copyright-license"><strong>Copyright Notice: </strong>All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/3.0/" rel="external nofollow" target="_blank">CC BY-NC-SA 3.0</a> unless stating additionally.</li></ul></div><footer class="post-footer"><div class="post-tags"><a href="/tags/Deep-Learning/" rel="tag"># Deep Learning</a> <a href="/tags/Generative-Adversarial-Networks/" rel="tag"># Generative Adversarial Networks</a> <a href="/tags/GANs/" rel="tag"># GANs</a> <a href="/tags/DCGAN/" rel="tag"># DCGAN</a> <a href="/tags/WGAN/" rel="tag"># WGAN</a> <a href="/tags/WGAN-GP/" rel="tag"># WGAN-GP</a></div><div class="post-nav"><div class="post-nav-next post-nav-item"><a href="/2017/06/14/Let-s-talk-about-zero-shot-learning/" rel="next" title="Let's talk about Zero-Shot Learning."><i class="fa fa-chevron-left"></i> Let's talk about Zero-Shot Learning.</a></div><span class="post-nav-divider"></span><div class="post-nav-prev post-nav-item"></div></div></footer></div></article><div class="post-spread"></div></div></div><div class="comments" id="comments"><div id="disqus_thread"><noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div></div></div><div class="sidebar-toggle"><div class="sidebar-toggle-line-wrap"><span class="sidebar-toggle-line sidebar-toggle-line-first"></span> <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span> <span class="sidebar-toggle-line sidebar-toggle-line-last"></span></div></div><aside id="sidebar" class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">Table of Contents</li><li class="sidebar-nav-overview" data-target="site-overview">Overview</li></ul><section class="site-overview sidebar-panel"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" src="/uploads/avatar.png" alt="Yusu Pan"><p class="site-author-name" itemprop="name">Yusu Pan</p><p class="site-description motion-element" itemprop="description">We've been gaining one good thing through losing another.</p></div><nav class="site-state motion-element"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">42</span> <span class="site-state-item-name">posts</span></a></div><div class="site-state-item site-state-categories"><a href="/categories/index.html"><span class="site-state-item-count">5</span> <span class="site-state-item-name">categories</span></a></div><div class="site-state-item site-state-tags"><a href="/tags/index.html"><span class="site-state-item-count">52</span> <span class="site-state-item-name">tags</span></a></div></nav><div class="feed-link motion-element"><a href="/atom.xml" rel="alternate"><i class="fa fa-rss"></i> RSS</a></div><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/corenel" target="_blank" title="GitHub"><i class="fa fa-fw fa-github"></i> GitHub </a></span><span class="links-of-author-item"><a href="https://twitter.com/corenel" target="_blank" title="Twitter"><i class="fa fa-fw fa-twitter"></i> Twitter </a></span><span class="links-of-author-item"><a href="http://www.zhihu.com/people/pan-yu-su" target="_blank" title="Zhihu"><i class="fa fa-fw fa-globe"></i> Zhihu</a></span></div><div class="cc-license motion-element" itemprop="license"><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" target="_blank"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a></div></section><!--noindex--><section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active"><div class="post-toc"><div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Before-Reading-PyTorch"><span class="nav-number">1.</span> <span class="nav-text">Before Reading: PyTorch</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Introduction"><span class="nav-number">2.</span> <span class="nav-text">Introduction</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#How-do-GANs-Work"><span class="nav-number">3.</span> <span class="nav-text">How do GANs Work?</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#The-GAN-framework"><span class="nav-number">3.1.</span> <span class="nav-text">The GAN framework</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Cost-function"><span class="nav-number">3.2.</span> <span class="nav-text">Cost function</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#DCGAN"><span class="nav-number">4.</span> <span class="nav-text">DCGAN</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#WGAN-amp-WGAN-GP"><span class="nav-number">5.</span> <span class="nav-text">WGAN & WGAN-GP</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#What-does-it-mean-to-learn-a-probability-distribution"><span class="nav-number">5.1.</span> <span class="nav-text">What does it mean to learn a probability distribution?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Different-Disrances"><span class="nav-number">5.2.</span> <span class="nav-text">Different Disrances</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#GANs-in-Practice"><span class="nav-number">6.</span> <span class="nav-text">GANs in Practice</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#MLP-GAN"><span class="nav-number">6.1.</span> <span class="nav-text">MLP-GAN</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#DCGAN-1"><span class="nav-number">6.2.</span> <span class="nav-text">DCGAN</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Further-Reading"><span class="nav-number">7.</span> <span class="nav-text">Further Reading</span></a></li></ol></div></div></section><!--/noindex--></div></aside></div></main><footer id="footer" class="footer"><div class="footer-inner"><div class="copyright">&copy; 2015 - <span itemprop="copyrightYear">2017</span> <span class="with-love"><i class="fa fa-heart"></i> </span><span class="author" itemprop="copyrightHolder">Yusu Pan</span></div><div class="powered-by">Powered by <a class="theme-link" href="https://hexo.io">Hexo</a></div><div class="theme-info">Theme - <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a></div></div></footer><div class="back-to-top"><i class="fa fa-arrow-up"></i></div></div><script type="text/javascript">if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }</script><script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script><script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script><script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script><script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script><script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script><script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script><script type="text/javascript" src="/js/src/utils.js?v=5.1.2"></script><script type="text/javascript" src="/js/src/motion.js?v=5.1.2"></script><script type="text/javascript" src="/js/src/affix.js?v=5.1.2"></script><script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.2"></script><script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.2"></script><script type="text/javascript" src="/js/src/post-details.js?v=5.1.2"></script><script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.2"></script><script id="dsq-count-scr" src="https://yuthons-blog.disqus.com/count.js" async></script><script type="text/javascript">var disqus_config = function () {
          this.page.url = 'http://www.yuthon.com/2017/08/12/Something-about-GANs/';
          this.page.identifier = '2017/08/12/Something-about-GANs/';
          this.page.title = 'Something about GAN';
        };
        var d = document, s = d.createElement('script');
        s.src = 'https://yuthons-blog.disqus.com/embed.js';
        s.setAttribute('data-timestamp', '' + +new Date());
        (d.head || d.body).appendChild(s);</script><script type="text/javascript">// Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });</script><script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end --></body></html>
<!DOCTYPE html><html class="theme-next pisces use-motion" lang="en"><head><!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta name="theme-color" content="#222"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta name="google-site-verification" content="BGEL63KNRW25AkpCy3shpRdMWDHE9LZTAFS3XSHtFK8"><link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css"><link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css"><link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css"><link href="/css/main.css?v=5.1.2" rel="stylesheet" type="text/css"><meta name="keywords" content="Deep Learning,Semantic Segmentation,"><link rel="alternate" href="/atom.xml" title="Yuthon's blog" type="application/atom+xml"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.2"><meta name="description" content="This is my notes for Seed, Expand and Constrain: Three Principles for Weakly-Supervised Image Segmentation.  arxiv: https://arxiv.org/abs/1603.06098 github: https://github.com/kolesman/SEC"><meta name="keywords" content="Deep Learning,Semantic Segmentation"><meta property="og:type" content="article"><meta property="og:title" content="Thesis Notes for SEC"><meta property="og:url" content="http://www.yuthon.com/2017/04/28/Thesis-Notes-for-SEC/index.html"><meta property="og:site_name" content="Yuthon&#39;s blog"><meta property="og:description" content="This is my notes for Seed, Expand and Constrain: Three Principles for Weakly-Supervised Image Segmentation.  arxiv: https://arxiv.org/abs/1603.06098 github: https://github.com/kolesman/SEC"><meta property="og:locale" content="en"><meta property="og:image" content="http://www.yuthon.com/images/illustratio_of_SEC.png"><meta property="og:image" content="http://www.yuthon.com/images/illustration_of_weak_localization.png"><meta property="og:image" content="http://www.yuthon.com/images/schematic_illustration_at_test_time.png"><meta property="og:updated_time" content="2017-05-10T14:06:08.000Z"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="Thesis Notes for SEC"><meta name="twitter:description" content="This is my notes for Seed, Expand and Constrain: Three Principles for Weakly-Supervised Image Segmentation.  arxiv: https://arxiv.org/abs/1603.06098 github: https://github.com/kolesman/SEC"><meta name="twitter:image" content="http://www.yuthon.com/images/illustratio_of_SEC.png"><script type="text/javascript" id="hexo.configurations">var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    sidebar: {"position":"left","display":"hide","offset":12,"offset_float":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };</script><link rel="canonical" href="http://www.yuthon.com/2017/04/28/Thesis-Notes-for-SEC/"><title>Thesis Notes for SEC | Yuthon's blog</title><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
            (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-76233259-1', 'auto');
  ga('send', 'pageview');</script><!-- hexo-inject:begin --><!-- hexo-inject:end --></head><body itemscope itemtype="http://schema.org/WebPage" lang="en"><!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail"><div class="headband"></div><header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-wrapper"><div class="site-meta"><div class="custom-logo-site-title"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span> <span class="site-title">Yuthon's blog</span> <span class="logo-line-after"><i></i></span></a></div><p class="site-subtitle"></p></div><div class="site-nav-toggle"><button><span class="btn-bar"></span> <span class="btn-bar"></span> <span class="btn-bar"></span></button></div></div><nav class="site-nav"><ul id="menu" class="menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i><br>Home</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i><br>Archives</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i><br>Tags</a></li><li class="menu-item menu-item-search"><a href="javascript:;" class="popup-trigger"><i class="menu-item-icon fa fa-search fa-fw"></i><br>Search</a></li></ul><div class="site-search"><div class="popup search-popup local-search-popup"><div class="local-search-header clearfix"><span class="search-icon"><i class="fa fa-search"></i> </span><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span><div class="local-search-input-wrapper"><input autocomplete="off" placeholder="Searching..." spellcheck="false" type="text" id="local-search-input"></div></div><div id="local-search-result"></div></div></div></nav></div></header><main id="main" class="main"><div class="main-inner"><div class="content-wrap"><div id="content" class="content"><div id="posts" class="posts-expand"><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><div class="post-block"><link itemprop="mainEntityOfPage" href="http://www.yuthon.com/2017/04/28/Thesis-Notes-for-SEC/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="Yusu Pan"><meta itemprop="description" content=""><meta itemprop="image" content="/uploads/avatar.png"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Yuthon's blog"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">Thesis Notes for SEC</h1><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">Posted on</span> <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-04-28T09:13:33+08:00">2017-04-28 </time><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-calendar-check-o"></i> </span><span class="post-meta-item-text">Post modified</span> <time title="Post modified" itemprop="dateModified" datetime="2017-05-10T22:06:08+08:00">2017-05-10 </time></span><span class="post-category"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-folder-o"></i> </span><span class="post-meta-item-text">In</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Thesis-Notes/" itemprop="url" rel="index"><span itemprop="name">Thesis Notes</span> </a></span></span><span class="post-comments-count"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-comment-o"></i> </span><a href="/2017/04/28/Thesis-Notes-for-SEC/#comments" itemprop="discussionUrl"><span class="post-comments-count disqus-comment-count" data-disqus-identifier="2017/04/28/Thesis-Notes-for-SEC/" itemprop="commentCount"></span></a></span></div></header><div class="post-body" itemprop="articleBody"><p>This is my notes for <strong>Seed, Expand and Constrain: Three Principles for Weakly-Supervised Image Segmentation</strong>.</p><ul><li>arxiv: <a href="https://arxiv.org/abs/1603.06098" target="_blank" rel="external">https://arxiv.org/abs/1603.06098</a></li><li>github: <a href="https://github.com/kolesman/SEC" target="_blank" rel="external">https://github.com/kolesman/SEC</a></li></ul><a id="more"></a><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>本篇论文主要是介绍了针对 image-level 弱监督语义分割的一种新的 loss function。这个 loss function 由三部分组成：</p><ul><li><strong>seeding loss</strong>：针对使用 Image calssification CNN 来进行 object localization 的问题。传统的分类网络（比如 AlexNet 或者说 VGG）能够生成可靠的定位线索（即 <strong>seeds</strong> ），然是在预测物体确切的空间范围上就不怎么样了。这个 seeding loss 主要就是来使得分割网络能够准确地匹配到物体的定位线索（localization cues），但是不要扩展得太开，基本上就是只标出物体的中心位置，而无视图像中的其他不相关的部分。</li><li><strong>expansion loss</strong>：因为是要用 image-level 的标注来训练份额网络，所以需要考虑用 global pooling 来将预测出的 mask 转换成 image-level label scrores。这个 pooling 层的选择很大程度上决定了最终训练得到的分割网络的预测质量。一般来说，global max-pooling 倾向于低估物体的尺寸，而global average-pooling 则倾向于高估。本文使用了一种叫做 <strong>global weighted rank pooling</strong> 的方法来将物体的 seeds 扩展到一个尺寸比较合适的区域来计分，从而计算 expansion loss。这种方法是 max-pooling 和 average-pooling 的一种泛化版本，并且性能比这两者要高。</li><li><strong>constrain-to-boundary loss</strong>：根据 image-level label 训练出来的网络很少能够捕捉到图像中物体的精确边缘，而且仅仅在测试的时候在网络后面套一层全连接的 CRF 也往往难以完全克服这个缺陷。这是因为按照传统方法训练出来的网络，即便是对于未标记的区域，也倾向于有比较高的置信度。于是本文提出了一种新的 loss， 能够使得网络在训练的时候就减轻不精确的边缘预测。这一 loss 主要是对预测得到的 mask 进行约束，使其能在一定程度上遵循低层次的图像信息，特别是物体的边缘这样的重要信息。</li></ul><p>文中将这一方法称为<strong>SEC</strong>，即 <strong>S</strong>eed，<strong>E</strong>xpand和<strong>C</strong>onstrain。之后将分块介绍其具体实现。</p><h2 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h2><p>现有的 image-level 弱监督语义分割的方法主要可以分为三类：</p><ul><li><strong>基于图的方法（graph-based Model）</strong>：根据图像内或图像间的部分（segments）或是超像素（superpixels）的相似性来推断其标签。</li><li><strong>多实例学习（multiple instance learning）</strong>：使用 per-image loss function 来进行训练，本质上是保持了图像中能够被用来生成 mask 的一种空间表示。<ul><li>例如 MIL-FCN 以及 MIL-ILP，其区别主要在于 pooling 策略，也就是说它们如何将其内在的空间表示转换到 per-image labels。</li></ul></li><li><strong>自学习（self-training）</strong>：模型本身使用基于 EM-like 的方法来生成 pixel-level 的标注，然后再来训练 fully-supervised 的分割网络。<ul><li>例如 EM-Adapt 以及 CCNN，其区别在于如何将 per-image annotation 转换到 mask 并保持其一致性。</li><li>SN_B 又增加了额外的步骤来创建于合并多个目标的proposal。</li></ul></li></ul><p>文中介绍的 SEC 包含了后两类方法，即其既使用了 per-image 的 loss，也使用了 per-pixel 的 loss 形式。</p><h2 id="Weakly-supervised-segmentation-from-image-level-labels"><a href="#Weakly-supervised-segmentation-from-image-level-labels" class="headerlink" title="Weakly supervised segmentation from image-level labels"></a>Weakly supervised segmentation from image-level labels</h2><h3 id="Table-of-Symbols"><a href="#Table-of-Symbols" class="headerlink" title="Table of Symbols"></a>Table of Symbols</h3><table><thead><tr><th style="text-align:center">Symbol</th><th style="text-align:center">Description</th><th style="text-align:center">Note</th></tr></thead><tbody><tr><td style="text-align:center">$\chi$</td><td style="text-align:center">the space of images</td><td style="text-align:center"></td></tr><tr><td style="text-align:center">$X_i$</td><td style="text-align:center">an image</td><td style="text-align:center">$X_i \in \chi$</td></tr><tr><td style="text-align:center">$N$</td><td style="text-align:center">number of images</td><td style="text-align:center"></td></tr><tr><td style="text-align:center">$Y$</td><td style="text-align:center">a segmentation mask</td><td style="text-align:center">$Y = (y_1 \dots y_n)$</td></tr><tr><td style="text-align:center">$y_i$</td><td style="text-align:center">a semantic label at $i$ spatial location</td><td style="text-align:center"></td></tr><tr><td style="text-align:center">$n$</td><td style="text-align:center">number of spatial locations</td><td style="text-align:center"></td></tr><tr><td style="text-align:center">$u$</td><td style="text-align:center">a location</td><td style="text-align:center">$u\in {1,2,\dots n}$</td></tr><tr><td style="text-align:center">$C$</td><td style="text-align:center">a set of all labels</td><td style="text-align:center">$C=C’ \cup {c^{bg}}$, size is $k$</td></tr><tr><td style="text-align:center">$C’$</td><td style="text-align:center">a set of all foreground labels</td><td style="text-align:center"></td></tr><tr><td style="text-align:center">$c^{bg}$</td><td style="text-align:center">a background label</td><td style="text-align:center"></td></tr><tr><td style="text-align:center">$k$</td><td style="text-align:center">number of kinds of labels</td><td style="text-align:center"></td></tr><tr><td style="text-align:center">$c$</td><td style="text-align:center">a label</td><td style="text-align:center">$c\in C$</td></tr><tr><td style="text-align:center">$T_i$</td><td style="text-align:center">a set of weakly annotated foreground labels in an image</td><td style="text-align:center">$T_i \in C’$</td></tr><tr><td style="text-align:center">$S_c$</td><td style="text-align:center">a set of locations that are labeled with class $c$ by the weak localizatio procdure</td><td style="text-align:center"></td></tr><tr><td style="text-align:center">$f(X;\theta)$</td><td style="text-align:center">segment network, briefly written as $f(X)$</td><td style="text-align:center">$f_{u,c}(X;\theta)=p(y_u=c \mid X)$</td></tr></tbody></table><h3 id="The-SEC-loss-for-weakly-supervised-image-segmentation"><a href="#The-SEC-loss-for-weakly-supervised-image-segmentation" class="headerlink" title="The SEC loss for weakly supervised image segmentation"></a>The SEC loss for weakly supervised image segmentation</h3><p>本节将介绍 SEC 的 loss function 的三个组成部分，其各自的功用如下：</p><ul><li>$L_{seed}$: 为网络预测提供提示（hint）</li><li>$L_{expand}$: 惩罚太小或者是搞错对象的预测 mask</li><li>$L_{constrain}$: 鼓励分割能够与图像空间以及色彩结构相适应</li></ul><p>本文的目标是训练一个参数为$\theta$的一个深度卷积神经网络$f(X;\theta)$，其能够预测在任一位置$u\in {1,2, \dots , n}$上任一标签$c\in C$的条件概率，也就是说，$f_{u,c}(X;\theta)=p(y_u=c \mid X)$。</p><p>该网络的训练即为下式的优化问题：<br>$$<br>min_{\theta} \sum_{(X,T)\in D}[L_{seed}(f(X;\theta), T) + L_{expand}(f(X;\theta), T) + L_{constrain}(X, f(X;\theta))]<br>$$</p><p>整个网络的结构如下图所示：</p><p><img src="/images/illustratio_of_SEC.png" alt="A schematic illustration of SEC"></p><h4 id="Seeding-loss-with-localization-cues"><a href="#Seeding-loss-with-localization-cues" class="headerlink" title="Seeding loss with localization cues"></a>Seeding loss with localization cues</h4><p>Image-level 的标签本身是不能提供语义目标的定位信息的，但是以 CNN 为基础的 Classification Network 却能够提供一个比较弱的定位信息（<strong>weak localization</strong>），如下图所示。</p><p><img src="/images/illustration_of_weak_localization.png" alt="The schematic illustration of the weak localization procedure"></p><p>当然，这种 weak location 或者说 location cues 并没有精确到能直接拿来当 full and accurate segmentation masks 的地步。不过还是可以用来指导弱监督分割网络的。文中提到的 <em>seeding loss</em> 主要是用来使得网络只匹配 weak localization 的 landmark，而无视图像中的其他部分。<em>seeding loss</em> $L_{seed}$ 的定义如下：<br>$$<br>L_{seed}(f(X), T, S_c) = - \frac{1}{\sum_{c\in T} |S_c|} \sum_{c\in T} \sum_{u\in S_c} log f_{u,c}(X)<br>$$<br>需要注意的是，文章中的 weak location 是预先计算好的，并非在训练过程中生成。前景用的是 <em>Learning deep features for discriminative localization</em>，背景用的是 <em>Deep inside convolutional networks: Visualising image classification models and saliency maps</em> 中的方法</p><h4 id="Expansion-loss-with-global-weighted-rank-pooling"><a href="#Expansion-loss-with-global-weighted-rank-pooling" class="headerlink" title="Expansion loss with global weighted rank pooling"></a>Expansion loss with global weighted rank pooling</h4><p>要度量分割后的 mask 与原来的 image-level 标签的一致程度的话，可以把每个像素的分割的得分合起来形成一个总的分类得分，然后再套上个 loss function 就能用来训练多标签的图像分类了。一般来说，有两种比较常用的方法：</p><ul><li>一个是 <strong>GMP (global max-pooling)</strong>，对于一张图像$X$，每个类$c$的得分就是所有像素的该类得分的最大值$max_{u\in {1,\dots,n}} f_{u,c} (X)$。GMP 仅仅鼓励单个位置的响应变得很高，因此常常低估了目标的大小。</li><li>另外一个就是 GAP (global average-pooling) ，得分是所有像素该类得分的平均值$\frac{1}{n} \sum ^n _{u=1} f_{u,c} (X)$。而 GAP 鼓励所有的响应都变高，因此常常高估了目标的大小。</li></ul><p>文中提出了一个叫做 <strong>GWRP</strong> 的方法，具体来说是这样的：对于一个类$c\in C$，定义其预测得分的一个降序排列$I^c = {i_1, \dots, i_n}$，即$f_{i_1, c} (x) \ge f_{i_2, c} (x) \ge \dots \ge f_{i_n, c} (x)$ 。同时令$d_c$为类别$c$得分的衰减系数。那么 GWRP 的分类得分$G_c(f(X), d_c)$可定义为：<br>$$<br>G_c (f(X); d_c) = \frac{1}{Z(d_c)} \sum ^n _{j=1} (d_c)^{-1} f_{i_j, c} (X) \text{, where } Z(d_c) = \sum ^n _{j=1} (d_c) ^ {j-1}<br>$$<br>值得注意的是，当$d_c = 0$时，GWRP 即为 GMP （$0^0=1$），而当$d_c = 1$时，GWRP 为 GAP。也就是说， GWRP 是前述两种方法的一个泛化形式，通过$d_c$来控制。</p><p>原则上来说，可以给每个类和每张图片设置不同的衰减系数$d_c$，不过这就需要知道每个类里面的物体通常的大小这样的先验知识，显然我们用的弱监督是没有这类信息的。因此，文中只设置了三个不同的$d_c$：</p><ul><li>$d_{+}$：在图像中出现了的类别的衰减系数</li><li>$d_{-}$：在图像中未出现的类别的衰减系数</li><li>$d_{bg}$：图像背景类别的衰减系数。</li></ul><p>这三个系数的具体取值见第四节。</p><p>综上，<em>expansion loss</em> 的完整形式如下：<br>$$<br>\begin{align} L_{expand}(f(X), T) = &amp;-\frac{1}{|T|} \sum _{c\in T} log G_c (f(X);d_{+}) \\ &amp;-\frac{1}{|C’ \backslash T|} \sum _{c\in C’\backslash T} log G_c (f(X);d_{-}) \\ &amp;- logG_{c^{bg}} (f(X);d_{bg}) \end{align}<br>$$</p><h4 id="Constrain-to-boundary-loss"><a href="#Constrain-to-boundary-loss" class="headerlink" title="Constrain-to-boundary loss"></a>Constrain-to-boundary loss</h4><p>使用 <em>constrain-to-boundary loss</em> 的思想是要惩罚网络，使其不要预测出和输入图像的色彩与空间信息不连续的分割。也就是说，要<strong>鼓励网络学习到生成与目标边界相匹配的分割 mask</strong>。</p><p>具体来说，就是构建了一个全连接的 CRF 层，$Q(X,f(X))$，unary potentials 用的是分割网络预测出的对数概率得分，pairwise potentials 则是只取决于图像像素的定值参数形式。为了与分割 mask 的分辨率相匹配，还要对图像 $X$ 降采样。具体的方式见第四节。</p><p>总而言之， <em>constrain-to-boundary loss</em> 被定义为网络输出与 CRF 输出之间的 KL 散度：<br>$$<br>L_{constrain} (X, f(X)) = \frac{1}{n} \sum ^n _{u=1} \sum _{c\in C} Q_{u,c} (X, f(X)) log \frac{Q_{u,c}(X, f(X))}{f_{u,c}(X)}<br>$$<br>这一构建形式的公式能够很好地达到预期目标。其能鼓励网络输出与 CRF 的输出接近，而 CRF 的输出又被确信是能够遵循图像边缘的。</p><h3 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h3><p>既然要训练，那么反向传播肯定是要的，因此各个层都要是可微的。其它层都没什么问题，全连接 CRF 层的梯度计算方法见 <em>Random field model for integration of local informationand global information</em> 。</p><h2 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h2><h3 id="Experiment-setup"><a href="#Experiment-setup" class="headerlink" title="Experiment setup"></a>Experiment setup</h3><h4 id="Dataset-and-evaluation-metric"><a href="#Dataset-and-evaluation-metric" class="headerlink" title="Dataset and evaluation metric"></a>Dataset and evaluation metric</h4><p>文中<strong>用的数据集是 PASCAL VOC 2012</strong>，含背景在内共21个类别。原版的 VOC 2012 的语义分割部分的图像很少，训练集、验证集、测试集分别是1464、1449、1456张图像。所以文章里还<strong>用了 SegmentationAug 的扩充数据集</strong>，里面总共有10582张弱标注的图像，这个数量基本上够了。</p><p>至于与其他方法的对比是在验证集与测试集上进行比较。因为验证集的 ground truth 是向公众开放的，所以主要在验证集上研究一些 SEC 中不同组件之间的相互影响。而测试集必须在 PASCAL VOC 的官方服务器上才能得到结果的，因此就只是用来对比结果。</p><p><strong>性能度量用的是最常见的 mIoU</strong>。</p><h4 id="Segmentation-network"><a href="#Segmentation-network" class="headerlink" title="Segmentation network"></a>Segmentation network</h4><p>本文所选用的分割网络是基于 VGG-16 修改而来的 DeepLab-CRF-LargeFOV，输入为321x321，输出41x41的 mask。除了最后一层预测层初始化为均值为0方差为0.01的正态分布外，其余卷积层都按照 VGG 原本的方式初始化。</p><h4 id="Localization-network"><a href="#Localization-network" class="headerlink" title="Localization network"></a>Localization network</h4><p>定位网络也是根据 VGG-16 改的，训练的话是用 SegmentationAug 数据集训练一个多标签分类的问题。详细的方法和参数在文章的附录里面。值得注意的是，在训练的时候，为了提高效率，降低计算复杂度，localization cues是预先生成好的。</p><h4 id="Optimization"><a href="#Optimization" class="headerlink" title="Optimization"></a>Optimization</h4><p>用的是传统的 batched SGD来训练。总计8000次迭代，batch size为15，dropout rate为0.5，weight decay为0.0005。初始 learning rate 为0.001，每2000次迭代除以10。</p><p>硬件设备用的是 TITAN-X，训练一次大约7到8小时。</p><h4 id="Decay-parameters"><a href="#Decay-parameters" class="headerlink" title="Decay parameters"></a>Decay parameters</h4><p>经验法则如下：</p><ul><li>对于那些没有出现在图像中的类别，我们希望预测的像素越少越好。所以说令$d_{-}=0$，即使用GMP。</li><li>对于那些出现在图像中的类别，建议前10%的得分能够占到总得分之和的50%。对于41x41的mask来说，差不多相当于$d_{+}=0.996$。</li><li>对于背景类别，建议前30%的得分占到总得分之和的50%，在文中是$d_{bg}=0.999$</li></ul><h4 id="Fully-connected-CRF-at-training-time"><a href="#Fully-connected-CRF-at-training-time" class="headerlink" title="Fully-connected CRF at training time"></a>Fully-connected CRF at training time</h4><p>Pairwise parameter 照搬 <em>Efficient inference in fully connected CRFs with gaus- sian edge potentials</em> 这篇文章的默认值，除了把所有的空间距离项乘了12（为了与预测出来的 mask 大小相匹配，文中把原始图像降采样了）。</p><h4 id="Inference-at-test-time"><a href="#Inference-at-test-time" class="headerlink" title="Inference at test time"></a>Inference at test time</h4><p>分割网络最终输出的图像大小比原始图像小，因此还需要经过上采样以及过一遍全连接 CRF 来 refine。</p><p><img src="/images/schematic_illustration_at_test_time.png" alt="The schematic illustration of our approach at test time"></p><h3 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h3><p>（To be continued）</p></div><div><ul class="post-copyright"><li class="post-copyright-author"><strong>Post author:</strong> Yusu Pan</li><li class="post-copyright-link"><strong>Post link:</strong> <a href="http://www.yuthon.com/2017/04/28/Thesis-Notes-for-SEC/" title="Thesis Notes for SEC">http://www.yuthon.com/2017/04/28/Thesis-Notes-for-SEC/</a></li><li class="post-copyright-license"><strong>Copyright Notice: </strong>All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/3.0/" rel="external nofollow" target="_blank">CC BY-NC-SA 3.0</a> unless stating additionally.</li></ul></div><footer class="post-footer"><div class="post-tags"><a href="/tags/Deep-Learning/" rel="tag"># Deep Learning</a> <a href="/tags/Semantic-Segmentation/" rel="tag"># Semantic Segmentation</a></div><div class="post-nav"><div class="post-nav-next post-nav-item"><a href="/2017/04/27/Notes-From-Faster-R-CNN-to-Mask-R-CNN/" rel="next" title="Notes: From Faster R-CNN to Mask R-CNN"><i class="fa fa-chevron-left"></i> Notes: From Faster R-CNN to Mask R-CNN</a></div><span class="post-nav-divider"></span><div class="post-nav-prev post-nav-item"><a href="/2017/05/10/Thesis-Notes-for-Amortized-Inference-and-Learning-in-Latent-CRF/" rel="prev" title="Thesis Notes for Amortized Inference and Learning in Latent CRF">Thesis Notes for Amortized Inference and Learning in Latent CRF <i class="fa fa-chevron-right"></i></a></div></div></footer></div></article><div class="post-spread"></div></div></div><div class="comments" id="comments"><div id="disqus_thread"><noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div></div></div><div class="sidebar-toggle"><div class="sidebar-toggle-line-wrap"><span class="sidebar-toggle-line sidebar-toggle-line-first"></span> <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span> <span class="sidebar-toggle-line sidebar-toggle-line-last"></span></div></div><aside id="sidebar" class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">Table of Contents</li><li class="sidebar-nav-overview" data-target="site-overview">Overview</li></ul><section class="site-overview sidebar-panel"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" src="/uploads/avatar.png" alt="Yusu Pan"><p class="site-author-name" itemprop="name">Yusu Pan</p><p class="site-description motion-element" itemprop="description">We've been gaining one good thing through losing another.</p></div><nav class="site-state motion-element"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">44</span> <span class="site-state-item-name">posts</span></a></div><div class="site-state-item site-state-categories"><a href="/categories/index.html"><span class="site-state-item-count">5</span> <span class="site-state-item-name">categories</span></a></div><div class="site-state-item site-state-tags"><a href="/tags/index.html"><span class="site-state-item-count">54</span> <span class="site-state-item-name">tags</span></a></div></nav><div class="feed-link motion-element"><a href="/atom.xml" rel="alternate"><i class="fa fa-rss"></i> RSS</a></div><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/corenel" target="_blank" title="GitHub"><i class="fa fa-fw fa-github"></i> GitHub </a></span><span class="links-of-author-item"><a href="https://twitter.com/corenel" target="_blank" title="Twitter"><i class="fa fa-fw fa-twitter"></i> Twitter </a></span><span class="links-of-author-item"><a href="http://www.zhihu.com/people/pan-yu-su" target="_blank" title="Zhihu"><i class="fa fa-fw fa-globe"></i> Zhihu</a></span></div><div class="cc-license motion-element" itemprop="license"><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" target="_blank"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a></div></section><!--noindex--><section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active"><div class="post-toc"><div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Introduction"><span class="nav-number">1.</span> <span class="nav-text">Introduction</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Related-Work"><span class="nav-number">2.</span> <span class="nav-text">Related Work</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Weakly-supervised-segmentation-from-image-level-labels"><span class="nav-number">3.</span> <span class="nav-text">Weakly supervised segmentation from image-level labels</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Table-of-Symbols"><span class="nav-number">3.1.</span> <span class="nav-text">Table of Symbols</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#The-SEC-loss-for-weakly-supervised-image-segmentation"><span class="nav-number">3.2.</span> <span class="nav-text">The SEC loss for weakly supervised image segmentation</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Seeding-loss-with-localization-cues"><span class="nav-number">3.2.1.</span> <span class="nav-text">Seeding loss with localization cues</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Expansion-loss-with-global-weighted-rank-pooling"><span class="nav-number">3.2.2.</span> <span class="nav-text">Expansion loss with global weighted rank pooling</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Constrain-to-boundary-loss"><span class="nav-number">3.2.3.</span> <span class="nav-text">Constrain-to-boundary loss</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Training"><span class="nav-number">3.3.</span> <span class="nav-text">Training</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Experiments"><span class="nav-number">4.</span> <span class="nav-text">Experiments</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Experiment-setup"><span class="nav-number">4.1.</span> <span class="nav-text">Experiment setup</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Dataset-and-evaluation-metric"><span class="nav-number">4.1.1.</span> <span class="nav-text">Dataset and evaluation metric</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Segmentation-network"><span class="nav-number">4.1.2.</span> <span class="nav-text">Segmentation network</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Localization-network"><span class="nav-number">4.1.3.</span> <span class="nav-text">Localization network</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Optimization"><span class="nav-number">4.1.4.</span> <span class="nav-text">Optimization</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Decay-parameters"><span class="nav-number">4.1.5.</span> <span class="nav-text">Decay parameters</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Fully-connected-CRF-at-training-time"><span class="nav-number">4.1.6.</span> <span class="nav-text">Fully-connected CRF at training time</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Inference-at-test-time"><span class="nav-number">4.1.7.</span> <span class="nav-text">Inference at test time</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Results"><span class="nav-number">4.2.</span> <span class="nav-text">Results</span></a></li></ol></li></ol></div></div></section><!--/noindex--></div></aside></div></main><footer id="footer" class="footer"><div class="footer-inner"><div class="copyright">&copy; 2015 - <span itemprop="copyrightYear">2017</span> <span class="with-love"><i class="fa fa-heart"></i> </span><span class="author" itemprop="copyrightHolder">Yusu Pan</span></div><div class="powered-by">Powered by <a class="theme-link" href="https://hexo.io">Hexo</a></div><div class="theme-info">Theme - <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a></div></div></footer><div class="back-to-top"><i class="fa fa-arrow-up"></i></div></div><script type="text/javascript">if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }</script><script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script><script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script><script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script><script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script><script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script><script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script><script type="text/javascript" src="/js/src/utils.js?v=5.1.2"></script><script type="text/javascript" src="/js/src/motion.js?v=5.1.2"></script><script type="text/javascript" src="/js/src/affix.js?v=5.1.2"></script><script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.2"></script><script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.2"></script><script type="text/javascript" src="/js/src/post-details.js?v=5.1.2"></script><script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.2"></script><script id="dsq-count-scr" src="https://yuthons-blog.disqus.com/count.js" async></script><script type="text/javascript">var disqus_config = function () {
          this.page.url = 'http://www.yuthon.com/2017/04/28/Thesis-Notes-for-SEC/';
          this.page.identifier = '2017/04/28/Thesis-Notes-for-SEC/';
          this.page.title = 'Thesis Notes for SEC';
        };
        var d = document, s = d.createElement('script');
        s.src = 'https://yuthons-blog.disqus.com/embed.js';
        s.setAttribute('data-timestamp', '' + +new Date());
        (d.head || d.body).appendChild(s);</script><script type="text/javascript">// Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });</script><script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end --></body></html>
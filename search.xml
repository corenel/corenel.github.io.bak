<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title><![CDATA[Train YOLOv2 on my own dataset]]></title>
      <url>%2F2016%2F12%2F03%2FTrain-YOLOv2-on-my-own-dataset%2F</url>
      <content type="text"><![CDATA[最近在看 Darkflow 的时候, 发现连 YOLOv2 都出了, 据称 mAP 和速度都提升了不少, 立马 clone 下来试了一番. InstructionComparison下面是官网挂出来的一个对比表, 可以看出, YOLOv2 有 76.8 的mAP, 和 SSD500 相同, 但是 FPS 不知比 SSD 高到哪里去了. YOLOv2 544x544 提升到了 78.6 mAP, 比 Faster-RCNN 的 Baseline (ResNet-101, VOC07+12) 的 76.4 mAP 高, 但是比其 Baseline+++ (ResNet-101, COCO+VOC2007+VOC2012) 的 85.6 mAP 还是逊色了不少. 不过官网没有挂出来 training on Pascal + COCO data and testing on Pascal data 的数据, 想见应该也会在 80 mAP 以上. 更加可喜的是, Tiny-YOLOv2比之前的Tiny-YOLO高出了52FPS, 达到了惊人的207FPS, 想必在 TX1 上跑的话应该也能上20FPS. Model Train Test mAP FLOPS FPS Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 SSD300 VOC 2007+2012 2007 74.3 - 46 SSD500 VOC 2007+2012 2007 76.8 - 19 YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 SSD300 COCO trainval test-dev 41.2 - 46 SSD500 COCO trainval test-dev 46.5 - 19 YOLOv2 544x544 COCO trainval test-dev 44.0 59.68 Bn 40 What’s New in Version 2具体的文章还没在 Arxiv 上挂出来, 按照目前透露的信息, 主要是像 SSD 和 Overfeat 那样全部都用了卷积层, 而不是后面还跟着全连接层. 但是不同的是, 仍然是对整个图像进行训练. 同时还借鉴了 Faster-RCNN, 调整了 Bounding Box 的优先级, 不直接预测w, h, 但是仍然是直接预测x, y坐标. Video官网还挂了一个用 YOLOv2 识别过的 007 的 Trailer, 配乐+Bounding Box 使得这个视频莫名其妙地非常搞笑, 建议去看看. Training下面讲讲使用 YOLOv2 在我自己做的数据集 ROBdevkit 上的训练过程. Make123$ git clone https://github.com/pjreddie/darknet$ cd darknet$ make -j8 在make之前, 为了最大发挥机器的性能, 还需要修改Makefile: 1234567891011121314151617181920diff --git a/Makefile b/Makefileindex 3d3d5e4..dd7a33d 100644--- a/Makefile+++ b/Makefile@@ -1,6 +1,6 @@-GPU=0-CUDNN=0-OPENCV=0+GPU=1+CUDNN=1+OPENCV=1 DEBUG=0 ARCH= -gencode arch=compute_20,code=[sm_20,sm_21] \@@ -10,47 +10,47 @@ ARCH= -gencode arch=compute_20,code=[sm_20,sm_21] \ -gencode arch=compute_52,code=[sm_52,compute_52] # This is what I use, uncomment if you know your arch and want to specify-# ARCH= -gencode arch=compute_52,code=compute_52+ARCH= -gencode arch=compute_61,code=compute_61 PrepareYOLOv2这次不用改yolo.c源文件了, 只需要修改一些配置文件即可, 大大方便了我们用自己的数据集训练. 首先修改data/voc.names, 另存为data/rob.names: 123ballgoalrobot 修改cfg/voc.data, 另存为cfg/rob.names: 12345classes= 3train = /home/m/data/ROBdevkit/train.txtvalid = /home/m/data/ROBdevkit/2017_test.txtnames = data/rob.namesbackup = /home/m/workspace/backup/ 其次修改script/voc_label.py, 另存为script/rob_label.py: 1234567891011import xml.etree.ElementTree as ETimport pickleimport osfrom os import listdir, getcwdfrom os.path import joinsets = [('2017', 'train'), ('2017', 'val'), ('2017', 'test')]classes = ['ball', 'goal', 'robot']... 然后在ROBdevkit的根目录下执行python rob_label.py来生成 label 文件, 并用cat 2017_* &gt; train.txt生成train.txt. 最终目录结构为: 1234567891011.├── ROBdevkit│ ├── 2017_test.txt│ ├── 2017_train.txt│ ├── 2017_val.txt│ ├── results│ ├── ROB2017│ ├── scripts│ ├── train.txt│ └── VOC0712├── rob_label.py 最后, 修改cfg/voc.data, 另存为cfg/rob.names: 123456789101112131415161718192021222324252627282930diff --git a/cfg/tiny-yolo-voc.cfg b/cfg/tiny-yolo-rob.cfg-- a/cfg/tiny-yolo-voc.cfg++ b/cfg/tiny-yolo-rob.cfg[convolutional]size=1stride=1pad=1-filters=250+filters=40activation=linear[region]anchors = 1.08,1.19, 3.42,4.41, 6.63,11.38, 9.42,5.11, 16.62,10.52bias_match=1-classes=20+classes=3coords=4num=5softmax=1jitter=.2rescore=1object_scale=5noobject_scale=1class_scale=1coord_scale=1absolute=1thresh = .6random=1 注意region的前一层的filter值的计算方法为$num \times (classes+coords+1)$. Train1$ ./darknet detector train cfg/rob.data cfg/tiny-yolo-rob.cfg darknet.conv.weights]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[1Password Problem browser could not be verified]]></title>
      <url>%2F2016%2F12%2F02%2F1Password-Problem-browser-could-not-be-verified%2F</url>
      <content type="text"><![CDATA[最近在 Chrome 上使用 1Password 总是会提示Browser could not be verified, 经过查阅资料解决, 特此记录. 现象如图: 根据官网这篇文章, 应该是 Surge 代理的原因. 只要将127.0.0.1加入到白名单里面就好了. Configure your proxy settings Choose Apple menu () &gt; System Preferences, then click the Network icon. Select your primary network interface (typically Wi-Fi, or Ethernet if you have a wired connection). Click Advanced, then select the Proxies tab. Select Web Proxy (HTTP). Under “Bypass proxy settings for these Hosts &amp; Domains”, click to the right of the existing text, and type a comma followed by 127.0.0.1. Then click OK. If “Secure Web Proxy (HTTPS)” is also enabled, select it, and add 127.0.0.1 as above.]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Train Caffe-YOLO on our own dataset]]></title>
      <url>%2F2016%2F11%2F26%2FTrain-Caffe-YOLO-on-our-own-dataset%2F</url>
      <content type="text"><![CDATA[经过这几天不断地测试, YOLO 在 TX1 上跑得还是挺不错的, 符合我们实验室的要求. 但是 YOLO 依赖的 Darknet 框架还是太原始了, 不如 TensorFlow 或者 Caffe 用着顺手. 另外, 我负责的目标检测这一块还需要和梅老板写的新框架相结合, 所以更加需要把 YOLO 移植到一个成熟的框架上去. 很幸运的是, YOLO 在各个框架上的移植都有前人做过了, 比如 darktf 和 caffe-yolo. 今天以 caffe-yolo 为例, 谈一下在其上使用自己的数据集来训练. Reformat our dataset as PASCAL VOC style为了之后的方便起见, 首先将我们的数据集转成 PASCAL VOC 的标准的目录格式. Structure of PASCAL VOC dataset其目录结构如下: 12345678910111213.├── VOC2007│ ├── Annotations│ ├── ImageSets│ ├── JPEGImages│ ├── SegmentationClass│ └── SegmentationObject└── VOC2012 ├── Annotations ├── ImageSets ├── JPEGImages ├── SegmentationClass └── SegmentationObject 其中Annotations目录放的是.xml文件, JPEGImages目录中存放的是对应的.jpg图像. 由于我们不做语义分割, 所以SegmentationClass与SegmentationObject对我们没什么用. ImageSets目录中结构如下, 主要关注的是Main文件夹中的trainval.txt, train.txt , val.txt以及test.txt四个文件. 123456789101112131415161718192021.├── Layout│ ├── test.txt│ ├── train.txt│ ├── trainval.txt│ └── val.txt├── Main│ ├── aeroplane_test.txt│ ├── aeroplane_train.txt│ ├── aeroplane_trainval.txt│ ├── aeroplane_val.txt│ ├── ...│ ├── test.txt│ ├── train.txt│ ├── trainval.txt│ └── val.txt└── Segmentation ├── test.txt ├── train.txt ├── trainval.txt └── val.txt Reformat our dataset首先是把之前杂乱的图片文件名重新整理, 如下所示: 12345678.├── image00001.jpg├── image00002.jpg├── image00012.jpg├── ...├── image04524.jpg├── image04525.jpg└── image04526.jpg 随后用labelImg重新标注这些图. 标注完成后, 建立我们自己的数据集的结构, 并且将图片和标注放到对应的文件夹里: 1234567891011.├── ROB2017│ ├── Annotations│ ├── ImageSets│ ├── JPEGImages│ └── JPEGImages_original└── scripts ├── clean.py ├── conf.json ├── convert_png2jpg.py └── split_dataset.py 之后写了几个脚本, 其中clean.py用来清理未标注的图片; split_dataset.py用来分割训练集验证集测试集, 并且保存到ImageSets/Main中. 至此, 把我们的数据集转成 PASCAL VOC 标准目录的工作就完成了, 可以进行下一步的训练工作. Train YOLO on CaffeClone &amp; Make1234$ git clone https://github.com/yeahkun/caffe-yolo.git$ cd caffe-yolo$ cp Makefile.config.example Makefile.config$ make -j8 若是出现src/caffe/net.cpp:8:18: fatal error: hdf5.h: No such file or directory这一错误, 可以照下文修改Makefile.config文件: 123456789101112131415diff --git a/Makefile.config b/Makefile.configindex a873502..88828cc 100644--- a/Makefile.config.example+++ b/Makefile.config.example@@ -69,8 +69,8 @@ PYTHON_LIB := /usr/lib # WITH_PYTHON_LAYER := 1 # Whatever else you find you need goes here.-INCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/include-LIBRARY_DIRS := $(PYTHON_LIB) /usr/local/lib /usr/lib+INCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/include /usr/include/hdf5/serial/+LIBRARY_DIRS := $(PYTHON_LIB) /usr/local/lib /usr/lib /usr/lib/x86_64-linux-gnu/hdf5/serial/ # If Homebrew is installed at a non standard location (for example your home directory) and you use it for general dependencies # INCLUDE_DIRS += $(shell brew --prefix)/include 同时还可以开启 cuDNN 以及修改 compute, 充分发挥 GTX1080 的性能: 1234567891011121314151617181920## Refer to http://caffe.berkeleyvision.org/installation.html# Contributions simplifying and improving our build system are welcome!# cuDNN acceleration switch (uncomment to build with cuDNN).-# USE_CUDNN := 1+USE_CUDNN := 1# CPU-only switch (uncomment to build without GPU support).# CPU_ONLY := 1...# CUDA architecture setting: going with all of them.# For CUDA &lt; 6.0, comment the *_50 lines for compatibility.CUDA_ARCH := -gencode arch=compute_20,code=sm_20 \ -gencode arch=compute_20,code=sm_21 \ -gencode arch=compute_30,code=sm_30 \ -gencode arch=compute_35,code=sm_35 \ -gencode arch=compute_50,code=sm_50 \- -gencode arch=compute_50,code=compute_50+ -gencode arch=compute_50,code=compute_50 \+ -gencode arch=compute_61,code=compute_61 Data preparation1234567$ cd data/yolo$ ln -s /your/path/to/VOCdevkit/ .$ python ./get_list.py# change related path in script convert.sh$ sudo rm -r lmdb$ mkdir lmdb$ ./convert.sh 有一些注意点: 记得将ln -s /your/path/to/VOCdevkit/ .中的/your/path/to/VOCdevkit/换成自己数据集的路径, 例如ln -s ~/data/ROBdevkit/ . 修改./get_list.py: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768diff --git a/data/yolo/get_list.py b/data/yolo/get_list.pyindex f519f1a..73b9858 100755--- a/data/yolo/get_list.py+++ b/data/yolo/get_list.py@@ -3,12 +3,15 @@ import os trainval_jpeg_list = [] trainval_xml_list = []-test07_jpeg_list = []-test07_xml_list = []-test12_jpeg_list = []--for name in ["VOC2007", "VOC2012"]:- voc_dir = os.path.join("VOCdevkit", name)+test_jpeg_list = []+test_xml_list = []++for name in ['ROB2017']:+ # voc_dir = os.path.join("VOCdevkit", name)+ voc_dir = os.path.join('ROBdevkit', name) txt_fold = os.path.join(voc_dir, "ImageSets/Main") jpeg_fold = os.path.join(voc_dir, "JPEGImages") xml_fold = os.path.join(voc_dir, "Annotations")@@ -23,35 +26,49 @@ for name in ["VOC2007", "VOC2012"]: print trainval_jpeg_list[-1], "not exist" if not os.path.exists(trainval_xml_list[-1]): print trainval_xml_list[-1], "not exist"- if name == "VOC2007":- file_path = os.path.join(txt_fold, "test.txt")- with open(file_path, 'r') as fp:- for line in fp:- line = line.strip()- test07_jpeg_list.append(os.path.join(jpeg_fold, "&#123;&#125;.jpg".format(line)))- test07_xml_list.append(os.path.join(xml_fold, "&#123;&#125;.xml".format(line)))- if not os.path.exists(test07_jpeg_list[-1]):- print test07_jpeg_list[-1], "not exist"- if not os.path.exists(test07_xml_list[-1]):- print test07_xml_list[-1], "not exist"- elif name == "VOC2012":+ if name == "ROB2017": file_path = os.path.join(txt_fold, "test.txt") with open(file_path, 'r') as fp: for line in fp: line = line.strip()- test12_jpeg_list.append(os.path.join(jpeg_fold, "&#123;&#125;.jpg".format(line)))- if not os.path.exists(test12_jpeg_list[-1]):- print test12_jpeg_list[-1], "not exist"+ test_jpeg_list.append(os.path.join(jpeg_fold, "&#123;&#125;.jpg".format(line)))+ test_xml_list.append(os.path.join(xml_fold, "&#123;&#125;.xml".format(line)))+ if not os.path.exists(test_jpeg_list[-1]):+ print test_jpeg_list[-1], "not exist"+ if not os.path.exists(test_xml_list[-1]):+ print test_xml_list[-1], "not exist" with open("trainval.txt", "w") as wr: for i in range(len(trainval_jpeg_list)): wr.write("&#123;&#125; &#123;&#125;\n".format(trainval_jpeg_list[i], trainval_xml_list[i]))-with open("test_2007.txt", "w") as wr:- for i in range(len(test07_jpeg_list)):- wr.write("&#123;&#125; &#123;&#125;\n".format(test07_jpeg_list[i], test07_xml_list[i]))--with open("test_2012.txt", "w") as wr:- for i in range(len(test12_jpeg_list)):- wr.write("&#123;&#125;\n".format(test12_jpeg_list[i]))+with open("test.txt", "w") as wr:+ for i in range(len(test_jpeg_list)):+ wr.write("&#123;&#125; &#123;&#125;\n".format(test_jpeg_list[i], test_xml_list[i])) 修改convert.sh 12345678910111213141516171819202122232425262728diff --git a/data/yolo/convert.sh b/data/yolo/convert.shindex 8a52525..a06eb69 100755--- a/data/yolo/convert.sh+++ b/data/yolo/convert.sh@@ -1,7 +1,7 @@ #!/usr/bin/env sh CAFFE_ROOT=../..-ROOT_DIR=/your/path/to/vocroot/+ROOT_DIR=/home/m/data/ LABEL_FILE=$CAFFE_ROOT/data/yolo/label_map.txt # 2007 + 2012 trainval@@ -10,13 +10,15 @@ LMDB_DIR=./lmdb/trainval_lmdb SHUFFLE=true # 2007 test-# LIST_FILE=$CAFFE_ROOT/data/yolo/test_2007.txt-# LMDB_DIR=./lmdb/test2007_lmdb+# LIST_FILE=$CAFFE_ROOT/data/yolo/test.txt+# LMDB_DIR=./lmdb/test_lmdb # SHUFFLE=false RESIZE_W=448 RESIZE_H=448 $CAFFE_ROOT/build/tools/convert_box_data --resize_width=$RESIZE_W --resize_height=$RESIZE_H \ --label_file=$LABEL_FILE $ROOT_DIR $LIST_FILE $LMDB_DIR --encoded=true --encode_type=jpg --shuffle=$SHUFFLE 修改label_map.txt: 12345678910111213141516171819202122232425262728diff --git a/data/yolo/label_map.txt b/data/yolo/label_map.txtindex 1fe873a..bee8f82 100644--- a/data/yolo/label_map.txt+++ b/data/yolo/label_map.txt@@ -1,20 +1,3 @@-aeroplane 0-bicycle 1-bird 2-boat 3-bottle 4-bus 5-car 6-cat 7-chair 8-cow 9-diningtable 10-dog 11-horse 12-motorbike 13-person 14-pottedplant 15-sheep 16-sofa 17-train 18-tvmonitor 19+ball 0+goal 1+robot 2 Train1234cd examples/yolo# change related path in script train.shmkdir modelsnohup ./train.sh &amp; 也有一些注意点: 修改gnet_train.prototxt: 12345678910111213diff --git a/examples/yolo/gnet_train.prototxt b/examples/yolo/gnet_train.prototxtindex 8483a32..da01daf 100644--- a/examples/yolo/gnet_train.prototxt+++ b/examples/yolo/gnet_train.prototxt@@ -36,7 +36,7 @@ layer &#123; mean_value: 123 &#125; data_param &#123;- source: "../../data/yolo/lmdb/test2007_lmdb"+ source: "../../data/yolo/lmdb/test_lmdb" batch_size: 1 side: 7 backend: LMDB 修改train.sh: 1234567891011121314diff --git a/examples/yolo/train.sh b/examples/yolo/train.shindex 416e2b0..ecd0872 100755--- a/examples/yolo/train.sh+++ b/examples/yolo/train.sh@@ -3,8 +3,7 @@ CAFFE_HOME=../.. SOLVER=./gnet_solver.prototxt-WEIGHTS=/your/path/to/bvlc_googlenet.caffemodel+WEIGHTS=/home/m/workspace/caffe-yolo/models/bvlc_googlenet/bvlc_googlenet.caffemodel $CAFFE_HOME/build/tools/caffe train \- --solver=$SOLVER --weights=$WEIGHTS --gpu=0,1+ --solver=$SOLVER --weights=$WEIGHTS --gpu=0 注意还要预先下载 GoogleNet 的预训练权重文件, 并且放在caffe-yolo/models/bvlc_googlenet/(当然放哪里是随便的, 注意改train.sh中的相应地址即可). Test123# if everything goes well, the map of gnet_yolo_iter_32000.caffemodel may reach ~56.cd examples/yolo./test.sh model_path gpu_id (To be continued)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Thesis Notes for ScribbleSup]]></title>
      <url>%2F2016%2F11%2F20%2FThesis-Notes-for-ScribbleSup%2F</url>
      <content type="text"><![CDATA[毕设需要写一个图像标注的软件, 来给场景分割的数据集做标注. 经学长推荐, 看了今年的这篇文章, 作者中竟然还有 Kaiming He 大神, 给微软膜一秒. 这篇文章讲了一个弱监督的场景分割的算法 ScribbleSup, 主要是先通过 Graph Cut 将输入的 scribble 信息广播到没有标注的像素, 然后用 FCN 来做像素级别的预测. 令人遗憾的是 Github 上并没有人实现 (不能偷懒了TAT). IntroductionTBD Scribble-Supervised LearningObjective Functions主要用到的记号如下: Symbol Name Note $X$ training image ${x_i}$ set of non-overlapping superpixles $\cup_i x_i = X; x_i \cap x_j = \varnothing, \forall i,j$ $S$ scribble annotations of image $S={s_k, c_k}$ $s_k$ the pixels of a scribble $k$ $c_k$ the scribble’s category label $0 \le c_k \le C$; $c_k=0$ for background $Y$ or ${y_i}$ the category label of ${x_i}$ provides full annotations of the image 定义目标函数为 $$\sum_i \psi_i (y_i | X,S) + \sum_{i,j} \psi_{ij} (y_i, y_j | X)$$ 其中$\psi_i$是一个关于$x_i$的一元项 (unary term), 而$\psi\ _{ij}$是关于$x_i$与$x_j$的成对项 (pairwise term). $\psi _i$由两个部分组成, 一个是$\psi ^{scr}_i$, 另一个是$\psi^{net}_i$.两者权重相同, $\psi _i = \psi^{scr} _i + \psi^{net} _i$. $\psi ^{scr}_i$ 基于 scribble, 定义如下:$$\psi ^{scr}_i=\begin{aligned}&amp;0 &amp; \text{if $y_i=c_k$ and $x_i \cap s_k \ne \varnothing$}\\&amp;-log(\frac{1}{|c_k|}) &amp; \text{if $y_i \in {c_k}$ and $x_i \cap S = \varnothing$} \\&amp;\infty &amp; \text{otherwise} \\\end{aligned}$$ 当$x_i$与$s_k$有交集, 且标签是分到$c_k$时, 则$cost=0$ 当$x_i$与所有 scribble 都没有交集, 则它可以被等概率地分给任何标签. 当然, $y_i$需要在${c_k}$之内. 此处$|{c_k}|$表示标签集内元素个数. 如果不是以上两种情况, 则$cost= \infty$ $\psi ^{net}_i$基于 FCN 的输出, 定义为$$\psi^{net}_i (y_i) = -log P(y_i|X, \Theta)$$ $\Theta$表示网络的参数 $log P(y_i|X, \Theta)$表示了$x_i$属于标签$y_i$的对数概率, 实际上是$x_i$内所有像素的对数概率之和. $\psi_{ij}$用以衡量相邻的两个超像素的相似程度, 主要是用色彩直方图与纹理直方图来量化 (均已归一化).$$\psi_{ij} (y_i, y_j | X) = [y_i \ne y_j] exp \left( -\frac{||h_c(x_i) - h_c(x_j)||^2_2}{\delta_c^2} - \frac{||h_t(x_i) - h_t(x_j)||^2_2}{\delta_t^2} \right)$$ $h_c(x_i)$ 表示RGB三个 channel 每个 channel 分成 25 bins 的色彩直方图 $h_t(x_i)$ 表示横向与纵向的梯度直方图, 每个方向 10 bins $[\cdot]$表示一个符号函数, 条件为真则为$1$, 否则为$0$ $\delta_c=5, \delta_t = 10$ 对于不是同一个标签的临近超像素来说, 它们间的外观越相似, 则 cost 越大 最后把上边这些合起来, 就成了一个对于以下式子进行最优化的问题:$$\sum_i \psi^{scr}_i (y_i |X, S) + \sum_i -log P(y_i | X, \Theta) + \sum_{i,j} \psi_{ij} (y_i, y_j | X)$$其中有两组变量, 一个是所有超像素的标签$Y={y_i}$, 另一个是 FCN 的参数 $\Theta$. Optimization论文里采用的是一种交替优化的方法: $\Theta$固定, 优化$Y$, slover 基于 scribbles, appearance 以及 FCN 网络的预测, 将标签传播到未标记的像素中 $Y$固定, 优化$\Theta$, slover 对 pixel-wise 的语义分割的 FCN 进行学习 具体的来说就是 Propagating scribble information to unmarked pixels 当$\Theta$固定时, 一元项$\psi _i = \psi^{scr} _i + \psi^{net} _i$能够用列举所有可能的标签$0 \le y_i \le C$得到, 成对项也能够预先计算生成一个 look-up table. 因此, 优化问题就能用 graph cut 的方法来解决. 论文里用的是这一篇文章的现成代码. Optimizing network parameters 前一步做完后, 所有超像素的标签都已经定好了, 也就是说$Y$固定了. 之后优化$\Theta$就相当于用$Y$做为监督来训练 FCN. $Y$有了, 那么每个像素的标签就有了, 然后 FCN 面对的就是一个 pixel-wise 的回归问题. FCN 的最后一层输出的就是每个像素的分类的对数概率, 可以用来更新 graph 上的一元项. 训练的时候有几点需要注意: 初始化的时候没有 network prediction, 因此就是直接用 graph cut 初始化的. 之后则是在两步之间不断迭代. 每次 network optimizing step 的时候, 前50k次用0.0003的 learning rate, 后10k次用0.0001的 learning rate, batch size 为 8. 每次 network optimizing step 都是从一个 pre-trained 的 model (比如 VGG-16) 重新初始化的. 作者也试过复用上一次迭代后的权重, 但是效果不是很理想. 似乎是由于本来标签就不可靠, 导致训练的时候参数被调到了不太好的局部最优里面. 基本上3次迭代就能得到比较好的效果了, 再多得到的提升微乎其微. 做验证的时候只要用 FCN 就好了, 超像素和 graph model 之类的都只是用来训练用的. Post-process 用了 CRF. 迭代结果如下: Related WorkGraphical models for segmentationGraphical model 在交互式的图像分割和语义分割领域是很常见的, 通常是目标函数包含了一元项和成对项, 特别适用于对局部和全局的空间约束的建模. 有趣的是, FCN 作为目前最成功的语义分割的方法之一, 由于做的是 pixel-wise 的 regression, 因此其目标函数只有一元项. 不过像 CRF/MRF 这样给 FCN 做 post-processing 或是 joint-training 的方法在之后也发展起来了. 但是这一类 graph model 都是强监督的, 主要工作是在优化 mask 的边缘, 而 ScribbleSup 里面的 graph model 主要是用来把标签传播到其他未标注的像素上. 同时, 这类方法是 pixel-based, 而 ScribbleSup 是 super-pixel-based. Weakly-supervised semantic segmentation用 CNN/FCN 来做弱监督的语义分割的方法很多, 用的标注方法也有很多种. Image-level 的标注很容易获取, 但是只用这个的话精度远低于强监督的结果 Box-level 的相比较而言结果与强监督的接近了不少. 由于 Box annotations 本身就提供了物体边缘以及可信的背景区域的信息, 因此就不需要 graph model 来传播标签. 这些方法和本篇论文里面讲的 ScribbleSup 比起来到底哪个更胜一筹, 姿势水平更高, 就看下面的实验了. ExperimentAnnotating Scribbles主要使用了 PASCAL VOC 2012 (20个分类) 以及 PASCAL-CONTEXT (59个分类) 这两个数据集, 同时也标注了 PASCAL VOC 2007 (标注了59个分类). 不过 2007 没有 mask-level 的标注. 总共有10个人在标注, 每张图片一人标注一人检查. 平均下来20分类的话每张图片25秒, 59分类的话每张图片50秒, 算是相当快的了. 同时, 保证每个 object 上的 scribble 至少有其 bounding box 长边的 70% 以上的长度. Experiments on PASCAL VOC 2012Strategies of utilizing scribblesScribbleSup 是将标签的扩散与网络的训练合起来考虑的, 但是一个更为简单的方案是把这两步分开来, 先用一些现成的工具 (比如说 GrabCut 或者是 LazySnapping) 把 scribble 转换成 mask, 然后再来训练 FCN 网络. 这个方案听起来也是很吼的, 那么中央到底兹不兹瓷呢, 我们来看看实验结果 Method mIoU(%) GrabCut + FCN 49.1 LazySnapping + FCN 53.8 ours, w/o pairwise terms 60.5 ours, w/ pairwise terms 63.1 所以说不要听风就是雨, 可以看出分两步走的方案是一个错误的道路, mIoU显著低于 ScribbleSup. 其中的原因主要是这些传统的方法仅仅针对 low-level 的空间或者是色彩信息建模, 并没有考虑到语义的层面. 也就是说, 这些方法得到的 mask 是不值得信赖的, 不能作为 ground truth 来用. 而 ScribbleSup 就不同了, 通过不断的迭代, FCN 能够逐渐学习到 high-level 的语义特征, 这些特征又能反哺给 graph-based scribble propagation. 这样就形成了一个良性循环, 自然 mIoU 就不知比传统方法高到哪里去了. 同时可以看出, 用了成对项的效果比不用的好. 这是因为如果没有了成对项, 那么目标函数就只剩下了一元项, graph cut 步骤变成了基于network prediction 的 winner-take-all 的模式. 这样的话, 信息的传播就只与全卷积有关, 会过于看重局部一致性, 最终导致准确度降低. Sensitivities to scribble qualityScribble quality 是个非常主观的东西, 所以为了研究这个对于准确度的影响, 论文里采用了将原 scribble 放缩为不同长度 (甚至是一个点), 然后实验来观察. Length ratio mIoU (%) 1 63.1 0.8 61.8 0.5 58.5 0.3 54.3 0 (spot) 51.6 可以看出, ScribbleSup 对于 scribble length 还是比较鲁棒的, 甚至到了一个点都还能有不错的准确度. Comparisons with other weakly-supervised methodsAll methods are trained on the PASCAL VOC 2012 training images using VGG-16, except that the annotations are different. Method Annotations mIoU (%) MIL-FCN image-level 25.1 WSSL image-level 38.2 point supervision spot 46.1 WSSL box 60.6 BoxSup box 62.0 ours spot 51.6 ours scribble 63.1 可以看出 虽然 image-level 的标注很容易标, 但是训练出来的结果惨不忍睹. 同时, 用 scribble 来标注得到的结果准确度很不错, 并且也是相对比较方便的. ScribbleSup 即便是用 spot 标注, 结果的 mIoU 也比 point supervision 高了 5%. Comparisons with using masks虐了一遍同等级的 weakly-supervised 的方法之后, ScribbleSup 开始对比使用 scribble 和使用 mask 得到的结果. (在 PASCAL VOC 2012 上训练) Supervision # w/ masks # w/scribbles total mIoU (%) weakly - 11k 11k 63.1 strongly 11k - 11k 68.5 semi 11k 10k (VOC07) 21k 71.3 使用 scribble 比使用 mask 得到的结果差了5%左右, 考虑到这两者标注的困难程度, 这点差距还是可以忍的. ScribbleSup 其实也是可以用 mask-level 的标注来训练的. 对于 mask-level 的标注, 不使用 graph model, 直接扔到 FCN 的训练里面去就行了. 注意的是这些只能用在 FCN 的训练步骤里, 优化 graph model 这一步骤中不使用. 可以看出, scribble 与 mask 联合起来能达到71.3%的 mIoU, 可以说是非常理想了. Experiments on PASCAL-CONTEXTTo the best of our knowledge, our accuracy is the current state of the art on this dataset. (向dalao低头) Method Data/Annotations mIoU (%) CFM 5k w/ masks 34.4 FCN 5k w/ masks 35.1 Boxsup 5k w/ masks + 133k w/ boxes (COCO+VOC7) 40.5 baseline 5k w/ masks 37.7 ours, weakly 5k w/ scribbles 36.1 ours, weakly 5k w/ scribbles + 10k w/ scribbles (VOC07) 39.3 ours, semi 5k w/ masks + 10k w/ scribbles (VOC07) 42.0 (To be continued…)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Thesis Notes for YOLO]]></title>
      <url>%2F2016%2F11%2F18%2FThesis-Notes-for-YOLO%2F</url>
      <content type="text"><![CDATA[前几天发烧流鼻涕, 睡不了觉, 因此就熬夜读完了 YOLO 的论文. 可以说, YOLO 的实现方式相较于之前 R-CNN 一系的 Region Proposal 的方法来说, 很有新意. YOLO 将 Classification 和 Bounding Box Regression 合起来放进了 CNN 的输出层里面, 从而大大加快了速度. Unified DetectionYOLO 将 Bounding Box 的位置回归和分类都放在了 CNN 的输出层中, 从整张图输入来预测 Bounding Box 的信息, 从而实现了 end-to-end 的训练, 实时的检测性能, 并且还保持了较高的精度. YOLO 将整张图分成了$S\times S$个网格 (论文中$S=2$), 如果一个物体的中心在某个网格内, 那么这个网格就负责预测这个物体的检测. 每个网格需要预测$B$个 Bounding Box (论文中$B=2$), 以及它们的置信度 (confidence). 置信度定义为$Pr(Object) * IOU^{truth}_{pred}$ $Pr(Object)$ 即为有物体的概率, 取0或1 $IOU^{truth}_{pred}$ 即为 ground truth 与predicted box 区域的交并比 每个 Bounding Box 有5个属性$(x,y,w,h,c)$ $(x,y)$ 代表 Bounding Box 的中心距离与网格边界的相对距离, 取值在0与1之间 $x = \frac{x_{max} + x_{min}}{2 * width}$ $y = \frac{y_{max} + y_{min}}{2 * height}$ $(w,h)$ 代表 Bounding Box 的长宽与整个图像长宽的相对比值, 取值在0与1之间 $x = \frac{x_{max} - x_{min}}{width}$ $y = \frac{y_{max} - y_{min}}{height}$ $c$ 即此 Bounding Box 的置信度 每个格子还要预测 $C$ 个类别的概率, 记为$Pr(Class_i|Object)$. 此概率与网格中是否有物体有关, 并且使相对于每个网格来说的, 与网格中的 Bounding Box 数量 $B$ 无关. 测试时, 将 class 的条件概率和 box 的置信度乘起来, 得到每个 box 关于 class 的置信度 $Pr(Class_i|Object) * Pr(Object) * IOU^{truth}_{pred} = Pr(Class_i) * IOU^{truth}_{pred}$ 这个概率既包含了 box 属于哪个 class 的概率, 又包含了这个 box 对于 object 的拟合度 合起来看, 最终的预测张量的维数是 $S\times S \times (B*5 + C)$. 论文里用 PASCAL VOC 数据集, 取$S=7, B=2, C=20$, 因此总计$7\times 7 \times 30$. Network Design 整个网络参考了 GoogleNet, 总共有24个卷积层和两个全连接层. Training为了让整个网络有更好的性能, YOLO 使用了以下 tricks: 前20层卷积层使用 ImageNet 进行 pretrain, 后4层卷积层和两层全连接层则是随机初始化 将输入图像的分辨率从$224\times 224$提升到$448*448$ 将$(x,y,w,h)$全部都归一化 (详见上文) 最后一层(输出层)采用线性激活函数, 其它层都用 Leaky ReLU. 损失函数采用平方和误差(sum-squared error), 并且针对以下问题作出了改进: 8维的 box 的位置信息$(x,y,w,h)$, 2维的置信度信息, 以及20维 box 的类别信息的平方和误差直接放在一起显然是不合理的. 因此增加 box 的位置信息的误差的权重系数$\lambda_{coord}$ (论文内取$5$). 同时, 一个图像会有很多网格没有物体, 那么就会把格子里的 box 的置信度变成 0, 导致那些真正有物体的柜子被压制, 最终导致整个网络发散.因此减少没有物体的 box 的权重系数$\lambda_noobj$ (论文内取$0.5$). 另外, 平方和误差会把 large box 和 small Box 的误差一视同仁. 然而相对于 large box 稍微偏一点, small box 的误差更加不能忍受. 因此使用$(\sqrt{w}, \sqrt{h})$而非$(w,h)$来计算误差. 每个格子里都有多个 Bounding Box, 但是在训练的时候我们希望对于每个物体只有一个 Bounding Box Predictor. 因此就选择与 ground truth 的 IoU 最大的那个, 称对该 box 对 该 object “负责” (responsible). 最终整个的 loss function 如下: $1^{obj}_{ij}$代表第$i$个网格中的第$j$个 box 是否对此 object “负责”, $1^{obj}_i$表示第$i$个网格中是否有 object. 该损失函数仅仅对有物体的网格的分类误差, 以及对 ground truth box 负责的 box 的位置误差进行惩罚 另外还采用了 Dropout 和 Data Augmentation 的方法来增强泛化能力. $Dropout = 0.5$ 对图像进行最大$20\%$的随机缩放和平移变换, 同时还有最大$1.5$的曝光与色调变换 Limitations of YOLO 由于 YOLO 每个网格只有 $B$ 个Bounding Box与1个 Class, 因此限制了临近物体检测到的个数 泛化能力不够, 由于降采样比较多导致只能用比较粗的特征 损失函数主要来源还是定位误差, 在对大小物体的位置误差的均衡上还需要改进.]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Train YOLO on our own dataset]]></title>
      <url>%2F2016%2F11%2F12%2FTrain-YOLO-on-our-own-dataset%2F</url>
      <content type="text"><![CDATA[之前到手 TX1 之后试了一下 YOLO 的 Demo, 感觉很是不错, 帧数勉强达到实时要求, 因此就萌生了使用自己的数据集来训练看看效果的想法. DatasetGet The ImageNet Data为了最大限度地利用资源 (其实是为了偷懒, 但是之后发现给自己挖了个大坑), 我用的是从 ImageNet 上的图片与 Bounding Box 标注. 本次使用了两个类别, 分别是 ball 和 goal. 在Downloads内可以可以下到images in the synset以及Bounding Boxes ImageNet 里的图片看起来多, 实际上摊到每个子类上的就1000多张, 能下下来的就500多, 能直接和 Bounding Box 标注匹配的只剩此案100多了TAT. 果然还是需要自己标注, 自力更生. 另外 ImageNet 上的 Bounding Box 信息只有当前类别的. 比如说我下了 goal 的 Bounding Box, 其实某张图片里还有 ball 等 Object, 但是并不会被标出来. 这对于之后的训练有一定影响. 注意如果要从 ImageNet 上下原始图片的话是需要注册账号, 并且通过邮箱认证的 (还不能是 Gmail 这类的可以免费注册的邮箱, 需要机构或者学校邮箱才行). 下好的文件结构如下: 1234567.├── Annotation│ ├── n03820318│ └── n04254680└── images ├── n03820318 └── n04254680 其中Annotation目录下放标注, images目录下放图片. Convert labels for darknetImageNet 上下下来的 Bounding Box 信息是 Pascal VOC 的 xml 格式: 12345678910111213141516171819202122232425&lt;annotation&gt; &lt;folder&gt;n03820318&lt;/folder&gt; &lt;filename&gt;n03820318_101&lt;/filename&gt; &lt;source&gt; &lt;database&gt;ImageNet database&lt;/database&gt; &lt;/source&gt; &lt;size&gt; &lt;width&gt;500&lt;/width&gt; &lt;height&gt;333&lt;/height&gt; &lt;depth&gt;3&lt;/depth&gt; &lt;/size&gt; &lt;segmented&gt;0&lt;/segmented&gt; &lt;object&gt; &lt;name&gt;n03820318&lt;/name&gt; &lt;pose&gt;Unspecified&lt;/pose&gt; &lt;truncated&gt;0&lt;/truncated&gt; &lt;difficult&gt;0&lt;/difficult&gt; &lt;bndbox&gt; &lt;xmin&gt;19&lt;/xmin&gt; &lt;ymin&gt;43&lt;/ymin&gt; &lt;xmax&gt;499&lt;/xmax&gt; &lt;ymax&gt;214&lt;/ymax&gt; &lt;/bndbox&gt; &lt;/object&gt;&lt;/annotation&gt; 而 darknet 需要的标注文件是 txt 格式: 1&lt;object-class&gt; &lt;x&gt; &lt;y&gt; &lt;width&gt; &lt;height&gt; 于是就需要对于 labels 进行转换. 我写了一份 Python 脚本, 将其放在数据集的根目录下执行即可: 1$ python imagenet_bb_label.py 之后得到目录结构如下: 123456789101112.├── Annotation│ ├── n03820318│ └── n04254680├── imagenet_bb_label.py├── images│ ├── n03820318│ └── n04254680├── labels│ ├── n03820318│ └── n04254680└── train.txt 其中, labels目录保存着转换后的 Bounding Box 信息, train.txt则包含了所有图片文件的绝对路径. ImageNet 的 xml 文件里 object 的名字是类似n03820318这种格式的, 如果需要转成goal这样的话可以再目录下执行以下命令来批量替换: 12&gt; $ find . -name "*.xml" -print | xargs sed -i 's/&lt;name&gt;n03820318/&lt;name&gt;goal/g'&gt; Modify darknet由于 class 的数量和名字都变了, 因此需要修改下 YOLO 的源代码. 首先是从 clone repository. 可以选择 clone 官方的, 也可以直接下我修改好的. 此处里官方 repo 为例. 1$ git clone https://github.com/pjreddie/darknet.git 由于最新的 commit 修改了 label image 的显示方法, 并且改变了源文件里类别的定义, 因此需要先切回之前的 commit: 1$ git checkout 73f7aacf35ec9b1d0f9de9ddf38af0889f213e99 首先修改Makefile: 123GPU=1CUDNN=1OPENCV=1 之后是src/yolo.c, 主要是类别名称和数量, 以及train.txt与backup的地址.(backup目录用来存放训练得到的weights) 1234567891011121314151617181920212223242526// ...#define NUM_CLASS 2char *voc_names[] = &#123;"ball", "goal"&#125;;image voc_labels[NUM_CLASS];void train_yolo(char *cfgfile, char *weightfile)&#123; char *train_images = "/home/m/workspace/dataset/train.txt"; char *backup_directory = "/home/m/workspace/backup/";&#125;// ...void test_yolo(char *cfgfile, char *weightfile, char *filename, float thresh)&#123; // ... draw_detections(im, l.side*l.side*l.n, thresh, boxes, probs, voc_names, voc_labels, NUM_CLASS); // ...&#125;void run_yolo(int argc, char **argv)&#123; // ... for(i = 0; i &lt; NUM_CLASS; ++i)&#123; // ... &#125; // ... else if(0==strcmp(argv[2], "demo")) demo(cfg, weights, thresh, cam_index, filename, voc_names, voc_labels, NUM_CLASS, frame_skip);&#125; 接着是yolo_kernels.cu: 12345678910// ...#define NUM_CLASS 2// ...void *detect_in_thread(void *ptr)&#123; // ... draw_detections(det, l.side*l.side*l.n, demo_thresh, boxes, probs, voc_names, voc_labels, NUM_CLASS); // ...&#125;// ... 然后是cfg(建议新建一个, 我的配置可作为参考): 123456789101112131415161718192021# ...[connected]# output = Side x Side x (2x5 + class_num)output= 588activation=linear[detection]# modify the class numclasses=2coords=4rescore=1side=7num=2softmax=0sqrt=1jitter=.2object_scale=1noobject_scale=.5class_scale=1coord_scale=5 最后, 如果使用了新的 class 的话, 需要在data/labels里修改make_labels.py并执行来生成新的 label image: 123456import osl = ["ball", "goal"]for word in l: os.system("convert -fill black -background white -bordercolor white -border 4 -font ubuntu-mono -pointsize 18 label:\"%s\" \"%s.png\""%(word, word)) 至此前期准备完成, 可以开始训练了. Training首先还需要下载 pre-trained weights. 全尺寸的 YOLO 使用这个 tiny-YOLO 使用这个 之后就是慢慢训练之路了: 123$ cd darknet$ make -j8$ ./darknet yolo train cfg/tiny-yolo.train.cfg darknet.conv.weights 我用上述的 dataset 训练 tiny-YOLO, 从 22:43 一直到 05:12, 总计 6 个小时左右, 最终得到tiny-yolo_final.weights文件. 之后就可以拿来 test 或者 demo 了: 1$ ./darknet yolo test cfg/tiny-yolo.train.cfg tiny-yolo_final.weights or 1$ ./darknet yolo demo cfg/tiny-yolo.train.cfg tiny-yolo_final.weights Results Reference Start Training YOLO with Our Own Data Training YOLO]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[YOLO on NVIDIA Jetson TX1]]></title>
      <url>%2F2016%2F11%2F10%2FYOLO-on-NVIDIA-Jetson-TX1%2F</url>
      <content type="text"><![CDATA[实验室昨天到了 NVIDIA 的 Jetson TX1, 可以说是移动端比较好的带GPU的开发板子了, 于是可以试试在移动端上用YOLO (You Look Only Once) 来做目标识别. Specifications GPU 1 TFLOP/s 256-core with NVIDIA Maxwell™ Architecture CPU 64-bit ARM® A57 CPUs Memory 4 GB LPDDR4, 25.6 GB/s Video decode 4K 60 Hz Video encode 4K 30 Hz CSI Up to 6 cameras, 1400 Mpix/s Display 2x DSI, 1x eDP 1.4, 1x DP 1.2/HDMI Connectivity Connects to 802.11ac Wi-Fi and Bluetooth-enabled devices Networking 1 Gigabit Ethernet PCIE Gen 2 1x1 + 1x4 Storage 16 GB eMMC, SDIO, SATA Other 3x UART, 3x SPI, 4x I2C, 4x I2S, GPIOs 标称1TFlops这个比较猛, 都快比得上XPS 15 9550的GTX960M了. Environment到手TX1之后发现是 Ubuntu 14.04 32-bit 的, 果断先用 JetPack 2.3 升级到 Ubuntu 16.04 64bit. 用 JetPack 刷机的好处是能够顺便配置一大堆库, 比如说 CUDA, cuDNN, OpenCV4Terga 之类的. JetPack 在刷机之前需要下载一大堆 Package, 因此在国内的话最好在运行前配置好代理. JetPack 刷完系统后会要求按 reset 键重启进 GUI, 之后就是不断地安装包安装依赖的过程, 因此在国内的话可以趁此机会修改/etc/apt/source.list: 123456789deb http://mirrors.ustc.edu.cn/ubuntu-ports/ xenial-updates main restricted universe multiversedeb-src http://mirrors.ustc.edu.cn/ubuntu-ports/ xenial-updates main restricted universe multiversedeb http://mirrors.ustc.edu.cn/ubuntu-ports/ xenial-security main restricted universe multiversedeb-src http://mirrors.ustc.edu.cn/ubuntu-ports/ xenial-security main restricted universe multiversedeb http://mirrors.ustc.edu.cn/ubuntu-ports/ xenial-backports main restricted universe multiversedeb-src http://mirrors.ustc.edu.cn/ubuntu-ports/ xenial-backports main restricted universe multiversedeb http://mirrors.ustc.edu.cn/ubuntu-ports/ xenial main universe restricteddeb-src http://mirrors.ustc.edu.cn/ubuntu-ports/ xenial main universe restricteddeb http://mirrors.ustc.edu.cn/ubuntu-ports/ xenial universe 注意arm64的源与普通的x86-64的源是不一样的. Darknet为了用 Webcam demo, 所以需要 Compiling with CUDA and OpenCV: 123456$ git clone https://github.com/pjreddie/darknet.git$ cd darknet$ sed 's/GPU=0/GPU=1/g' Makefile$ sed 's/CUDNN=0/CUDNN=1/g' Makefile$ sed 's/OPENCV=0/OPENCV=1/g' Makefile$ make -j4 上面编译完了之后输入以下指令, 与输出结果相对应, 那就说明成功了 12$ ./darknet$ usage: ./darknet &lt;function&gt; YOLO先去下训练好的权重, 建议选 yolo-tiny 的, 吃内存少. (毕竟 TX1 只有 4GB 内存, 还是 CPU 和 GPU 共用的) 之后运行一下命令即可测试 Real-Time Detection on a Webcam: 1$ ./darknet yolo demo cfg/tiny-yolo.cfg tiny-yolo.weights 实际效果如下: 左下为摄像头实拍屏幕的画面, 可以看出检测结果还是很不错的. 帧数有12fps左右, 基本上达到实时要求. Re-train重新训练 YOLO, 使其识别球与球门. (To be continued…) Reference YOLO: Real-Time Object Detection Start Training YOLO with Our Own Data]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Solution for 'import tensorflow' error in REPL on macOS]]></title>
      <url>%2F2016%2F11%2F02%2FSolution-for-import-tensorflow-error-in-REPL-on-macOS%2F</url>
      <content type="text"><![CDATA[Description使用 pip 安装 Tensorflow 之后, 在 REPL 中执行import tensorflow as tf之后, 报出以下错误: 123456789101112131415161718192021Python 2.7.10 (default, Oct 23 2015, 19:19:21)[GCC 4.2.1 Compatible Apple LLVM 7.0.0 (clang-700.0.59.5)] on darwinType "help", "copyright", "credits" or "license" for more information.&gt;&gt;&gt; import tensorflow as tfTraceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; File "/Library/Python/2.7/site-packages/tensorflow/__init__.py", line 23, in &lt;module&gt; from tensorflow.python import * File "/Library/Python/2.7/site-packages/tensorflow/python/__init__.py", line 53, in &lt;module&gt; from tensorflow.core.framework.graph_pb2 import * File "/Library/Python/2.7/site-packages/tensorflow/core/framework/graph_pb2.py", line 16, in &lt;module&gt; from tensorflow.core.framework import node_def_pb2 as tensorflow_dot_core_dot_framework_dot_node__def__pb2 File "/Library/Python/2.7/site-packages/tensorflow/core/framework/node_def_pb2.py", line 16, in &lt;module&gt; from tensorflow.core.framework import attr_value_pb2 as tensorflow_dot_core_dot_framework_dot_attr__value__pb2 File "/Library/Python/2.7/site-packages/tensorflow/core/framework/attr_value_pb2.py", line 16, in &lt;module&gt; from tensorflow.core.framework import tensor_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__pb2 File "/Library/Python/2.7/site-packages/tensorflow/core/framework/tensor_pb2.py", line 16, in &lt;module&gt; from tensorflow.core.framework import tensor_shape_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__shape__pb2 File "/Library/Python/2.7/site-packages/tensorflow/core/framework/tensor_shape_pb2.py", line 22, in &lt;module&gt; serialized_pb=_b('\n,tensorflow/core/framework/tensor_shape.proto\x12\ntensorflow\"z\n\x10TensorShapeProto\x12-\n\x03\x64im\x18\x02 \x03(\x0b\x32 .tensorflow.TensorShapeProto.Dim\x12\x14\n\x0cunknown_rank\x18\x03 \x01(\x08\x1a!\n\x03\x44im\x12\x0c\n\x04size\x18\x01 \x01(\x03\x12\x0c\n\x04name\x18\x02 \x01(\tB2\n\x18org.tensorflow.frameworkB\x11TensorShapeProtosP\x01\xf8\x01\x01\x62\x06proto3')TypeError: __init__() got an unexpected keyword argument 'syntax' Solution经检查是protobuf的锅. TF 需要protobuf&gt;=3.0.0a3, 而macOS里似乎有两份protobuf, 一份是之前装的2.6.1, 另外一份是随着 TF 装的. 默认似乎是调用到了 2.6.1 的那个版本. 找到原因就好办了, 卸掉重装呗: 1234$ sudo pip uninstall protobuf$ sudo pip uninstall tensorflow$ brew uninstall protobuf$ sudo pip install --upgrade $TF_BINARY_URL 之后就好了, 确认一下是不是调用了3.0.0的版本: 12345&gt;&gt;&gt; import google.protobuf&gt;&gt;&gt; google.protobuf.__file__'/Library/Python/2.7/site-packages/google/protobuf/__init__.pyc'&gt;&gt;&gt; google.protobuf.__version__'3.0.0' Reference Error in python after ‘import tensorflow’: TypeError: init() got an unexpected keyword argument ‘syntax’]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Solution for matplotlib importing error on macOS]]></title>
      <url>%2F2016%2F11%2F01%2FSolution-for-matplotlib-importing-error-on-Mac-OS-X%2F</url>
      <content type="text"><![CDATA[今天在做 CS231n 的 Assignment #2 的时候遇到了导入 matplotlib.pyplot 的问题, 特此记录. Description打开 IPython Notebook 之后, 执行以下命令: 1import matplotlib.pyplot as plt 出现错误: 1ValueError: unknown locale: UTF-8 Solution把下面这些加到~/.zshrc或者是~/.bash_profile里面: 12export LC_ALL=en_US.UTF-8export LANG=en_US.UTF-8 同时, 如果用 iTerm 的话, 还需要在 Preference -&gt; Profiles -&gt; Terminal -&gt; Environment 中, 取消选择 Set locale variables automatically. 然而又出现了下列报错: 1ImportError: cannot import name _thread 这个问题已经在最新的six和dateutil库中解决了, 然而 macOS 本身却还在使用旧版本的库. 解决方法如下: 执行以下命令安装最新版本的six 1$ sudo pip install six -U 开 python 看看是否还在使用旧版本的库: 123&gt;&gt;&gt; import six&gt;&gt;&gt; six.__file__/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/six.pyc 显然确实是这样 删除旧版本的库 1$ rm -rf /System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/six.* 这样就可以了, 之后 python 会使用我们之前新装的版本的six库 123&gt;&gt;&gt; import six&gt;&gt;&gt; six.__file__'/Library/Python/2.7/site-packages/six.pyc' 之后再执行import matplotlib.pyplot as plt之后就没问题了. 说到底还是 macOS 的锅… Reference Mac OS X: ValueError: unknown locale: UTF-8 in Python Matplotlib issue on OS X (“ImportError: cannot import name _thread”)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Thesis Notes for SLIC]]></title>
      <url>%2F2016%2F11%2F01%2FThesis-Notes-for-SLIC%2F</url>
      <content type="text"><![CDATA[文章介绍了当前 State-of-the-Art 的5种超像素 (Superpixel) 的算法, 并主要从其对于图像边缘信息的拟合程度 (their ability to adhere to image boundaries), 速度, 内存利用效率, 以及它们对于图像分割性能的影响 (their impact on segmentation performance) 来综合评价. 同时, 本文还提出了一种 SLIC (simple linear iterative clustering) 的算法, 用的是 k-means clustering 的方法. Introduction超像素算法主要是将一幅图像中, 具有相似颜色, 纹理或者亮度等信息的相邻的像素点聚集起来, 组成一些具有一定视觉意义的像素块, 为后续处理做准备. 这种算法用少量的超像素来代替原来的图像像素, 能够减少图像的冗余度, 为计算图像特征做了很好的铺垫, 并且显著地降低了随后的图像处理步骤的复杂度. 超像素算法作为一个预处理的步骤, 现在已经成为了很多计算机视觉算法中的重要一环, 比如说图像分割 (image segmentation), 深度估计(depth estimation), 姿态预估 (body model estimation) 和目标定位 (object localization) 这些领域. 生成超像素的方法有很多, 各自有各自的优点和缺陷. 在此主要考虑以下方面来评测对比这些算法: 超像素必须保持图像的边缘信息 (Superpixels should adhere well to image boundaries.) 如果超像素是作为一个预处理步骤, 来减少计算复杂度的, 那么就需要考虑计算速度, 内存效率以及是否方便使用等因素 (When used to reduce computational complexity as a pre- processing step, superpixels should be fast to compute, memory efficient, and simple to use.) 同时, 如果超像素算法是为了用来给之后的分割做准备的, 那么就要考虑它是否既能加快速度, 又能提升分割的效果. (When used for segmentation purposes, superpixels should both increase the speed and improve the quality of the results.) Existing Superpixel MethodsGraph-Based Algorithms这类算法主要就是把整个图像看成一张图, 各个像素是节点, 相邻像素之间的相似度作为边上的权值. 超像素就是根据最小化损失函数来构建的. 相关的方法有: NC05: 对边缘的保持不好. 时间复杂度$O(N^{\frac{1}{2}})$ The Normalized cuts algorithm recursively partitions a graph of all pixels in the image using contour and texture cues, globally minimizing a cost function defined on the edges at the partition boundaries. GS04: 对边缘保持较好, 但是生成的超像素大小与形状不规则, 不能严格控制超像素的个数. 时间复杂度$O(NlogN)$ It performs an agglomerative clustering of pixels as nodes on a graph such that each superpixel is the minimum spanning tree of the constituent pixels. SL08: 时间复杂度$O(N^{\frac{3}{2}}logN)$, 但是没有算上预先生成边缘图(boundary map)所耗的时间 Moore et al. propose a method to generate superpixels that conform to a grid by finding optimal paths, or seams, that split the image into smaller vertical or horizontal regions. Optimal paths are found using a graph cuts method similar to Seam Carving. GCa10 &amp; GCb10: Veksler et al. use a global optimization approach similar to the texture synthesis work. Superpixels are obtained by stitching together overlapping image patches such that each pixel belongs to only one of the overlapping regions. They suggest two variants of their method, one for generating compact superpixels (GCa10) and one for constant- intensity superpixels (GCb10). Gradient-Ascent-Based Algorithms这类方法生对像素生成一个随机的初始聚类, 然后不断迭代优化, 直到满足收敛条件. 相关的方法有: MS02: 一种比较老的方法, 生成的超像素形状不规整, 而且对于超像素的数量大小等均不能控制. 同时, 时间复杂度是$O(N^2)$, 非常慢. Mean shift, an iterative mode-seeking procedure for locating local maxima of a density function, is applied to find modes in the color or intensity feature space of an image. Pixels that converge to the same mode define the superpixels. MS02 QS08: 对边界的保持比较好, 但是速度相当慢. 时间复杂度$O(dN^2)$. Quick shift also uses a mode-seeking segmentation scheme. It initializes the segmentation using a medoid shift procedure. It then moves each point in the feature space to the nearest neighbor that increases the Parzen density estimate. WS91: 对边界保持不好, 形状不规整, 不能严格控制超像素的数量, 但是速度快. 时间复杂度$O(NlogN)$. The watershed approach performs a gradient ascent starting from local minima to produce watersheds, lines that separate catchment basins. The TP09: 生成的超像素具有一致的大小, 紧凑性. 宣称时间复杂度$O(N)$, 但是实际上很慢, 而且对边界的保持不好. The Turbopixel method progressively dilates a set of seed locations using level-set-based geometric flow. The geometric flow relies on local image gradients, aiming to regularly distribute superpixels on the image plane. SLIC SuperpixelsSLIC (simple linear iterative clustering) 算法是 k-means 在超像素生成方面的一个改写. 主要有以下特性: 将搜索域限制在与超像素大小成比例的一个区域内, 从而显著减少优化过程中的距离计算量. 此举将复杂度降到了$N$的级别,并且与超像素数量$k$无关. 综合颜色以及空间上的临近关系来构造权边, 同时也能控制超像素的数量. Algorithm 聚类初始化: 按照设定的超像素个数$k$, 采取步长$S=\sqrt{N/k}$, 在图像中均匀采样选取聚类中心$C_i = \begin{bmatrix} l_i &amp; a_i &amp; b_i &amp; x_i &amp; y_i \end{bmatrix}^T$. 然后在聚类中心的$3\times 3$领域内寻找梯度最小的点, 作为新的聚类中心的位置. 图像色彩空间采用 CIELAB 步长$S=\sqrt{N/k}$是为了使得聚类中心分布均匀 移动聚类中心是为了避免把中心建在边缘或者噪点上 像素点分类: 将每个像素点$i$与离其最近并且搜索域覆盖到它的聚类中心相关联. 若是该像素点在多个聚类中心的搜索域内, 则取距离$D$最小的那个作为其关联的聚类中心. 搜索域为$2S\times 2S$ 将搜索域限制在一个较小的范围内, 避免了传统的 k-means 方法里每个像素点要和所有的聚类中心比较的缺点, 使得运行速度大大提高. 这也是本算法速度快的最重要的一个原因. 分类更新: 在所有的像素都已经关联到聚类中心之后, 我们需要调整聚类中心的位置, 使得其位于与其关联的像素点的中心. 这样的分配(assign)然后再更新(update)的步骤可以迭代多次, 直到满足收敛条件为止. 一般来说10次就差不多了 后续处理: 通过将不相交的点分配给相邻的超像素来增强联通性 (enforces connectivity by reassigning disjoint pixels to nearby superpixels). 伪代码如下： 123456789101112131415161718192021/* Initialization */Initialize cluster centers C_k = [l_k, a_k, b_k, x_k, y_k] by sampling pixels at regular grid steps S.Move cluster centers to the lowest gradient position in a 3x3 neighborhood.Set label l(i) = -1 for each pixel i.Set distance d(i) = \infty for each pixel irepeat /* Assignment */ for each cluster center C_k do for each pixel i in a 2Sx2S region around C_k do Compare the distance between C_k and i. if D &lt; d_i then set d(i) = D set l(i) = k end if end for end for /* Update */ Compute new cluster centers. Compute residual error Euntil E &lt;= threshold Distance MeasureSLIC 算法用的是 CIELAB 的色彩空间, 再加上像素本身的坐标, 因此一个像素的全部信息需要用一个5维的向量$\begin{bmatrix} l_i &amp; a_i &amp; b_i &amp; x_i &amp; y_i \end{bmatrix}^T$来表示, 也可以说是在一个$labxy$的图像空间内. $(l, a, b)$表示颜色信息, $(x ,y)$表示位置信息, 因此不能简单地用5维空间的欧氏距离来衡量两个像素之间的距离. 为了统一色彩与空间上的接近程度, 需要引入归一化 (normalization). $d_c = \sqrt{(l_j - l_i)^2 + (a_j - a_i)^2 + (b_j - b_i)^2}$ $d_s = \sqrt{(x_j - x_i)^2 + (y_j - y_i)^2}$ $D’ = \sqrt{(d_c / N_c)^2 + (d_s / N_s)^2}$ 其中$N_c$与$N_s$分别代表最大的色彩与空间距离. $N_s$很好确定, 就是超像素的大小, $N_s = S = \sqrt{N/k}$. 然而$N_c$则根据每个聚类区域的不同而不同, 为了方便起见, 将其设定为一个常数值$m$. 因此距离$D$的定义即可表示为: $D’ = \sqrt{(d_c / m)^2 + (d_s / S)^2}$ 进而可简化为 $D = \sqrt{d_c^2 + (d_s / S)^2 m^2}$ $m$其实也是用来衡量色彩与空间相似度哪个更加重要的标志. $m$较大时, 表示空间相似度更为重要, 产生的超像素会更为紧凑, 区域/边缘比率较低; 当$m$较小时, 表示色彩相似度更为重要, 产生的超像素会紧贴边缘, 但是大小与形状就不会很规整. 一般来说, 使用 CIELAB 色彩空间时, $m \in [1,40]$. 对于灰阶图像, $d_c = \sqrt{(l_j - l_i)^2}$ 对于三维的超体素, $d_s = \sqrt{(x_j - x_i)^2 + (y_j - y_i)^2 + (z_j - z_i)^2}$ PostprocessingSLIC 和其他算法一样并不严格地强制保证连通性 (connectivity). 聚类完成时候, 会有一些与其聚类中心不属于同一个连通单元 (connected component) 的孤立像素存在. 为了对此做出校正, 这些像素会根据某种连通单元算法 (connected components algorithm) 来分配到另外一个最近的聚类中心上. (To be continued…)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Notes for CS231n Recurrent Neural Network]]></title>
      <url>%2F2016%2F10%2F30%2FNotes-for-CS231n-RNN%2F</url>
      <content type="text"><![CDATA[从 RNN 开始, CS231n 的 Lecture Notes 就没有了, 因此我根据上课时的 Slides 整理了一些需要重视的知识点. 还可以参考这些文章或是视频来加深理解: [原创翻译]循环神经网络惊人的有效性（上） [原创翻译]循环神经网络惊人的有效性（下） Recurrent Neural Networks (Video, recommend) Recurrent Neural Network (RNN) (Note of Stanford CS231n) Lecture 10IntroductionRecurrent Networks offer a lot of flexibility: one to one: Vanilla Neural Networks one to many: e.g. Image Captioning (image -&gt; sequence of words) many to one: e.g. Sentiment Classification (sequence of words -&gt; sentiment) many to many: e.g. Machine Translation (seq of words -&gt; seq of words) e.g. Video classification on frame level RNN can also do sequential precessing of fix inputs (Multiple Object Recognition with Visual Attention, Ba et al.) or fixed outputs (DRAW: A Recurrent Neural Network For Image Generation, Gregor et al.). Recurrent Neural NetworkConceptUsually we want to predict a vector at some time steps. To achieve this goal, we can process a sequence of vectors $x$ by applying a recurrence formula at every time step: Notice: the same function and the same set of parameters are used at every time step. That’s to say, we use shared weights. (Vanilla) Recurrent Neural Network The state consists of a single “hidden” vector $h$: $h_t = tanh (W_{hh} h_{t-1} + W_{xh} x_t)$ $y_t = W_{hy} h_t$ Example: Character-level language modelWe have a vocabulary of four characters $\begin{bmatrix} h &amp; e &amp; l &amp; o \end{bmatrix}$, and the example training sequence is “hello”. And we can look its the implement. Data I/O 12345678910111213"""Minimal character-level Vanilla RNN model. Written by Andrej Karpathy (@karpathy)BSD License"""import numpy as np# data I/Odata = open('input.txt', 'r').read() # should be simple plain text filechars = list(set(data))data_size, vocab_size = len(data), len(chars)print 'data has %d characters, %d unique.' % (data_size, vocab_size)char_to_ix = &#123; ch:i for i,ch in enumerate(chars) &#125;ix_to_char = &#123; i:ch for i,ch in enumerate(chars) &#125; Initializations 1234567891011# hyperparametershidden_size = 100 # size of hidden layer of neuronsseq_length = 25 # number of steps to unroll the RNN forlearning_rate = 1e-1# model parametersWxh = np.random.randn(hidden_size, vocab_size)*0.01 # input to hiddenWhh = np.random.randn(hidden_size, hidden_size)*0.01 # hidden to hiddenWhy = np.random.randn(vocab_size, hidden_size)*0.01 # hidden to outputbh = np.zeros((hidden_size, 1)) # hidden biasby = np.zeros((vocab_size, 1)) # output bias Main Loop 1234567891011121314151617181920212223242526272829303132n, p = 0, 0mWxh, mWhh, mWhy = np.zeros_like(Wxh), np.zeros_like(Whh), np.zeros_like(Why)mbh, mby = np.zeros_like(bh), np.zeros_like(by) # memory variables for Adagradsmooth_loss = -np.log(1.0/vocab_size)*seq_length # loss at iteration 0while True: # prepare inputs (we're sweeping from left to right in steps seq_length long) if p+seq_length+1 &gt;= len(data) or n == 0: hprev = np.zeros((hidden_size,1)) # reset RNN memory p = 0 # go from start of data inputs = [char_to_ix[ch] for ch in data[p:p+seq_length]] targets = [char_to_ix[ch] for ch in data[p+1:p+seq_length+1]] # sample from the model now and then if n % 100 == 0: sample_ix = sample(hprev, inputs[0], 200) txt = ''.join(ix_to_char[ix] for ix in sample_ix) print '----\n %s \n----' % (txt, ) # forward seq_length characters through the net and fetch gradient loss, dWxh, dWhh, dWhy, dbh, dby, hprev = lossFun(inputs, targets, hprev) smooth_loss = smooth_loss * 0.999 + loss * 0.001 if n % 100 == 0: print 'iter %d, loss: %f' % (n, smooth_loss) # print progress # perform parameter update with Adagrad for param, dparam, mem in zip([Wxh, Whh, Why, bh, by], [dWxh, dWhh, dWhy, dbh, dby], [mWxh, mWhh, mWhy, mbh, mby]): mem += dparam * dparam param += -learning_rate * dparam / np.sqrt(mem + 1e-8) # adagrad update p += seq_length # move data pointer n += 1 # iteration counter Loss function forward pass (compute loss) backward pass (compute param gradient) 1234567891011121314151617181920212223242526272829303132333435def lossFun(inputs, targets, hprev): """ inputs,targets are both list of integers. hprev is Hx1 array of initial hidden state returns the loss, gradients on model parameters, and last hidden state """ xs, hs, ys, ps = &#123;&#125;, &#123;&#125;, &#123;&#125;, &#123;&#125; hs[-1] = np.copy(hprev) loss = 0 # forward pass for t in xrange(len(inputs)): xs[t] = np.zeros((vocab_size,1)) # encode in 1-of-k representation xs[t][inputs[t]] = 1 hs[t] = np.tanh(np.dot(Wxh, xs[t]) + np.dot(Whh, hs[t-1]) + bh) # hidden state ys[t] = np.dot(Why, hs[t]) + by # unnormalized log probabilities for next chars ps[t] = np.exp(ys[t]) / np.sum(np.exp(ys[t])) # probabilities for next chars loss += -np.log(ps[t][targets[t],0]) # softmax (cross-entropy loss) # backward pass: compute gradients going backwards dWxh, dWhh, dWhy = np.zeros_like(Wxh), np.zeros_like(Whh), np.zeros_like(Why) dbh, dby = np.zeros_like(bh), np.zeros_like(by) dhnext = np.zeros_like(hs[0]) for t in reversed(xrange(len(inputs))): dy = np.copy(ps[t]) dy[targets[t]] -= 1 # backprop into y. see http://cs231n.github.io/neural-networks-case-study/#grad if confused here dWhy += np.dot(dy, hs[t].T) dby += dy dh = np.dot(Why.T, dy) + dhnext # backprop into h dhraw = (1 - hs[t] * hs[t]) * dh # backprop through tanh nonlinearity dbh += dhraw dWxh += np.dot(dhraw, xs[t].T) dWhh += np.dot(dhraw, hs[t-1].T) dhnext = np.dot(Whh.T, dhraw) for dparam in [dWxh, dWhh, dWhy, dbh, dby]: np.clip(dparam, -5, 5, out=dparam) # clip to mitigate exploding gradients return loss, dWxh, dWhh, dWhy, dbh, dby, hs[len(inputs)-1] Sampling 1234567891011121314151617def sample(h, seed_ix, n): """ sample a sequence of integers from the model h is memory state, seed_ix is seed letter for first time step """ x = np.zeros((vocab_size, 1)) x[seed_ix] = 1 ixes = [] for t in xrange(n): h = np.tanh(np.dot(Wxh, x) + np.dot(Whh, h) + bh) y = np.dot(Why, h) + by p = np.exp(y) / np.sum(np.exp(y)) ix = np.random.choice(range(vocab_size), p=p.ravel()) x = np.zeros((vocab_size, 1)) x[ix] = 1 ixes.append(ix) return ixes Gradient Check 1234567891011121314151617181920212223242526# gradient checkingfrom random import uniformdef gradCheck(inputs, target, hprev): global Wxh, Whh, Why, bh, by num_checks, delta = 10, 1e-5 _, dWxh, dWhh, dWhy, dbh, dby, _ = lossFun(inputs, targets, hprev) for param,dparam,name in zip([Wxh, Whh, Why, bh, by], [dWxh, dWhh, dWhy, dbh, dby], ['Wxh', 'Whh', 'Why', 'bh', 'by']): s0 = dparam.shape s1 = param.shape assert s0 == s1, 'Error dims dont match: %s and %s.' % (`s0`, `s1`) print name for i in xrange(num_checks): ri = int(uniform(0,param.size)) # evaluate cost at [x + delta] and [x - delta] old_val = param.flat[ri] param.flat[ri] = old_val + delta cg0, _, _, _, _, _, _ = lossFun(inputs, targets, hprev) param.flat[ri] = old_val - delta cg1, _, _, _, _, _, _ = lossFun(inputs, targets, hprev) param.flat[ri] = old_val # reset old value for this parameter # fetch both numerical and analytic gradient grad_analytic = dparam.flat[ri] grad_numerical = (cg0 - cg1) / ( 2 * delta ) rel_error = abs(grad_analytic - grad_numerical) / abs(grad_numerical + grad_analytic) print '%f, %f =&gt; %e ' % (grad_numerical, grad_analytic, rel_error) # rel_error should be on order of 1e-7 or less Results Using Shakespeare’s sonnet as input: Example: Image CaptioningWe use CNN to recognize objects and use RNN to generate captions. Cut the last two layers from CNN and connect it to RNN: And smaple the output from previous layer to next layer as input: Sampling is stoped when meeting an END Finally, we’ll get a complete sentence (using Microsoft COCO dataset). The first row are good, but the second row may be not satisfactory. Reference: Explain Images with Multimodal Recurrent Neural Networks, Mao et al. Deep Visual-Semantic Alignments for Generating Image Descriptions, Karpathy and Fei-Fei Show and Tell: A Neural Image Caption Generator, Vinyals et al. Long-term Recurrent Convolutional Networks for Visual Recognition andDescription, Donahue et al. Learning a Recurrent Visual Representation for Image CaptionGeneration, Chen and Zitnick More examplesWe can also use RNN to generate open source textbooks written in LaTex, or generate C code from Linux source code, or searching for interpretable cells. Long Short Term Memory (LSTM)Vanishing/Exploding gradients Exploding gradients Truncated BPTT Clip gradients at threshold (something like anti-windup in control science LOL) RMSProp to adjust learning rate Vanishing gradients Harder to detect Weight Initialization ReLU activation functions RMSProp LSTM, GRUs (&lt;– That’s why we use LSTM) IntroductionLSTM is proposed in [Hochreiter et al., 1997]. GRU is a knid of simplified LSTM. ResNet is to PlainNet what LSTM is to RNN, kind of. Concept LSTM have two states, one is cell state ($c$), another is hidden state ($h$): $i$: input gate, “add to memory”, decides whether do we want to add value to this cell. $f$: forget gate, “flush the memory”, decides whether to shut off the cell and reset the counter. $o$: output gate, “get from memory”, decides how much do we want to get from this cell. $g$: input, decides how much do we want to add to this cell. Summary RNNs allow a lot of flexibility inarchitecture design Vanilla RNNs are simple but don’twork very well Common to use LSTM or GRU: theiradditive interactions improve gradient flow Backward flow of gradients in RNNcan explode or vanish. Exploding is controlled with gradient clipping.Vanishing is controlled with additive interactions (LSTM) Better/simpler architectures are ahot topic of current research Better understanding (boththeoretical and empirical) is needed. (To be improved by adding extra materials…)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Traffic Prediction Using LSTM]]></title>
      <url>%2F2016%2F10%2F30%2FTraffic-Prediction-Using-LSTM%2F</url>
      <content type="text"><![CDATA[最近上的一门课 “无线传感器网络” 快要结束了, 于是所谓的大作业的 DDL 也压上来了. TAT 不过这门课虽然说是讲无线传感器网络的, 但是大作业的要求却额外的宽松, 只要是和数据分析有关的就好了. 老师还给了些数据集, 比如说公共自行车的出借与归入记录啊, 出租车在各个路段的行驶速度啊, 或者是顺丰快递途径各个城市需要的时间啊这类的. 当然也可以自己选题. 我当然是想自己选题的, 然而想了一圈没想到什么好的方案, 于是只好回到了老师给的题目上面来, 选了道路速度预测这样的题目. 刚好之前在 CS231n 上看了 RNN 和 LSTM, 心想这总比传统方法好点吧, 于是就开始干了. (于是就有了之前的那篇装 CUDA 和 TF) I wanna traffic prediction, I learn LSTM. ugh, Traffic prediction using LSTM! (此处应有 PPAP) RNN 与 LSTM 基本原理直接看我 CS231n 相关的课程笔记吧 Notes for CS231n Recurrent Neural Network 模型结构详细代码可见我Github上的项目 traffic-prediction. 为了课堂展示我还做了一个pdf, 可以从此处下载. 本次用了两层的 LSTM, 中间加了 Dropout: 输入是一个 4 元素的向量, 分别是星期几, 是否周末, 小时与分钟. $Input = \begin{bmatrix}Weekday &amp; isWeekend &amp; Hour &amp; Minute\end{bmatrix}$ 输出自然是道路上此刻的速度 $Output = \begin{bmatrix} Velocity \end{bmatrix}$ 话说 Keras 竟然能用 graphviz 直接输出模型的结构图, 真是方便 数据集老师给的数据集简直弱爆了, 一条路上总共2000+条数据, 还是按照小时计的, 训练出来的结果惨不忍睹. 于是在网上找到了 Caltrans Performance Measurement System (PeMS) 这个网站, 里面数据是每 5 分钟采样一次的, 比前面的那个不知高到哪里去了. 此次选取的是 16444 路段, 时间是 2016-05-01 到 2016-10-26 总共 6 个月 5W+ 条数据. 结果一天(2016-10-26)和一周(2016.10.20 - 2016.10.26)的预测如下: 可以看出, 总体的趋势还是不错的, 但是高峰的部分还是有些够不上. 同时, 也确实预测到了周末与工作日的速度的区别. matplotlib 可以用 ggplot 的样式, 好看多了 Deeper使用了3层LSTM, MSE有一定下降, 但是高峰期跟不上的问题还是没有解决 改进 加深层数 仔细考虑输入向量的长度和内容, 还可加入假日, 天气等(老师给的数据集有, 但是PeMS没) 使用 Stateful LSTM 的尝试失败了]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[CUDA and Tensorflow Installation on Ubuntu 16.04]]></title>
      <url>%2F2016%2F10%2F25%2FCUDA-and-Tensorflow-Installation-on-Ubuntu-16-04%2F</url>
      <content type="text"><![CDATA[昨天折腾了一个下午开发环境的配置，记录一下其中遇到的坑。 硬件配置我的硬件配置(XPS 15 9550): CPU: i5 6300HQ GPU: GTX960M 2G 内存: 16G DDR4 2133 硬盘: 512G SM951 NVMe 基本上就只处于玩票的状态, 实验室快给我配1080啊~~~ 上一个 NVIDIA 钦定的 DevBox 配置: Name Description GPUs 8x Tesla P100 TFLOPS (GPU FP16 /CPU FP32) 170/3 GPU Memory 16 GB per GPU CPU Dual 20-core Intel® Xeon®E5-2698 v4 2.2 GHz NVIDIA CUDA® Cores 28672 System Memory 512 GB 2133 MHz DDR4 Storage 4x 1.92 TB SSD RAID 0 Network Dual 10 GbE, 4 IB EDR Software Ubuntu Server Linux OSDGX-1 Recommended GPUDriver System Weight 134 lbs System Dimensions 866 D x 444 W x 131 H (mm) Packing Dimensions 1180 D x 730 W x 284 H (mm) Maximum Power Requirements 3200W Operating Temperature Range 10 - 30°C 这简直是吾辈梦想神机啊… 然而要 $129000 ! 系统环境推荐是用 Ubuntu 最新的 LTS 版本 16.04.1, 对 Skylake 系列的 CPU 和主板的支持都很不错. 关于在 XPS 15 9550 上的详细配置过程, 我计划稍后专门写一篇. 本来想在 macOS 上跑的, 奈何黑苹果不支持独显. 安装 CUDACUDA 与 cuDNN 的安装在 NVIDIA 与 Tensorflow的官网上都有详细说明, 此处仅就一些关键环节作出说明. 禁用开源的 Nouveau 驱动 首先看看有没有在使用这个开源驱动: 1$ lsmod | grep nouveau 创建/etc/modprobe.d/blacklist-nouveau.conf文件, 并写入以下内容 12blacklist nouveauoptions nouveau modeset=0 重启kernel initramfs 1$ sudo update-initramfs -u 从ppa源下载最新版的驱动(&gt;364), 或者使用 CUDA-Toolkit 自带的驱动: 1234$ sudo apt-get purge nvidia-*$ sudo add-apt-repository ppa:graphics-drivers/ppa$ sudo apt-get update$ sudo apt-get install nvidia-370 下载 CUDA 的 runfile (local) 版本, 不要使用apt-get 的方式, 保证获取到的是最新的版本 (目前是8.0). 安装过程中, 需要Ctrl+Alt+F1切换到 tty 界面, 然后关闭 X server: 1$ sudo service lightdm stop 之后再执行安装过程 安装过程中, 如果是像我一样的 Intel 核显 + NVIDIA 独显的, 绝对不要装 OpenGL, 否则重启后会陷入 login loop. 安装完成之后, 设置环境变量: 12export LD_LIBRARY_PATH=&quot;$LD_LIBRARY_PATH:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64&quot;export CUDA_HOME=/usr/local/cuda 安装 cuDNN从官网下载之后, 执行以下命令 (目前最新版本5.1): 1234tar xvzf cudnn-8.0-linux-x64-v5.1-ga.tgzsudo cp cuda/include/cudnn.h /usr/local/cuda/includesudo cp cuda/lib64/libcudnn* /usr/local/cuda/lib64sudo chmod a+r /usr/local/cuda/include/cudnn.h /usr/local/cuda/lib64/libcudnn* 安装Tensorflow这是最纠结的一步, 之前按照别人教程说最好从源码编译支持 GPU. 但是由于国内的网络环境, 源码编译需要下一堆的依赖包, 速度超级慢. 因此还是使用官网推荐的 pip 安装方式: 123456789# Get pip$ sudo apt-get install python-pip python-dev# Ubuntu/Linux 64-bit, GPU enabled, Python 2.7# Requires CUDA toolkit 8.0 and CuDNN v5. For other versions, see &quot;Install from sources&quot; below.$ export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.11.0rc1-cp27-none-linux_x86_64.whl# Python 2$ sudo pip install --upgrade $TF_BINARY_URL 可以先把tensorflow-0.11.0rc1-cp27-none-linux_x86_64.whl下下来, 本地执行安装命令 可以使用国内的 pip 源, 加快安装依赖的速度 测试 Tensorflow用下面的小例子来测试下 Tensorflow 安装得成不成功: 123456789101112$ python...&gt;&gt;&gt; import tensorflow as tf&gt;&gt;&gt; hello = tf.constant(&apos;Hello, TensorFlow!&apos;)&gt;&gt;&gt; sess = tf.Session()&gt;&gt;&gt; print(sess.run(hello))Hello, TensorFlow!&gt;&gt;&gt; a = tf.constant(10)&gt;&gt;&gt; b = tf.constant(32)&gt;&gt;&gt; print(sess.run(a + b))42&gt;&gt;&gt; 在 import的同时, 还会显示 CUDA 方面与 GPU 方面的信息. 至此大功告成! Docker for tensorflow其实在这期间还试过直接用装了 Tensorflow 的 Docker 镜像, 也有支持 GPU 的版本. 各位如有兴趣可以试试: Github - Using TensorFlow via Docker Github - An all-in-one Docker image for deep learning. Contains all the popular DL frameworks (TensorFlow, Theano, Torch, Caffe, etc.)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Notes for CS231n Convolutional Neural Network]]></title>
      <url>%2F2016%2F10%2F19%2FNotes-for-CS231n-CNN%2F</url>
      <content type="text"><![CDATA[本文主要对于 CS231n 课程自带的 Lecture Notes 的一些补充与总结. 建议先看原版的 Lecture Notes: Convolutional Neural Networks: Architectures, Convolution / Pooling Layers 或者可以看知乎专栏中的中文翻译: CS231n课程笔记翻译：卷积神经网络笔记 另外, 本文主要根据讲课的 Slides 上的顺序来, 与 Lecture Notes 的顺序略有不同. Lecture 7IntroductionCNN 主要有以下的层(layer): 卷积层 (Conv Layer): 通过不同的 filter 进行卷积操作, 来增加 depth ReLU 层 汇聚层 / 池化层 (Pooling Layer): 进行 down-sampling, 减小空间尺寸 全连接层 (Full-connected Layer): 放在最后进行 classification, 相当于普通的 NN CNN 相对于 NN 来说, 其结构基于输入数据是图像这么一个假设. 基于该假设, 我们就向结构中添加了一些特有的性质. 这些特有属性使得前向传播函数实现起来更高效, 并且大幅度降低了网络中参数的数量. 这也是 CNN 更适用于图像方面的原因. Conv layer主要需要了解以下几个概念: 滤波器(Filter): 又叫卷积核 (Kernel), 尺寸较小 (例如5x5x3). 通过在输入数据上滑动来生成新的 Activation Map / Feature Map. 滤波器的深度须与输入数据的深度一致. 也就是说输入 32x32x3 的图像, 其对应的滤波器的尺寸必须是 FxFx3. 下一层的深度取决于这层用了几个滤波器 滤波器的尺寸又称感受野 (Receptive Field) 步长 (Stride): 即指滤波器每次移动几个像素. 通常步长为奇数. 零填充 (Zero-padding): 用来保证滤波器完整平滑地划过输入数据, 不出现非整数的问题. 同时还能够用来保持输入与输出数据具有相同的尺寸, 即令$P=(F-1)/2$. 如是这般, 宽度与高度不断缩小, 深度不断增加, 信息提取得更为抽象. 总结 输入数据尺寸$W_1 \times H_1 \times D_1$ 需要的超参数 滤波器数量$K$, 通常是2的几次幂, 例如32, 64, 128, 512等 滤波器尺寸$F$, 通常为1, 3, 5等 步长$S$, 通常为1或2 零填充数量$P$ 输出数据尺寸$W_2 \times H_2 \times D_2$ $W_2 = (W_1 - F + 2P) / S + 1$ $H_2 = (H_1 - F + 2P) / S + 1$ (通常$W_1=H_1,W_2=H_2$) $D_2 = K$ 就参数共享来说, 每个滤波器有$F\cdot F\cdot D_1$个权重参数, 总共有$(F\cdot F\cdot D_1)\cdot K$个权重参数 (weights) 和$K$个偏差参数 (biases). 在输出数据体中, 第$d$层 (尺寸$W_2\times H_2$) 深度切片(depth slice)是由第$d$个滤波器在输入数据体上以$S$为补偿进行有效的卷积, 并且偏移了第$d$个偏差之后得到的. 有时候会有$1\times 1\times D$的滤波器, 其也是有效的. 因为它有深度, 实际上进行的是一个$D$维的点积. Pooling layer makes the representations smaller and more manageable operates over each activation map independently 总结 输入数据尺寸$W_1 \times H_1 \times D_1$ 需要的超参数 滤波器尺寸$F$, 通常为2或3 步长$S$, 通常为2 输出数据尺寸$W_2 \times H_2 \times D_2$ $W_2 = (W_1 - F) / S + 1$ $H_2 = (H_1 - F) / S + 1$ (通常$W_1=H_1,W_2=H_2$) $D_2 = D_1$ 由于是固定的计算, 因此没有引入参数. 通常不在汇聚层中使用零填充 Case studyTo be continued…]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Notes for CS231n Neural Network]]></title>
      <url>%2F2016%2F10%2F16%2FNotes-for-CS231n-NN%2F</url>
      <content type="text"><![CDATA[本文主要对于 CS231n 课程自带的 Lecture Notes 的一些补充与总结. 建议先看原版的 Lecture Notes: Neural Networks Part 1: Setting up the Architecture Neural Networks Part 2: Setting up the Data and the Loss Neural Networks Part 3: Learning and Evaluation 或者可以看知乎专栏中的中文翻译: CS231n课程笔记翻译：神经网络笔记1（上） CS231n课程笔记翻译：神经网络笔记1（下） CS231n课程笔记翻译：神经网络笔记2 CS231n课程笔记翻译：神经网络笔记3（上） CS231n课程笔记翻译：神经网络笔记3（下） 另外, 本文主要根据讲课的 Slides 上的顺序来, 与 Lecture Notes 的顺序略有不同. Lecture 5Activation Functions课程中主要讲了Sigmoid, tanh, ReLU, Leaky ReLU, Maxout 以及 ELU 这几种激活函数. Sigmoid 由于以下原因, 基本不使用 函数饱和使得梯度消失(Saturated neurons “kill” the gradients) 函数并非以零为中心(zero-centered) 指数运算消耗大量计算资源 tanh 相对于 Sigmoid 来说, 多了零中心这一个特性, 但还是不常用 重头戏 ReLU (Rectified Linear Unit): 在正半轴上没有饱和现象 线性结构省下了很多计算资源, 可以直接对矩阵进行阈值计算来实现, 速度是 sigmoid/tanh 的6倍 然而由于负半轴直接是0, 训练的时候会”死掉”(die), 因此就有了 Leaky ReLU 和 ELU (Exponential Linear Units), 以及更加通用的 Maxout (代价是消耗两倍的计算资源) 实践中一般就直接选 ReLU, 同时注意 Learning Rate 的调整. 实在不行用 Leaky ReLU 或者 Mahout 碰碰运气. 还可以试试 tanh. 坚决别用 Sigmoid. Data Preprocessing有很多数据预处理的方法, 比如零中心化(zero-centering), 归一化(normalization), PCA(Principal Component Analysis, 主成分分析)和白化(Whitening). 零中心化(zero-centering): 主要方法就是均值减法, 将数据的中心移到原点上 12# Assume X [NxD] is data matrix, each example in a rowX -= np.mean(X, axis=0) 零中心化主要有两种做法(e.g. consider CIFAR-10 example with [32,32,3] images): Subtract the mean image (e.g.AlexNet) (mean image = [32,32,3] array) Subtract per-channel mean (e.g.VGGNet) (mean along each channel = 3 numbers) 归一化(normalization): 使得数据所有维度的范围基本相等, 当然由于图像像素的数值范围本身基本是一致的(一般为0-255), 所以不一定要用. 1X /= np.std(X, axis=0) PCA 和白化在 CNN 中并没有什么用, 就不介绍了. 实践中一般就只做零中心化, 其他几样基本都不用做. 以下引自知乎专栏[智能单元]所翻译的课程讲义: 常见错误。进行预处理很重要的一点是：任何预处理策略（比如数据均值）都只能在训练集数据上进行计算，算法训练完毕后再应用到验证集或者测试集上。例如，如果先计算整个数据集图像的平均值然后每张图片都减去平均值，最后将整个数据集分成训练/验证/测试集，那么这个做法是错误的。应该怎么做呢？应该先分成训练/验证/测试集，只是从训练集中求图片平均值，然后各个集（训练/验证/测试集）中的图像再减去这个平均值。 译者注：此处确为初学者常见错误，请务必注意！ Weight Initialization由于各种原因, 将 Weight 全部初始化为0, 或者是小随机数的方法都不大好(一个是由于对称性, 另一个是由于梯度信号太小). 建议使用的是下面这个(配合 ReLU): 1w = np.random.randn(n) * sqrt(2.0/n) 或者 Xavier initialization: 另外就是还推荐 Batch Normalization (批量归一化), 通常应用在全连接层之后, 激活函数之前. 具体参见论文[Ioffe and Szegedy, 2015]. Improves gradient flow through thenetwork Allows higher learning rates Reduces the strong dependence on initialization Acts as a form of regularization in afunny way, and slightly reduces the need for dropout, maybe Babysitting the Learning ProcessDouble check that the loss is reasonable 首先不使用 regularization, 观察 loss 是否合理(下例中对于 CIFAR-10 的初始 loss 应近似等于$log(0.1)=2.31$) 然后再开启 regularization, 观察 loss 是否上升 Other sanity check tips 首先在一个小数据集上进行训练(可先设 regualrization 为0), 看看是否过拟合, 确保算法的正确性. 之后再从一个小的 regularization 开始, 寻找合适的能够使 loss 下降的 learning rate. 如果几次 epoch 后, loss 没没有下降, 说明 learning rate 太小了 如果 loss 爆炸了, 那么说明 learning rate 太大了 通常 learning rate 的范围是$[1e-3, 1e-5]$ Hyperparameter Optimization 从粗放(coarse)到细致(fine)地分段搜索, 先大范围小周期(1-5 epoch足矣), 然后再根据结果小范围长周期 First stage: only a few epochs to get rough idea of what params work Second stage: longer running time, finer search … (repeat as necessary) If the cost is ever &gt; 3 * original cost, break out early 在对数尺度上进行搜索, 例如learning_rate = 10 ** uniform(-6, 1). 当然有些超参数还是按原来的, 比如 dropout = uniform(0,1) 小心边界上的最优值, 否则可能会错过更好的参数搜索范围. 随机搜索优于网格搜索 Lecture 6Parameter Updates 参数更新有很多种方法, 常见的如下图: 最普通的就是SGD, 仅仅按照负梯度来更新 1x += - learning_rate * dx 其次就是各种动量方法, 比如 Momentum, 以及其衍生的 Nesterov 方法. 其主要思想就是在任何具有持续梯度的方向上保持一个会慢慢消失的动量, 使得梯度下降更为圆滑. 12345678# Momentum updatev = mu * v - learning_rate * dx # integrate velocityx += v # integrate position# Mesterov momentum update rewritev_prev = vv = mu * v - learning_rate * dxx += -mu * v_prev + (1 + mu) * v v 初始为 0 mu 一般取 0.5, 0.9 或 0.99. 有时候可以先 0.5, 然后慢慢变成 0.99 然后就是逐步改 learning rate 的方法, 比如 AdaGrad 或者 RMSProp (Hinton 大神在 Coursera 课上提出的改进方法) 1234567# AdaGradcache += dx**2x += - learning_rate * dx / (np.sqrt(cache) + eps)# RMSPropcache = decay_rate * cache + (1 - decay_rate) * dx**2x += - learning_rate * dx / (np.sqrt(cache) + eps) cache 尺寸与 dx 相同 eps 取值在 1e-4 到 1e-8 之间, 主要是为了防止分母为 0. AdaGrad 通常过早停止学习, RMSProp 通过引入一个梯度平方的滑动平均改善了它. 最后就是集上述方法之大成的 Adam, 在大多数的实践中都是一个很好的选择. 123456789# Adamm ,v = # ... initialize cacahe to zerosfor t in xrange(1, big_number): dx = # ... evaluate gradient m = beta1 * m + (1 - beta1) * dx # update first momentum v = beta2 * v + (1 - beta2) * (dx ** 2) # update second momentum mb = m / (1 - beta1 ** t) # bias correction vb = v / (1 - beta2 ** t) # bias correction x += - learning_rate * mb / (np.sqrt(vb) + 1e-7) # RMSProp-like The bias correction compensates for the fact that m,v are initialized at zero and needsome time to “warm up”. Only relevant in first few iterations when t is small. Learning rate decay主要是为了让 learning rate 随着训练时间的推移慢慢变小, 防止系统动能太大, 到最后在最优点旁边跳来跳去. step decay: e.g. decay learning rate by half every few epochs. exponential decay: $\alpha = \alpha_0 e^{-kt}$ 1/t decay: $\alpha = \alpha_0 / (1+kt)$ Second order optimization methods主要是一些基于牛顿法的二阶最优化方法, 包括 L-BGFS 之类的. 其优点是根本就没有 learning rate 这个超参数, 而缺点则是 Hessian 矩阵实在是太大了, 非常耗费时间与空间, 因此在 DL 和 CNN 中基本不使用. Evaluation: Model Ensembles 训练多个独立的模型, 然后在测试的时候对其结果进行平均, 一般能得到 2% 的额外性能提升; 平均单个模型的多个记录点 (check point) 上的参数, 也能获得一些提升 训练的时候对参数进行平滑操作, 并用于测试集 (keep track of (and use at test time) a running average parameter vector) 123456While True: data_batch = dataset.sample_data_batch() loss = network.forward(data_batch) dx = network.backward() x += - learning_rate * dx x_test = 0.995 * x_test + 0.005 * x # use for test set Regularization (dropout)Dropout 算是很常用的一种方法了, 主要就是在前向传播的时候随机设置某些神经元为零 (“randomly set some neurons to zero in the forward pass”). 其主要想法是让网络具有一定的冗余能力 (Forces the network to have aredundant representation), 或者说是训练出了一个大的集成网络 (Dropout is training a large ensemble of models (that share parameters), each binary mask is one model, gets trained on only ~one datapoint.) 具体实现如下 123456789101112131415161718192021p = 0.5 # probability of keeping a unit active. higher = less dropoutdef train_step(X): """ X contains the datat """ # forward pass for example 3-layer neural network H1 = np.maximum(0, np.dot(W1, X) + b1) U1 = (np.random.rand(*H1.shape) &lt; p) / p # First dropout mask. Notice /p! H1 *= U1 # drop! H2 = np.maximum(0, np.dot(W2, H1) + b2) U2 = (np.random.rand(*H2.shape) &lt; p) / p # Second dropout mask. Notice /p! H2 *= U2 # drop! out = np.dot(W3, H2) + b3 # backward pass: compute geadients ... (not shown) # parameter update... (not shown)def predict(X): # ensembled forward pass H1 = np.maximum(0, np.dot(W1, X) + b1) # no scaling necessary H2 = np.maximum(0, np.dot(W2, H1) + b2) out = np.dot(W3, H2) + b3 Gradient Checking主要就是通过数值法计算梯度, 然后和通过后向传播得到的解析梯度比较, 看看误差大不大, 防止手贱算错梯度导致后面算法全乱了. 用中心化公式$\frac{df(x)}{dx} = \frac{f(x+h - f(x-h)}{2h}$计算数值梯度, $h$取 $1e-5$ 左右. 使用相对误差$\frac{|f^{‘}_a - f^{‘}_n|}{max(|f^{‘}_a|, |f^{‘}_n|)}$ 同时还有些注意事项, 参见 Gradient Checks.]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[B-Human Code 浅析 - ScanGridProvider]]></title>
      <url>%2F2016%2F10%2F08%2FB-Human-Code-Brief-Analysis-2%2F</url>
      <content type="text"><![CDATA[本系列的文章主要是根据 B-Human 的开源代码库CodeRelease2015以及历年的 Team Description Paper 写成. 由于个人的 C++ 水平有限, 难免有缺漏之处, 望发现后不吝赐教. B-Human Code 浅析PerceptionScanGrid首先来看一个基础的类ScanGrid, 里面定义了由扫描线组成的网格. 这个类在ScanGridProvider以及LineScanner 中都有用到. 头文件如下: 123456789101112131415161718192021222324STREAMABLE(ScanGrid,&#123; STREAMABLE(Line, &#123; Line() = default; Line(int x, int y, unsigned yMaxIndex), (int) x, /**&lt; x coordinate of the scanline. */ (int) yMax, /**&lt; Maximum y coordinate (exclusive). */ (unsigned) yMaxIndex, /**&lt; Index of the lowest y coordinate relevant for this scanline. */ &#125;); void draw() const, (std::vector&lt;int&gt;) y, /**&lt; All possible y coordinates of pixels to be scanned. */ (std::vector&lt;Line&gt;) lines, /**&lt; Decription of all scanlines. */ (int)(0) fieldLimit, /**&lt; Upper bound for all scanlines (exclusive). */ (unsigned)(0) lowResStart, /**&lt; First index of low res grid. */ (unsigned)(1) lowResStep, /**&lt; Steps between low res grid lines. */&#125;);inline ScanGrid::Line::Line(int x, int yMax, unsigned yMaxIndex) : x(x), yMax(yMax), yMaxIndex(yMaxIndex)&#123;&#125; 原本的注释已经很清楚了, 我就不再多说什么. ScanGridProvider这个模块主要是提供了一个由一堆竖线组成的扫描图像的网格. 生成的网格可供LineScanner使用. 头文件如下: 1234567891011121314151617181920MODULE(ScanGridProvider,&#123;, REQUIRES(BodyContour), REQUIRES(CameraInfo), REQUIRES(CameraMatrix), REQUIRES(FieldDimensions), PROVIDES(ScanGrid), DEFINES_PARAMETERS( &#123;, (int)(3) minStepSize, /**&lt; The minimum pixel distance between two neigboring scanlines. */ (int)(25) minNumOfLowResScanlines, /**&lt; The minimum number of scanlines for low resolution. */ (float)(0.9f) lineWidthRatio, /**&lt; The ratio of field line width that is sampled when scanning the image. */ (float)(0.8f) ballWidthRatio, /**&lt; The ratio of ball width that is sampled when scanning the image. */ &#125;),&#125;);class ScanGridProvider : public ScanGridProviderBase&#123; void update(ScanGrid&amp; scanGrid);&#125;; 看看具体实现. 首先是一段初始化以及是否继续生成网格的判断: 摄像头参数矩阵未给定 场地边界上的最远点不在视野内 场地边界高度超过图像高度(视野完全在场地之内?) 不能将图像左下与右下两点射影到场地上(视野完全在场地之外?) 12345678910111213141516171819202122232425void ScanGridProvider::update(ScanGrid&amp; scanGrid)&#123; // 初始化网格信息 scanGrid.y.clear(); scanGrid.lines.clear(); if(!theCameraMatrix.isValid) return; // Cannot compute grid without camera matrix // Compute the furthest point away that could be part of the field given an unknown own position. Vector2f pointInImage; const float fieldDiagional = Vector2f(theFieldDimensions.boundary.x.getSize(), theFieldDimensions.boundary.y.getSize()).norm(); if(!Transformation::robotWithCameraRotationToImage(Vector2f(fieldDiagional, 0), theCameraMatrix, theCameraInfo, pointInImage)) return; // Cannot project furthest possible point to image -&gt; no grid in image scanGrid.fieldLimit = std::max(static_cast&lt;int&gt;(pointInImage.y()), -1); if(scanGrid.fieldLimit &gt;= theCameraInfo.height) return; // Image is above field limit -&gt; no grid in image // Determine the maximum distance between scanlines at the bottom of the image not to miss the ball. Vector2f leftOnField; Vector2f rightOnField; if(!Transformation::imageToRobotWithCameraRotation(Vector2i(0, theCameraInfo.height - 1), theCameraMatrix, theCameraInfo, leftOnField) || !Transformation::imageToRobotWithCameraRotation(Vector2i(theCameraInfo.width, theCameraInfo.height - 1), theCameraMatrix, theCameraInfo, rightOnField)) return; // Cannot project lower image border to field -&gt; no grid 接下来是要设置 x 方向的最大步长, 主要的考虑因素是扫描线的最小数量, 以及底部预计球的大小. 123456const int xStepUpperBound = theCameraInfo.width / minNumOfLowResScanlines;const int maxXStep = std::min(xStepUpperBound, static_cast&lt;int&gt;(theCameraInfo.width * theFieldDimensions.ballRadius * 2.f * ballWidthRatio / (leftOnField - rightOnField).norm())); 之后自下而上选取能够用来采样的 y 的值 1234567891011121314151617181920212223Vector2f pointOnField = (leftOnField + rightOnField) / 2.f;// Determine vertical sampling points of the gridscanGrid.y.reserve(theCameraInfo.height);const float fieldStep = theFieldDimensions.fieldLinesWidth * lineWidthRatio;bool singleSteps = false;// scanGrid.fieldLimit: Upper bound for all scanlines (exclusive).for(int y = theCameraInfo.height - 1; y &gt; scanGrid.fieldLimit;)&#123; scanGrid.y.emplace_back(y); // Calc next vertical position for all scanlines. if(singleSteps) --y; else &#123; pointOnField.x() += fieldStep; if(!Transformation::robotWithCameraRotationToImage(pointOnField, theCameraMatrix, theCameraInfo, pointInImage)) break; const int y2 = y; y = std::min(y2 - 1, static_cast&lt;int&gt;(pointInImage.y() + 0.5)); singleSteps = y2 - 1 == y; &#125;&#125; 接下来是要设置 x 方向的最小步长, 主要的考虑因素是图像顶部预计球的大小. 123456789// Determine the maximum distance between scanlines at the top of the image not to miss the ball. Do not go below minStepSize.int minXStep = minStepSize;if(Transformation::imageToRobotWithCameraRotation(Vector2i(0, 0), theCameraMatrix, theCameraInfo, leftOnField) &amp;&amp; Transformation::imageToRobotWithCameraRotation(Vector2i(theCameraInfo.width, 0), theCameraMatrix, theCameraInfo, rightOnField)) minXStep = std::max(minXStep, static_cast&lt;int&gt;(theCameraInfo.width * theFieldDimensions.ballRadius * 2.f * ballWidthRatio / (leftOnField - rightOnField).norm()));minXStep = std::min(xStepUpperBound, minXStep); 然后是确认一个 x 方向的次大步长, 主要是满足$maxXStep2 = minXStep * 2^n, maxXStep2 &lt;= maxXStep$ 123456789101112// Determine a max step size that fulfills maxXStep2 = minXStep * 2^n, maxXStep2 &lt;= maxXStep.// Also compute lower y coordinates for the different lengths of scanlines.int maxXStep2 = minXStep;std::vector&lt;int&gt; yStarts;while(maxXStep2 * 2 &lt;= maxXStep)&#123; float distance = Geometry::getDistanceBySize(theCameraInfo, theFieldDimensions.ballRadius * ballWidthRatio, static_cast&lt;float&gt;(maxXStep2)); VERIFY(Transformation::robotWithCameraRotationToImage(Vector2f(distance, 0), theCameraMatrix, theCameraInfo, pointInImage)); yStarts.push_back(static_cast&lt;int&gt;(pointInImage.y() + 0.5f)); maxXStep2 *= 2;&#125;yStarts.push_back(theCameraInfo.height); 根据上一步计算出的maxXStep2, 建立一个2为比值的等比数列作为扫描线的长度. 123456// Determine a pattern with the different lengths of scan lines, in which the longest appears once,// the second longest twice, etc. The pattern starts with the longest.std::vector&lt;int&gt; yStarts2(maxXStep2 / minXStep);for(size_t i = 0, step = 1; i &lt; yStarts.size(); ++i, step *= 2) for(size_t j = 0; j &lt; yStarts2.size(); j += step) yStarts2[j] = yStarts[i]; 初始化扫描线与颜色区域的信息 123456789101112// Initialize the scan states and the regions.const int xStart = theCameraInfo.width % (theCameraInfo.width / minXStep - 1) / 2;scanGrid.lines.reserve((theCameraInfo.width - xStart) / minXStep);size_t i = yStarts2.size() / 2; // Start with the second longest scanline.for(int x = xStart; x &lt; theCameraInfo.width; x += minXStep)&#123; int yMax = std::min(yStarts2[i++], theCameraInfo.height); i %= yStarts2.size(); theBodyContour.clipBottom(x, yMax); const size_t yMaxIndex = std::upper_bound(scanGrid.y.begin(), scanGrid.y.end(), yMax + 1, std::greater&lt;int&gt;()) - scanGrid.y.begin(); scanGrid.lines.emplace_back(x, yMax, static_cast&lt;unsigned&gt;(yMaxIndex));&#125; 设置低分辨率的扫描线的信息 123// Set low resolution scanline infoscanGrid.lowResStep = maxXStep2 / minXStep;scanGrid.lowResStart = scanGrid.lowResStep / 2;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[B-Human Code 浅析 - LineScanner]]></title>
      <url>%2F2016%2F10%2F07%2FB-Human-Code-Brief-Analysis-1%2F</url>
      <content type="text"><![CDATA[由于 ZJUDancer 组内需要重写视觉相关部分的代码, 因此最近开始看其他组视觉方面的实现. 而 B-Human 是标准组的老牌强队, 常年冠军, 很有借鉴价值. 本系列的文章主要是根据他们的开源代码库CodeRelease2015以及历年的 Team Description Paper 写成. 由于个人的 C++ 水平有限, 难免有缺漏之处, 望发现后不吝赐教. B-Human Code 浅析PerceptionLineScanner The file declares a class that creates colored regions on a single vertical scanline. The class is based on Arne Böckmann’s original implementation of this idea. @author Thomas Röfer 这个类提供了以竖线的形式扫描图像, 并且找出线上具有相同颜色的区域的功能. 对于之后对场地边缘, 球, 机器人, 球门等的检测提供了基础. 在LineScanner.h中的类定义: 1234567891011121314151617181920212223242526class LineScanner&#123;private: const ColorTable&amp; colorTable; const Image&amp; image; const ScanGrid&amp; scanGrid;public: LineScanner(const ColorTable&amp; colorTable, const Image&amp; image, const ScanGrid&amp; scanGrid) : colorTable(colorTable), image(image), scanGrid(scanGrid) &#123;&#125; /** * Scan vertically and add a new scanline with colored regions. * @param line Description of the line to be scanned. * @param top Upper bound for the pixels scanned (exclusive). * @param minColorRatio The ratio of pixels of a different color that is expected * after an edge (relative to the step width). * @param scanlineRegions A new scanline containing the regions found will be added * to this object. */ void scan(const ScanGrid::Line&amp; line, const int top, const float minColorRatio, ScanlineRegions&amp; scanlineRegions) const;&#125;; 主要看scan 这个成员函数. 1void LineScanner::scan(const ScanGrid::Line&amp; line, const int top, const float minColorRatio, ScanlineRegions&amp; scanlineRegions) const &#123;...&#125; 这个函数有四个输入参数, 分别是 要扫描的线line 扫描的上界top 对于不同颜色的区分度的比值minColorRatio(与之后判断隔了几个不同颜色的点的两个区域是否要连在一起有关) 扫描后得到的区域scanlineRegions 然后来看看具体的实现. 首先是一些变量的指定: 12345678910111213141516171819202122void LineScanner::scan(const ScanGrid::Line&amp; line, const int top, const float minColorRatio, ScanlineRegions&amp; scanlineRegions) const&#123; // 当前竖线的横坐标 const int x = line.x; // std::deque::emplace_back Appends a new element to the end of the container. // 在区域 scanlineRegions 的 scanlines 向量容器的最后加一个用 x 初始化的元素. scanlineRegions.scanlines.emplace_back(x); // std::array::back Returns reference to the last element in the container. // 前面新建的元素内的 regions 向量 auto&amp; regions = scanlineRegions.scanlines.back().regions; // 竖线的起始纵坐标指针 // ScanGridProvider.h 实现中 // const size_t yMaxIndex = std::upper_bound(scanGrid.y.begin(), scanGrid.y.end(), yMax + 1, std::greater&lt;int&gt;()) - scanGrid.y.begin(); auto y = scanGrid.y.begin() + line.yMaxIndex; // 竖线的终止纵坐标指针 const auto yEnd = scanGrid.y.end(); // 扫描步长 const int widthStep = image.widthStep; if(y != yEnd &amp;&amp; *y &gt; top &amp;&amp; line.yMax - 1 &gt; top) &#123;...&#125;&#125; 接着是一个条件判断, 主要是看这条竖线能不能用来扫描: 起始纵坐标指针y 是否已经与终止纵坐标指针yEnd重合 起始纵坐标*y是否高于场地上界top 竖线纵坐标最大值yMax 是否高于场地上界top 在这个if语句里面, 我们开始进行对于竖线的颜色扫描与区域生成的工作. 首先还是一些变量的指定, 以及操作完成之后将检测到的: 1234567891011121314151617if(y != yEnd &amp;&amp; *y &gt; top &amp;&amp; line.yMax - 1 &gt; top)&#123; // 前一个点的纵坐标 // ScanGridProvider.h 实现中 int yMax = std::min(yStarts2[i++], theCameraInfo.height); int prevY = line.yMax - 1 &gt; *y ? line.yMax - 1 : *y++; // 当前点的纵坐标 int currentY = prevY + 1; // 前一个点的像素信息 const Image::Pixel* pImg = &amp;image[prevY][x]; // 前一个点的颜色分类 ColorTable::Colors currentColor = colorTable[*pImg]; for(; y != yEnd &amp;&amp; *y &gt; top; ++y) &#123;...&#125; ASSERT(currentY &gt; top + 1); regions.emplace_back(currentY, top + 1, currentColor);&#125; 中间是一个for 循环, 用来遍历竖线上的所有点. 1234567891011121314151617181920212223242526272829303132333435363738for(; y != yEnd &amp;&amp; *y &gt; top; ++y)&#123; // 下一个点的像素信息 pImg += (*y - prevY) * widthStep; // 下一点的颜色分类 const ColorTable::Colors&amp; color = colorTable[*pImg]; // If color changes, determine edge position between last and current scanpoint if(color.colors != currentColor.colors) &#123; // 根据minColorRatio设定不同颜色区域相隔的像素数量阈值 const int otherColorThreshold = std::max(static_cast&lt;int&gt;((prevY - *y) * minColorRatio), 1); // 起始纵坐标向上移阈值个点的纵坐标 const int yMin = std::max(*y - otherColorThreshold + 1, 0); // 不同颜色的像素数量计数器 int counter = 0; // 前两个点的纵坐标 int yy = std::min(prevY - 1, line.yMax - 1); // 遍历从 yy 到 yMin , 计数不同颜色像素的个数 for(const Image::Pixel* pImg2 = pImg + (yy - *y) * widthStep; yy &gt;= yMin &amp;&amp; counter &lt; otherColorThreshold; --yy, pImg2 -= image.widthStep) if(colorTable[*pImg2].colors != currentColor.colors) ++counter; else counter = 0; // Enough pixels of different colors were found: end previous region and start a new one. // 如果发现了足够数量的不同颜色像素, 那么就结束原来的区域, 并开始记录一个新的区域 if(counter == otherColorThreshold) &#123; yy += otherColorThreshold + 1; ASSERT(currentY &gt; yy); regions.emplace_back(currentY, yy, currentColor); currentColor = color; currentY = yy; &#125; &#125; prevY = *y;&#125; (本文中略有缺陷, 待分析了ScanGridProvider之后再做补充)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Notes for Algorithm Design and Analysis - Week 1]]></title>
      <url>%2F2016%2F10%2F06%2FCoursera-Algorithm-Design-Analysis-Week-1%2F</url>
      <content type="text"><![CDATA[IntroductionWhy study Algorithm? important for all other branches of computer science plays a key role in modern technological innovation provides novel “lens” on processes outside of computer science and technology challenging (i.e., good for the brain!) fun Integer Multiplication Input: 2 n-digit numbers $x$ and $y$ Output: product $x*y$ The Grade School Algorithm There’re roughly $n$ operations per row, and we have $n$ rows. So the number of operations overall is about $n^2$. The Algorithm Designer’s Mantra “Perhaps the most important principle for the good algorithm designer is to refuse to be content.” — Aho, Hopcroft, and Ullman, The Design and Analysis of Computer Algorithms, 1974 Can we do better (than the “obvious” method)? Karatsuba MultiplicationA Recursive Algorithm Write $x=10^{n/2}a+b$ and $y=10^{n/2}c+d$ Where $a,b,c,d$ are $n/2$-digit numbers Then $x\cdot y = (10^{n/2}a+b)(10^{n/2}c+d) = 10^n ac + 10^{n/2} (ad+bc) +bd \ \ \ \ (*)$ Idea: recurseively compute $ac, ad, bc, bd$, then compute $(*)$ in the obvious way. Of course, simple base case should be omitted. Karatsuba Multiplication$x\cdot y = 10^n ac + 10^{n/2} (ad+bc) +bd$ Recursively compute $ac$ Recursively compute $bd$ Recursively compute $(a+b)(c+d) = ac+bd+ad+bc$ Gauss’ Trick: $(3)-(1)-(2)=ad+bc$ Upshot: only need 3 recursive multiplications (and some additions) About The CourseCourse Topics Vocabulary for design and analysisof algorithms E.g., “Big Oh” notation “sweet spot” for highGlevel reasoning about algorithms Divide and conquer algorithm design paradigm Will apply to: Integer multiplication, sorting, matrix multiplication, closest pair General analysis methods (“Master Method/Theorem”) Randomization in algorithm design Will apply to: QuickSort, primality testing, graph partitioning, hashing. Primitives for reasoning about graphs Connectivity information, shortest paths, structure of information and social networks. Use and implementation of data structures Heaps, balanced binary search trees, hashing and some variants (e.g., bloom ﬁlters) Topics in Sequel Course Greedy algorithm design paradigm Dynamic programming algorithm design paradigm NP-complete problems and what to do about them Fast heuristics with provable guarantees Fast exact algorithms for special cases Exact algorithms that beat brute-force search Skills You’ll Lean Become a better programmer Sharpen your mathematical and analytical skills Start “thinking algorithmically” Literacy with computer science’s “greatest hits” Ace your technical interviews Who Are You? It doesn’t really matter. (It’s a free course, after all.) Ideally, you know some programming. Doesn’t matter which language(s) you know. But you should be capable of translating high-level algorithm descriptions into working programs in some programming language. Some (perhaps rusty) mathematical experience. Basic discrete math, proofs by induction, etc. Supporting Materials All (annotated) slides available from course site. No required textbook.A few of the many good ones: Kleinberg/Tardos, Algorithm Design, 2005. Dasgupta/Papadimitriou/Vazirani, Algorithms, 2006. Cormen/Leiserson/Rivest/Stein, Introduction to Algorithms, 2009 (3rd edition). Mehlhorn/Sanders, Data Structures and Algorithms: The Basic Toolbox, 2008. No speciﬁc development environment required. But you should be able to write and execute programs. Assessment No grades per se. (Details on a certiﬁcate of accomplishment TBA.) Weekly homeworks. Test understand of material Synchronize students, greatly helps discussion forum Intellectual challenge Assessment tools currently just a “1.0” technology. We’ll do our best! Will sometimes propose harder “challenge problems” Will not be graded; discuss solutions via course forum Merge Sort: Motivation and ExampleWhy Study Merge Sort? Good introduction to divide &amp; conquer Improves over Selection, Insertion, Bubble sorts Calibrate your preparation Motivates guiding principles for algorithm analysis (worst-case and asymptotic analysis) Analysis generalizes to “Master Method” The Sorting Problem Input: array of numbers, unsorted Output: Same numbers, sorted in increasing or decreasing order. Merge Sort: Example]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Redmine configuration on Ubuntu 14.04]]></title>
      <url>%2F2016%2F09%2F15%2FRedmine-Configuration-on-Ubuntu-14-04%2F</url>
      <content type="text"><![CDATA[最近实验室要搞团队协作与项目管理，所以梅老板派我去装个 Redmine。 本文参考了 HowTo Install Redmine on Ubuntu step by step) 这篇官网的文章，并且根据实际情况有所改动。 安装首先自然是安装 Redmine 以及相关依赖： 123$ sudo apt-get install apache2 libapache2-mod-passenger$ sudo apt-get install mysql-server mysql-client$ sudo apt-get install redmine redmine-mysql 只得注意的是，安装 MySQL 的时候会要求设置数据库root用户的密码，这个密码在之后安装 Redmine 的时候需要。 同时注意安装bundler 12$ sudo gem update$ sudo gem install bundler 这时候 Redmine 应该已经可用了，可以到/usr/share/redmine下直接用 WEBrick 来测试 12345678$ sudo bundle exec ruby script/rails server webrick -e production=&gt; Booting WEBrick=&gt; Rails 3.2.16 application starting in production on http://0.0.0.0:3000=&gt; Call with -d to detach=&gt; Ctrl-C to shutdown server[2016-09-15 00:18:34] INFO WEBrick 1.3.1[2016-09-15 00:18:34] INFO ruby 1.9.3 (2013-11-22) [x86_64-linux][2016-09-15 00:18:34] INFO WEBrick::HTTPServer#start: pid=12337 port=3000 能用的话，我们接下来来配置 Apache。 配置 首先打开/etc/apache2/mods-available/passenger.conf，加一行PassengerDefaultUser www-data。之后整个文件看起来是这样： 12345&lt;IfModule mod_passenger.c&gt; PassengerDefaultUser www-data PassengerRoot /usr/lib/ruby/vendor_ruby/phusion_passenger/locations.ini PassengerDefaultRuby /usr/bin/ruby&lt;/IfModule&gt; 然后创建软链接，把 Redmine 的文件目录和 Apache 的根目录连起来 1$ sudo ln -s /usr/share/redmine/public /var/www/html/redmine 接下来编辑/etc/apache2/sites-available/000-default.conf，把以下内容插在&lt;VirtualHost&gt;...&lt;/VirtualHost&gt;之间。 1234&lt;Directory /var/www/html/redmine&gt; RailsBaseURI /redmine PassengerResolveSymlinksInDocumentRoot on&lt;/Directory&gt; 由于我手上的这台服务器的 80 端口被 Gitlab 占着，所以还需要换个端口，比如1234（不要忘了同时修改/etc/apache2/ports.conf中的监听端口号）： 1&lt;VirtualHost *:1234&gt; 同时，还可以设置服务器的地址： 1ServerName localhost 最后改完的/etc/apache2/sites-available/000-default.conf看起来如下： 12345678910111213&lt;VirtualHost *:1234&gt; ServerAdmin webmaster@localhost DocumentRoot /var/www ServerName localhost ErrorLog $&#123;APACHE_LOG_DIR&#125;/error.log CustomLog $&#123;APACHE_LOG_DIR&#125;/access.log combined &lt;Directory /var/www/html/redmine&gt; RailsBaseURI /redmine PassengerResolveSymlinksInDocumentRoot on &lt;/Directory&gt;&lt;/VirtualHost&gt; 创建并修改Gemfile.lock的权限： 12$ sudo touch /usr/share/redmine/Gemfile.lock$ sudo chown www-data:www-data /usr/share/redmine/Gemfile.lock 修改/etc/apache2/apache2.conf，添加一行设置 Passenger 的根目录。不然只能访问到 Redmine 下的文件目录。 1PassengerAppRoot /usr/share/redmine 重启 Apache： 1sudo service apache2 restart 此时已经可以直接通过浏览器访问 http://127.0.0.1:1234 了。 后续配置持续更新中]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Notes for Machine Learning - Week 6]]></title>
      <url>%2F2016%2F09%2F10%2FCoursera-Machine-Learning-Week-6%2F</url>
      <content type="text"><![CDATA[Advice for Applying Machine LearningEvaluating a Learning AlgorithmDeciding What to Try NextErrors in your predictions can be troubleshooted by: Getting more training examples Trying smaller sets of features Trying additional features Trying adding polynomial features Increasing or decreasing $\lambda$ Don’t just pick one of these avenues at random. We’ll explore diagnostic techniques for choosing one of the above solutions in the following sections. In the next few sections, We’ll first talk about how evaluate your learning algorithms and after that we’ll talk about some of these diagnostics which will hopefully let you much more effectively select more of the useful things to try mixing if your goal to improve the machine learning system. Evaluating a HypothesisA hypothesis may have low error for the training examples but still be inaccurate (because of overfitting). And it may fail to generalize to new examples not in training set. With a given dataset of training examples, we can split up the data into two sets: a training set and a test set. (normally 70% for training set and 30% for test set) The training/testing procedure using these two sets is then: Learn $\Theta$ and minimize $J_{train}(\Theta)$ using the training set Compute the test set error $J_{test}(\Theta)$ For linear regression: $J_{test}(\Theta) = \dfrac{1}{2m_{test}} \sum_{i=1}^{m_{test}}(h_\Theta(x^{(i)}_{test}) - y^{(i)}_{test})^2$ For classification ~ Misclassification error (aka 0/1 misclassification error): $err(h_\Theta(x),y) = \begin{cases} 1 &amp; \mbox{if } h_\Theta(x) \geq 0.5\ and\ y = 0\ or\ h_\Theta(x) &lt; 0.5\ and\ y = 1 \\ 0 &amp; otherwise \end{cases}$ This gives us a binary 0 or 1 error result based on a misclassification. The average test error for the test set is $\text{Test Error} = \dfrac{1}{m_{test}} \sum^{m_{test}}_{i=1} err(h_\Theta(x^{(i)}_{test}), y^{(i)}_{test})$ This gives us the proportion of the test data that was misclassified. Model Selection and Train/Validation/Test SetsOnce parameters $\theta _0, \theta _1, \dots , \theta _4$ were fit to some set of data (training set), the error of the parameters as measured on that data (the training error $J(\theta)$ ) is likely to be lower than the actual generalization error. Just because a learning algorithm fits a training set well, that does not mean it is a good hypothesis. The error of your hypothesis as measured on the data set with which you trained the parameters will be lower than any other data set. In order to choose the model of your hypothesis, you can test each degree of polynomial and look at the error result. Without the Validation Set (bad method) Optimize the parameters in $\Theta$ using the training set for each polynomial degree. Find the polynomial degree d with the least error using the test set. Estimate the generalization error also using the test set with $J_{test}(\Theta^{(d)})$, (d = theta from polynomial with lower error); In this case, we have trained one variable, d, or the degree of the polynomial, using the test set. I.e., our extra parameter is fit to the test set. This will cause our error value to be greater for any other set of data. Then the performance of the fitted model on the training set is not predictive of how well the hypothesis will generalize to new examples. Use of the CV set To solve this, we can introduce a third set, the Cross Validation Set (交叉验证集), to serve as an intermediate set that we can train d with. Then our test set will give us an accurate, non-optimistic error. One example way to break down our dataset into the three sets is: Training set: 60% Cross validation set: 20% Test set: 20% We can now calculate three separate error values for the three different sets. With the Validation Set (note: this method presumes we do not also use the CV set for regularization) Optimize the parameters in $\Theta$ using the training set for each polynomial degree. Find the polynomial degree d with the least error using the cross validation set. Estimate the generalization error using the test set with $J_{test}(\Theta^{(d)})$, (d = theta from polynomial with lower error); This way, the degree of the polynomial d has not been trained using the test set. Be aware that using the CV set to select ‘d’ means that we cannot also use it for the validation curve process of setting the lambda value. Bias vs. VarianceDiagnosing Bias vs. VarianceWe’ll examine the relationship between the degree of the polynomial $d$ and the underfitting or overfitting of our hypothesis. We need to distinguish whether bias (偏差) or variance (方差) is the problem contributing to bad predictions. High bias is underfitting and high variance is overfitting. We need to find a golden mean between these two. The training error will tend to decrease as we increase the degree d of the polynomial. At the same time, the cross validation error will tend to decrease as we increase d up to a point, and then it will increase as d is increased, forming a convex curve. High bias (underfitting): both $J_{train}(\Theta)$ and $J_{CV}(\Theta)$ will be high, and $J_{CV}(\Theta) \approx J_{train}(\Theta)$. High variance (overfitting): $J_{train}(\Theta)$ will be low but $J_{CV}(\Theta)$ will be high. And $J_{CV}(\Theta) \gg J_{train}(\Theta)$. Regularization and Bias/VarianceThe relationship of $\lambda$ to the training set and the variance set is as follows: Low $\lambda$ (High variance, overfitting): $J_{train}(\Theta)$ is low and $J_{CV}(\Theta)$ is high (high variance/overfitting). Intermediate λ: $J_{train}(\Theta)$ and $J_{CV}(\Theta)$ are somewhat low and Jtrain(Θ)≈JCV(Θ). Large $\lambda$ (High bias, underfitting): both $J_{train}(\Theta)$ and $J_{CV}(\Theta)$ will be high (underfitting/high bias) A large lambda heavily penalizes all the $\Theta$ parameters, which greatly simplifies the line of our resulting function, so causes underfitting. In order to choose the model and the regularization $\lambda$, we need: Create a list of lambda (i.e. $\lambda \in {0,0.01,0.02,0.04,0.08,0.16,0.32,0.64,1.28,2.56,5.12,10.24}$); Select a lambda to compute; Create a model set like degree of the polynomial or others; Select a model to learn $\Theta$; Learn the parameter $\Theta$ for the model selected, using $J_{train}(\Theta)$ with $\lambda$ selected (this will learn $\Theta$ for the next step); Compute the train error using the learned $\Theta$ (computed with λ ) on the $J_{train}(\Theta)$ without regularization or $\lambda = 0$; Compute the cross validation error using the learned $\Theta$ (computed with λ) on the $J_{CV}(\Theta)​$ without regularization or $\lambda = 0$; Do this for the entire model set and lambdas, then select the best combo that produces the lowest error on the cross validation set; Now if you need visualize to help you understand your decision, you can plot to the figure like above with: ($\lambda$ x Cost $J_{train}(\Theta)$) and ($\lambda$ x Cost $J_{CV}(\Theta)$); Now using the best combo $\Theta$ and $\lambda$, apply it on Jtest(Θ) to see if it has a good generalization of the problem. To help decide the best polynomial degree and $\lambda$ to use, we can diagnose with the learning curves, that is the next subject. Learning CurvesSupposed we use $h_\theta(x) = \theta_0 + \theta_1x + \theta_2x^2$, it’s clear that when $m=1, 2, 3$, we’ll get $0$ errors because we can always find a quadratic curve that exactly touches given points. As the training set gets larger, the error for a quadratic function increases. The error value will plateau out after a certain m, or training set size. High Bias Low training set size: $J_{train}(\Theta)$ will be low and $J_{CV}(\Theta)$ will be high. Large training set size: both $J_{train}(\Theta)$ and $J_{CV}(\Theta)$ will be high with $J_{train}(\Theta) \approx J_{CV}(\Theta)$. If a learning algorithm is suffering from high bias, getting more training data will not (by itself) help much. High Variance Low training set size: $J_{train}(\Theta)$ will be low and $J_{CV}(\Theta)$ will be high. Large training set size: $J_{train}(\Theta)$ increases with training set size and $J_{CV}(\Theta)$ continues to decrease without leveling off. Also, $J_{train}(\Theta) &lt; J_{CV}(\Theta)$ but the difference between them remains significant. If a learning algorithm is suffering from high variance, getting more training data is likely to help.]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Notes for Machine Learning - Week 5]]></title>
      <url>%2F2016%2F08%2F17%2FCoursera-Machine-Learning-Week-5%2F</url>
      <content type="text"><![CDATA[Neural Networks: LearningCost Function and BackpropagationCost FunctionLet’s first define a few variables that we will need to use: $L$ = total number of layers in the network $s_l$ = number of units (not counting bias unit) in layer $l$ $K$ = number of output units/classes Recall that the cost function for regularized logistic regression was: $J(\theta) = - \frac{1}{m} \sum_{i=1}^m \large[ y^{(i)}\ \log (h_\theta (x^{(i)})) + (1 - y^{(i)})\ \log (1 - h_\theta(x^{(i)}))\large] + \frac{\lambda}{2m}\sum_{j=1}^n \theta_j^2$ For neural networks, it is going to be slightly more complicated: $J(\Theta) = - \frac{1}{m} \sum_{i=1}^m \sum_{k=1}^K \left[y^{(i)}_k \log ((h_\Theta (x^{(i)}))_k) + (1 - y^{(i)}_k)\log (1 - (h_\Theta(x^{(i)}))_k)\right] + \frac{\lambda}{2m}\sum_{l=1}^{L-1} \sum_{i=1}^{s_l} \sum_{j=1}^{s_{l+1}} ( \Theta_{j,i}^{(l)})^2$ $h_\Theta (x) \in R^K$, $(h_\Theta (x))_i$ = $i^{th}$ output In the first part of the equation, the double sum simply adds up the logistic regression costs calculated for each cell in the output layer In the regularization part, the triple sum simply adds up the squares of all the individual $\Theta$s in the entire network. The number of columns in our current theta matrix is equal to the number of nodes in our current layer (including the bias unit). The number of rows in our current theta matrix is equal to the number of nodes in the next layer (excluding the bias unit). This is like a bias unit and by analogy to what we were doing for logistic progression, we won’t sum over those terms in our regularization term because we don’t want to regularize them and string their values as zero. Backpropagation Algorithm“Backpropagation” (后向搜索) is neural-network terminology for minimizing our cost function, just like what we were doing with gradient descent in logistic and linear regression. Our goal is try to find parameters $\Theta$ to try to minimize $J(\Theta)$. In order to use either gradient descent or one of the advance optimization algorithms. What we need to do therefore is to write code that takes this input the parameters theta and computes $J(\Theta)$ and $\dfrac{\partial}{\partial \Theta_{i,j}^{(l)}}J(\Theta)$. Gradient compuationGiven one training example $(x,y)$ Forward propagation: $a^{(1)} = x$ $z^{(2)} = \Theta ^{(1)} a ^{(1)}$ $a^{(2)} = g(z^{(2)})\ (add\ a^{(2)}_0)$ $z^{(3)} = \Theta ^{(1)} a ^{(2)}$ $a^{(3)} = g(z^{(3)})\ (add\ a^{(3)}_0)$ $z^{(4)} = \Theta ^{(3)} a ^{(3)}$ $a^{(2)} = h_\Theta (x) = g(z^{(3)})$ In backpropagation we’re going to compute for every node: $\delta_j^{(l)}$ = “error” of node j in layer $l$ ($s_{l+1}$ elements vector) For each output unit (layer $L = 4$): $\delta ^{(4)} = a^{(4)} - y$ To get the delta values of the layers before the last layer, we can use an equation that steps us back from right to left: $\delta^{(l)} = ((\Theta^{(l)})^T \delta^{(l+1)})\ .*\ g’(z^{(l)})$ The g-prime derivative terms can also be written out as: $g’(z^{(l)}) = a^{(l)}\ .*\ (1 - a^{(l)})$ There is no $\delta ^{(1)}$ term, because the first layer corresponds to the input layer and that’s just the feature we observed in our training sets, so that doesn’t have any error associated with that. It’s possible to prove that if you ignore regularation, then the partial derivative terms you want are exactly given by the activations and these delta terms. $\dfrac{\partial J(\Theta)}{\partial \Theta_{i,j}^{(l)}} = a^{(i)}_j \delta^{(l+1)}_i\ (\text{ignoring }\lambda)$ Backpropagation Algorithm Training set $\lbrace (x^{(1)}, y^{(1)}) \cdots (x^{(m)}, y^{(m)})\rbrace$ Set $\Delta^{(l)}_{i,j} := 0$ (for all $l, i, j$) For $i=1$ to $m$ Set $a^{(1)} := x^{(t)}$ Perform forward propagation to compute $a^{(l)}$ for $l = 2,3,\dots ,L$ Using $y^{(i)}$, compute $\delta^{(L)} = a^{(L)} - y^{(t)}$ Compute $\delta^{(L-1)}, \delta^{(L-2)},\dots,\delta^{(2)}$ $\Delta^{(l)}_{i,j} := \Delta^{(l)}_{i,j} + a_j^{(l)} \delta_i^{(l+1)}$ or with vectorization, $\Delta^{(l)} := \Delta^{(l)} + \delta^{(l+1)}(a^{(l)})^T$ $D^{(l)}_{i,j} := \dfrac{1}{m}\left(\Delta^{(l)}_{i,j} + \lambda\Theta^{(l)}_{i,j}\right)$ If $j\ne 0$ $D^{(l)}_{i,j} := \dfrac{1}{m}\Delta^{(l)}_{i,j}$ If $j = 0$ The capital-delta matrix is used as an “accumulator” to add up our values as we go along and eventually compute our partial derivative. the $D_{i,j}^{(l)}$ terms are the partial derivatives and the results we are looking for: $\dfrac{\partial J(\Theta)}{\partial \Theta_{i,j}^{(l)}} = D_{i,j}^{(l)}$ Backpropagation IntuitionForward propagation What’s backpropagation doing?The cost function is: $J(\theta) = - \frac{1}{m} \sum_{t=1}^m\sum_{k=1}^K \left[ y^{(t)}_k \ \log (h_\theta (x^{(t)}))_k + (1 - y^{(t)}_k)\ \log (1 - h_\theta(x^{(t)})_k)\right] + \frac{\lambda}{2m}\sum_{l=1}^{L-1} \sum_{i=1}^{s_l} \sum_{j=1}^{s_l+1} ( \theta_{j,i}^{(l)})^2$ Focusing on a single example $x^{(i)}, y^{(i)}$, the case of 1 output unit, and ignoring regularization ($\lambda = 0$), $cost(t) =y^{(t)} \ \log (h_\theta (x^{(t)})) + (1 - y^{(t)})\ \log (1 - h_\theta(x^{(t)}))$ Intuitively, $\theta ^{(l)}_j$ is the “error” for $a ^{(l)}_j$ (unit $j$ in layer $l$). More formally, the delta values are actually the derivative of the cost function: $\delta_j^{(l)} = \dfrac{\partial}{\partial z_j^{(l)}} cost(t)$ In above, we can compute $\delta ^{(4)}_1 = y^{(i)} - a^{(4)}_1$ $\delta ^{(3)}_2 = \Theta ^{(3)}_{12} \delta^{(4)}_1$ $\delta ^{(2)}_2 = \Theta ^{(2)}_{12} \delta^{(3)}_1 + \Theta ^{(2)}_{22} \delta^{(3)}_2$ Backpropagation in PracticeImplementation Note: Unrolling ParametersWe use following code to get the optimisation theta. 123function [jVal, gradient] = costFunction(theta) ...optTheta = fminunc(@costFunction, initialTheta, options) Where gradient, theta, initialTheta are vectors of $n+1$ dimension. In order to use optimizing functions such as fminunc(), we will want to “unroll” all the elements and put them into one long vector: 12thetaVec = [Theta1(:); Theta2(:); Theta3(:)];DVec = [D1(:); D2(:); D3(:)]; If the dimensions of Theta1 is $10\times11$, Theta2 is $10\times 11$ and Theta3 is $1\times 11$, then we can get back our original matrices from the “unrolled” versions as follows: 123Theta1 = reshape(thetaVector(1:110),10,11)Theta2 = reshape(thetaVector(111:220),10,11)Theta3 = reshape(thetaVector(221:231),1,11) Gradient CheckingGradient checking will assure that our backpropagation works as intended. Numerical estimation of gradients We can approximate the derivative of our cost function with: $\dfrac{\partial}{\partial\Theta}J(\Theta) \approx \dfrac{J(\Theta + \epsilon) - J(\Theta - \epsilon)}{2\epsilon}$ Implement 1gradApprox = (J(theta + EPSILON) - J(theta - EPSILON)) / (@ * EPSILON); Gradient CheckingWith multiple theta matrices, we can approximate the derivative with respect to $\Theta _J$ as follows: $\dfrac{\partial}{\partial\Theta_j}J(\Theta) \approx \dfrac{J(\Theta_1, \dots, \Theta_j + \epsilon, \dots, \Theta_n) - J(\Theta_1, \dots, \Theta_j - \epsilon, \dots, \Theta_n)}{2\epsilon}$ A good small value for ϵ (epsilon), guarantees the math above to become true. If the value be much smaller, may we will end up with numerical problems. The professor Andrew usually uses the value $\epsilon = 10^{-4}$. Implement 12345678epsilon = 1e-4;for i = 1 : n, thetaPlus = theta; thetaPlus(i) += epsilon; thetaMinus = theta; thetaMinus(i) -= epsilon; gradApprox(i) = (J(thetaPlus) - J(thetaMinus))/(2*epsilon)end; We then want to check that gradApprox $\approx$ deltaVector. Implement Note Implement backprop to compute DVec (unrolled $D^{(1)}, D^{(2)}, D^{(3)}$). Implement numerical gradient check to compute gradApprox. Make sure they give similar values. Turn off gradient checking. Using backprop code for learning. Important Be sure to disable your gradient checking code before training your classifier. If you run numerical gradient computation on every iteration of gradient descent (or in the inner loop of costFunction(...)), your code will be very slow. Random InitializationInitializing all theta weights to zero does not work with neural networks. When we backpropagate, all nodes will update to the same value repeatedly. Instead we can randomly initialize our weights to break symmetry. Initialize each $\Theta^{(l)}_{ij}$ to a random value between $[-\epsilon, \epsilon]$ $\epsilon = \dfrac{\sqrt{6}}{\sqrt{\mathrm{Loutput} + \mathrm{Linput}}}$ $\Theta^{(l)} = 2\epsilon\ rand(Loutput, Linput+1)-\epsilon$ 12345% If the dimensions of Theta1 is 10x11, Theta2 is 10x11 and Theta3 is 1x11.Theta1 = rand(10,11) * (2 * INIT_EPSILON) - INIT_EPSILON;Theta2 = rand(10,11) * (2 * INIT_EPSILON) - INIT_EPSILON;Theta3 = rand(1,11) * (2 * INIT_EPSILON) - INIT_EPSILON; Note: this epsilon is unrelated to the epsilon from Gradient Checking Putting It TogetherFirst, pick a network architecture; choose the layout of your neural network, including how many hidden units in each layer and how many layers total. Number of input units = dimension of features $x^{(i)}$ Number of output units = number of classes Number of hidden units per layer = usually more the better (must balance with cost of computation as it increases with more hidden units) Defaults: 1 hidden layer. If more than 1 hidden layer, then the same number of units in every hidden layer. Training a Neural Network Randomly initialize the weights Implement forward propagation to get $h_\theta(x^{(i)})$ Implement the cost function Implement backpropagation to compute partial derivatives Use gradient checking to confirm that your backpropagation works. Then disable gradient checking. Use gradient descent or a built-in optimization function to minimize the cost function with the weights in theta. When we perform forward and back propagation, we loop on every training example: 123for i = 1:m, Perform forward propagation and backpropagation using example (x(i),y(i)) (Get activations a(l) and delta terms d(l) for l = 2,...,L Quiz You are training a three layer neural network and would like to use backpropagation to compute the gradient of the cost function. In the backpropagation algorithm, one of the steps is to update $\Delta^{(2)}{ij} := \Delta^{(2)}{ij} + \delta^{(3)}_i * (a^{(2)})_j$ for every $i,j$. Which of the following is a correct vectorization of this step? $\Delta(2) :=\Delta(2)+(a(3))^T \ast\delta(2)$ $\Delta(2) :=\Delta(2)+\delta(3) \ast (a(3))^T$ $\Delta(2) :=\Delta(2)+(a(2))^T \ast \delta(3)$ $\Delta(2) :=\Delta(2)+\delta(3) \ast (a(2))^T$ Suppose Theta1 is a $5\times 3$ matrix, and Theta2 is a $4\times 6$ matrix. You set thetaVec=[Theta1(:);Theta2(:)]. Which of the following correctly recovers Theta2? reshape(thetaVec(16:39),4,6) reshape(thetaVec(15:38),4,6) reshape(thetaVec(16:24),4,6) reshape(thetaVec(15:39),4,6) reshape(thetaVec(16:39),6,4) Let $J(\theta) = 3\theta^3 + 2$. Let $\theta=1$, and $\epsilon=0.01$. Use the formula $\frac{J(\theta+\epsilon)-J(\theta-\epsilon)}{2\epsilon}$ to numerically compute an approximation to the derivative at $\theta=1$. What value do you get? (When $\theta=1$, the true/exact derivative is $ \frac{d J(\theta)}{ d\theta}=9$.) 9 8.9997 11 9.0003 Which of the following statements are true? Check all that apply. Computing the gradient of the cost function in a neural network has the same efficiency when we use backpropagation or when we numerically compute it using the method of gradient checking. For computational efficiency, after we have performed gradient checking to verify that our backpropagation code is correct, we usually disable gradient checking before using backpropagation to train the network. Using gradient checking can help verify if one’s implementation of backpropagation is bug-free. Gradient checking is useful if we are using one of the advanced optimization methods (such as in fminunc) as our optimization algorithm. However, it serves little purpose if we are using gradient descent. Using a large value of $\lambda$ cannot hurt the performance of your neural network; the only reason we do not set $\lambda$ to be too large is to avoid numerical problems. If our neural network overfits the training set, one reasonable step to take is to increase the regularization parameter $\lambda$. Gradient checking is useful if we are using gradient descent as our optimization algorithm. However, it serves little purpose if we are using one of the advanced optimization methods (such as in fminunc). Which of the following statements are true? Check all that apply. Suppose that the parameter $\theta(1)$ is a square matrix (meaning the number of rows equals the number of columns). If we replace $\theta(1)$ with its transpose ($\theta(1)^T$), then we have not changed the function that the network is computing. Suppose we have a correct implementation of backpropagation, and are training a neural network using gradient descent. Suppose we plot $J(\theta)$ as a function of the number of iterations, and find that it is increasing rather than decreasing. One possible cause of this is that the learning rate $\alpha$ is too large. If we are training a neural network using gradient descent, one reasonable “debugging” step to make sure it is working is to plot $J(\theta)$ as a function of the number of iterations, and make sure it is decreasing (or at least non-increasing) after each iteration. Suppose we are using gradient descent with learning rate $\alpha$. For logistic regression and linear regression, $J(\theta)$ was a convex optimization problem and thus we did not want to choose a learning rate $\alpha$ that is too large. For a neural network however, $J(\theta)$ may not be convex, and thus choosing a very large value of $\alpha$ can only speed up convergence. Suppose you have a three layer network with parameters $\theta(1)$ (controlling the function mapping from the inputs to the hidden units) and $\theta(2)$ (controlling the mapping from the hidden units to the outputs). If we set all the elements of $\theta(1)$ to be 0, and all the elements of $\theta(2)$ to be 1, then this suffices for symmetry breaking, since the neurons are no longer all computing the same function of the input. If we initialize all the parameters of a neural network to ones instead of zeros, this will suffice for the purpose of “symmetry breaking” because the parameters are no longer symmetrically equal to zero.]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Notes for Machine Learning - Week 4]]></title>
      <url>%2F2016%2F08%2F15%2FCoursera-Machine-Learning-Week-4%2F</url>
      <content type="text"><![CDATA[Neural Networks: RepresentationMotivationsNon-linear HypothesesPerforming linear regression with a complex set of data with many features is very unwieldy. For 100 features, if we wanted to make them quadratic we would get 5050 resulting new features. We can approximate the growth of the number of new features we get with all quadratic terms with $\mathcal{O}(n^2/2)$. And if you wanted to include all cubic terms in your hypothesis, the features would grow asymptotically at $\mathcal{O}(n^3)$. These are very steep growths, so as the number of our features increase, the number of quadratic or cubic features increase very rapidly and becomes quickly impractical. Example: let our training set be a collection of 50x50 pixel black-and-white photographs, and our goal will be to classify which ones are photos of cars. Our feature set size is then n=2500 if we compare every pair of pixels (7500 if RGB). Now let’s say we need to make a quadratic hypothesis function. With quadratic features, our growth is $\mathcal{O}(n^2/2)$. So our total features will be about 25002/2=3125000, which is very impractical. Neurons and the BrainOrigins: Algorithms that try to mimic the brain. Was very widely used in 80s and early 90s; popularity diminished in late 90s. Recent resurgence: State-of-the-art technique for mant applications The “one learning algorithm” hypothesisThere is evidence that the brain uses only one “learning algorithm” for all its different functions. Scientists have tried cutting (in an animal brain) the connection between the ears and the auditory cortex and rewiring the optical nerve with the auditory cortex to find that the auditory cortex literally learns to see. Neural NetworksModel Representation INeuron in the brainAt a very simple level, neurons are basically computational units that take input (dendrites, 树突) as electrical input (called “spikes”) that are channeled to outputs (axons, 轴突). Neuron model: Logistic unit In our model, our dendrites are like the input features ($x_1 \cdots x_n$), and the output is the result of our hypothesis function $h_\theta (x)$: In this model our $x_0$ input node is sometimes called the “bias unit.” It is always equal to 1. In neural networks, we use the same logistic function as in classification: $\frac{1}{1 + e^{-\theta^Tx}}$. In neural networks however we sometimes call it a sigmoid (logistic) activation function. Our $\theta$ parameters are sometimes instead called “weights“ in the neural networks model. Neural Network The first layer is called the “input layer“ and the final layer the “output layer“, which gives the final value computed on the hypothesis. We can have intermediate layers of nodes between the input and output layers called the “hidden layer“. $a_i^{(j)}$ = “activation” of unit $i$ in layer $j$ $a_1^{(2)} = g(\Theta_{10}^{(1)}x_0 + \Theta_{11}^{(1)}x_1 + \Theta_{12}^{(1)}x_2 + \Theta_{13}^{(1)}x_3)$ $a_2^{(2)} = g(\Theta_{20}^{(1)}x_0 + \Theta_{21}^{(1)}x_1 + \Theta_{22}^{(1)}x_2 + \Theta_{23}^{(1)}x_3)$ $a_3^{(2)} = g(\Theta_{30}^{(1)}x_0 + \Theta_{31}^{(1)}x_1 + \Theta_{32}^{(1)}x_2 + \Theta_{33}^{(1)}x_3)$ $h_\Theta(x) = a_1^{(3)} = g(\Theta_{10}^{(2)}a_0^{(2)} + \Theta_{11}^{(2)}a_1^{(2)} + \Theta_{12}^{(2)}a_2^{(2)} + \Theta_{13}^{(2)}a_3^{(2)})$ $\Theta^{(j)}$ = matrix of weights controlling function mapping from layer $j$ to layer $j+1$ If network has $sj$ units in layer $j$ and $s{j+1}$ units in layer $j+1$, then $\Theta ^{(j)}$ will be of dimension $s{j+1}×(s{j}+1)$. Model Representation IIForward propagation: Vectorized implementationThe vector representation of $x$ and $z^{(j)}$ is: $x = \begin{bmatrix}x_0 \\ x_1 \\ \cdots \\ x_n\end{bmatrix} , z^{(j)} = \begin{bmatrix}z_1^{(j)} \\ z_2^{(j)} \\ \cdots \\ z_n^{(j)}\end{bmatrix}$ Setting $x=a^{(1)}$, we can rewrite the equation as: $z^{(j)} = \Theta^{(j-1)}a^{(j-1)}$ Now we can get a vector of our activation nodes for layer $j$ as follows: $a^{(j)} = g(z^{(j)})$ We can then add a bias unit (equal to 1) to layer $j$ after we have computed $a^{(j)}$. This will be element $a^{(j)}_0$ and will be equal to 1. We then get our final result with: $h_\Theta(x) = a^{(j+1)} = g(z^{(j+1)})$ This last theta matrix ($\Theta ^{(j)}$) will have only one row so that our result is a single number. All of this is called Forward propagation (前向传播). The forward propagation step in a neural network works where you start from the activations of the input layer and forward propagate that to the first hidden layer, then the second hidden layer, and then finally the output layer. Neural Network learning its own featuresThe neural network, instead of being constrained to feed the features $x_1$, $x_2$, $x_3$ to logistic regression. It gets to learn its own features, $a_1$, $a_2$, $a_3$, to feed into the logistic regression. Depending on what parameters it chooses for $\Theta _1$, you can learn some pretty interesting and complex features and therefore you can end up with a better hypotheses than using the raw features. ApplicationsExamples and Intuitions IAND function We have: $x_1, x_2 \in {0,1}$ $y=x_1\ AND\ x_2$ $\Theta^{(1)} =\begin{bmatrix}-30 &amp; 20 &amp; 20\end{bmatrix}$ And we know the plot of sigmoid function So the results of $h_\Theta(x) = g(-30 + 20x_1 + 20x_2)$ are $x_1$ $x_2$ $h_\Theta (x)$ 0 0 $g(-30) \approx 0$ 0 1 $g(-10) \approx 0$ 1 0 $g(-10) \approx 0$ 1 1 $g(10) \approx 1$ OR function$\Theta^{(1)} =\begin{bmatrix}-10 &amp; 20 &amp; 20\end{bmatrix}$ $x_1$ $x_2$ $h_\Theta (x)$ 0 0 $g(-10) \approx 0$ 0 1 $g(10) \approx 1$ 1 0 $g(10) \approx 1$ 1 1 $g(10) \approx 1$ Examples and Intuitions IINegation (NOT function)$\Theta^{(1)} =\begin{bmatrix}10 &amp; -20\end{bmatrix}$ $x_1$ $h_\Theta (x)$ 0 $g(10) \approx 1$ 1 $g(-10) \approx 0$ NOR function$\Theta^{(1)} = \begin{bmatrix}10 &amp; -20 &amp; -20\end{bmatrix}$ $x_1$ $x_2$ $h_\Theta (x)$ 0 0 $g(10) \approx 1$ 0 1 $g(-10) \approx 0$ 1 0 $g(-10) \approx 0$ 1 1 $g(-30) \approx 0$ XNOR function Multiclass ClassificationTo classify data into multiple classes, we let our hypothesis function return a vector of values. Say we wanted to classify our data into one of four final resulting classes: Our final layer of nodes, when multiplied by its theta matrix, will result in another vector, on which we will apply the $g()$ logistic function to get a vector of hypothesis values. Our resulting hypothesis for one set of inputs may look like: $h_\Theta(x) = \begin{bmatrix}0 \\ 0 \\ 1 \\ 0 \\ \end{bmatrix}$ In which case our resulting class is the third one down, or $h_\Theta (x)_3$. We can define our set of resulting classes as $y$: $y^{(i)} = \begin{bmatrix}1\\ 0\\ 0\\ 0\end{bmatrix},\ \begin{bmatrix}0 \\ 1\\ 0\\ 0\end{bmatrix},\ \begin{bmatrix}0\\ 0\\ 1\\ 0\end{bmatrix},\ \begin{bmatrix}0\\ 0\\ 0\\ 1\end{bmatrix}$ Our final value of our hypothesis for a set of inputs will be one of the elements in $y$. Quiz Which of the following statements are true? Check all that apply. TRUE If a neural network is overfitting the data, one solution would be to increase the regularization parameter $\lambda$. FALSE If a neural network is overfitting the data, one solution would be to decrease the regularization parameter $\lambda$. FALSE Suppose you have a multi-class classification problem with three classes, trained with a 3 layer network. Let $a^{(3)}_1 = (h_\Theta(x))_1$ be the activation of the first output unit, and similarly $a^{(3)}_2 = (h_\Theta(x))_2$ and $a^{(3)}_3 = (h_\Theta(x))_3$. Then for any input x, it must be the case that $a^{(3)}_1 + a^{(3)}_2 + a^{(3)}_3 = 1$. The outputs of a neural network are not probabilities, so their sum need not be 1. TRUE In a neural network with many layers, we think of each successive layer as being able to use the earlier layers as features, so as to be able to compute increasingly complex functions. Consider the following neural network which takes two binary-valued inputs $x_1,x_2\in {0,1}$ and outputs $h_\Theta (x)$. Which of the following logical functions does it (approximately) compute? OR Consider the neural network given below. Which of the following equations correctly computes the activation $a{(3)}_1$? Note: $g(z)$ is the sigmoid activation function. $a_1^{(3)} = g(\Theta_{1,0}^{(2)}a_0^{(2)} + \Theta_{1,1}^{(2)}a_1^{(2)} + \Theta_{1,2}^{(2)}a_2^{(2)})$ You have the following neural network: You’d like to compute the activations of the hidden layer $a^{(2)}\in R^3$. One way to do so is the following Octave code: 123456789101112% Theta1 is Theta with superscript &quot;(1)&quot; from lecture% ie, the matrix of parmeters for the mapping from layer 1 (input) to layer 2% Theta1 has size 3x3% Assume &apos;sigmoid&apos; is a built-in function to compute 1 / (1 + exp(-z))a2 = zeros(3, 1);for i = 1:3 for j = 1:3 a2(i) = a2(i) + x(j) * Theta1(i, j); end a2(i) = sigmoid(a2(i));end You want to have a vectorized implementation of this (i.e., one that does not use for loops). Which of the following implementations correctly compute $a^{(2)}$? Check all that apply. a2 = sigmoid (Theta1 * x); You are using the neural network pictured below and have learned the parameters $\Theta^{(1)} = \begin{bmatrix} 1 &amp; 0.5 &amp; 1.9 \\ 1 &amp; 1.2 &amp; 2.7 \end{bmatrix}$ and $\Theta^{(2)} = \begin{bmatrix} 1 &amp; -0.2 &amp; -1.7 \end{bmatrix}$. Suppose you swap the parameters for the first hidden layer between its two units so $\Theta^{(1)} = \begin{bmatrix} 1 &amp; 1.2 &amp; 2.7 \\ 1 &amp; 0.5 &amp; 1.9 \end{bmatrix}$ and also swap the output layer so $\Theta^{(2)} = \begin{bmatrix} 1 &amp; -1.7 &amp; -0.2 \end{bmatrix}$. How will this change the value of the output $h_\Theta (x)$? It will stay the same.]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Notes for Machine Learning - Week 3]]></title>
      <url>%2F2016%2F08%2F05%2FCoursera-Machine-Learning-Week-3%2F</url>
      <content type="text"><![CDATA[Logistic RegressionClassification and RepresentationClassification Calssification Problem $y\in {0,1}$ 0: “Negative Class”, 负类 1: “Positive Class”, 正类 One method is to use linear regression and map all predictions greater than 0.5 as a 1 and all less than 0.5 as a 0. This method doesn’t work well because classification is not actually a linear function. Logistic Regression (逻辑回归) : $0\le h_\theta \le 1$ Hypothesis RepresentationLogistic Regression Model$h_\theta (x) = \frac{1}{1+e^{-\theta ^T x}}​$ Want $0\le h_\theta(x)\le 1$ $h_\theta (x) = g(\theta ^T x)$ $g(z) = \frac{1}{1+e^{-z}}$ Called “Sigmod function” or “Logistic function” Interpretation of Hypothesis Output $h_\theta (x)$ = estimated probability that $y=1$ on input $x$ $h_\theta (x) = P(y=1|x; \theta)$ probability that $y=1$, given $x$, parameterised by $\theta$. $P(y=0|x;\theta ) = 1 - P(y=1|x;\theta )$ Decision BoundaryIn order to get our discrete 0 or 1 classification, we can suppose $h_\theta(x) \geq 0.5 \rightarrow y = 1$ $h_\theta(x) &lt; 0.5 \rightarrow y = 0$ The way our logistic function $g$ behaves is that when its input is greater than or equal to zero, its output is greater than or equal to 0.5: $g(z) \ge 0.5$ when $z\ge 0$, i.e., $\theta ^T x \ge 0$ In conclusion, we can now say: $\theta^T x \geq 0 \Rightarrow y = 1$ $\theta^T x &lt; 0 \Rightarrow y = 0$ Decision boundariesThe decision boundary is the line that separates the area where $y=0$ and where $y=1$. It is created by our hypothesis function $\theta^T x = 0$. The decision boundary is a property, not of the trading set, but of the hypothesis $h_\theta(x)$ under the parameters. As long as we’re given parameter vector $\theta$, that defines the decision boundary. But the training set is not what we use to define the decision boundary. Non-linear decision boundariesThe input to the sigmoid function $g(z)$ (e.g. $\theta ^T x$) doesn’t need to be linear, and could be a function that describes a circle (e.g. $z = \theta_0 + \theta _1 x_1 + \theta _2 x_2 + \theta _3 x_1^2 + \theta _4 x_2^2$) or any shape to fit our data. Logistic Regression ModelCost FunctionWe cannot use the same cost function that we use for linear regression because the Logistic Function will cause the output to be wavy, causing many local optima. In other words, it will not be a convex function (凸函数). Instead, our cost function for logistic regression looks like: $J(\theta) = \dfrac{1}{m} \sum{i=1}^m \mathrm{Cost}(h\theta(x^{(i)}),y^{(i)})$ $\mathrm{Cost}(h\theta(x),y) = \begin{cases}-\log(h\theta(x)) ,&amp;\text{if y = 1}\newline -\log(1-h_\theta(x)) ,&amp;\text{if y = 0}\end{cases}$ $\mathrm{Cost} = 0$ if $y=1, h_\theta (x)=1$ But as $h_\theta (x) \to 0, \mathrm{Cost} \to \infty$ Captures intuition that if $h_\theta (x) = 0$ (predict $P(y=1|x;\theta ) = 0$), but $y=1$, we’ll penalise learning algorithm by a very large cost. Simplified Cost Function and Gradient DescentSimplified Cost FunctionWe can compress our cost function’s two conditional cases into one case: $\mathrm{Cost}(h_\theta(x),y) = - y \log(h_\theta(x)) - (1 - y) \log(1 - h_\theta(x))$ We can fully write out our entire cost function as follows: $J(\theta) = - \frac{1}{m} \sum_{i=1}^m [y^{(i)}\log (h_\theta (x^{(i)})) + (1 - y^{(i)})\log (1 - h_\theta(x^{(i)}))]$ This cost function can be derived from statistics using the principle of maximum likelihood estimation (极大似然估计). Which is an idea in statistics for how to efficiently find parameters’ data for different models. And it also has a nice property that it is convex. A vectorized implementation is: $h = g(X\theta)$ $ J(\theta) = \frac{1}{m} \cdot \left(-y^{T}\log(h)-(1-y)^{T}\log(1-h)\right)$ Gradient Descent$Repeat \lbrace \\ \theta_j := \theta_j - \alpha \dfrac{\partial}{\partial \theta_j}J(\theta)= \theta_j - \frac{\alpha}{m} \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)}) x_j^{(i)} \\ \rbrace$ Notice that this algorithm is identical to the one we used in linear regression (only $h_\theta (x)$ changes). We still have to simultaneously update all values in theta. A vectorized implementation is: $\theta := \theta - \frac{\alpha}{m} X^{T} (g(X \theta ) - \vec{y})$ To make sure th learning rate $\alpha$ is set properly, you can plot $J(\theta)$ as a function of the number of iterations and make sure $J(\theta )$ is decreasing on every iteration. Advanced OptimizationOptimization algorithms Gradient descent Conjugate gradient BFGS L-BFGS The avdantage of last three algorithms: No need to manually pick $\alpha$ Often faster than gradient descent Disadvantages: More complex ExampleWe first need to provide a function that evaluates the following two functions for a given input value $\theta$ : $J(\theta )$ $\frac{\partial}{\partial \theta _j} J(\theta )$ We can write a single function that returns both of these: 1234function [jVal, gradient] = costFunction(theta) jVal = [...code to compute J(theta)...]; gradient = [...code to compute derivative of J(theta)...];end Then we can use octave’s “fminunc()” optimization algorithm along with the “optimset()” function that creates an object containing the options we want to send to “fminunc()”. 123options = optimset(&apos;GradObj&apos;, &apos;on&apos;, &apos;MaxIter&apos;, 100);initialTheta = zeros(2,1);[optTheta, functionVal, exitFlag] = fminunc(@costFunction, initialTheta, options); Multiclass Classification: One-vs-allInstead of $y = {0,1}$, we will expand our definition so that $y = {1,2…n}$. In this case we divide our problem into $n$ binary classification problems; in each one, we predict the probability that ‘y’ is a member of one of our classes. That is, we can train a logistic regression classifier $h_\theta ^{(i)} (x)$ for each class $i$ to predict the probability that $y=i$. $h_\theta^{(i)}(x) = P(y = i | x ; \theta)\ \ \ \ (i=1,2,3,\dots , n+1)$ On a new input $x$, to make a prediction, pick the class $i$ that maximizes $h_\theta ^{(i)} (x)$. RegularizationSolving the Problem of OverfittingThe Problem of Overfitting High bias or underfitting is when the form of our hypothesis function h maps poorly to the trend of the data. It is usually caused by a function that is too simple or uses too few features. eg. if we take $h_\theta (x)=\theta _0+\theta _1x_1+\theta _2x_2$ then we are making an initial assumption that a linear model will fit the training data well and will be able to generalize but that may not be the case. At the other extreme, overfitting or high variance is caused by a hypothesis function that fits the available data but does not generalize (泛化) well to predict new data. It is usually caused by a complicated function that creates a lot of unnecessary curves and angles unrelated to the data. This terminology is applied to both linear and logistic regression. There are two main options to address the issue of overfitting: Reduce the number of features. Manually select which features to keep. Use a model selection algorithm (later in the course). Regularization (正则化) Keep all the features, but reduce the parameters $\theta _j$. Regularization works well when we have a lot of slightly useful features. Cost FunctionIntuitionIf we have overfitting from our hypothesis function, we can reduce the weight that some of the terms in our function carry by increasing their cost. Say we wanted to make the following function more quadratic: $\theta_0 + \theta_1x + \theta_2x^2 + \theta_3x^3 + \theta_4x^4$ We’ll want to eliminate the influence of $\theta _3x_3​$ and $\theta _4x_4​$. Without actually getting rid of these features or changing the form of our hypothesis, we can instead modify our cost function: $min_\theta\ \dfrac{1}{2m} \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)})^2 + 1000\cdot \theta _3^2 + 1000\cdot \theta _4^2$ We’ve added two extra terms at the end to inflate the cost of $\theta_3$ and $\theta_4$. Now, in order for the cost function to get close to zero, we will have to reduce the values of $\theta_3$ and $\theta_4$ to near zero. This will in turn greatly reduce the values of $\theta _3x_3$ and $\theta _4x_4$ in our hypothesis function. RegularizationWe could also regularize all of our theta parameters in a single summation: $min_\theta \dfrac{1}{2m}\ \left[ \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)})^2 + \lambda\ \sum_{j=1}^n \theta_j^2 \right]$ The $\lambda$, or lambda, is the regularization parameter. It determines how much the costs of our theta parameters are inflated. Using the above cost function with the extra summation, we can smooth the output of our hypothesis function to reduce overfitting. If lambda is chosen to be too large, it may smooth out the function too much and cause underfitting. (fails to fit even the training set). Regularized Linear RegressionGradient DescentWe will modify our gradient descent function to separate out $\theta_0$ from the rest of the parameters because we do not want to penalize $\theta_0$. $\text{Repeat}\ \lbrace \\ \ \ \ \ \theta_0 := \theta_0 - \alpha\ \frac{1}{m}\ \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)})x_0^{(i)} \\ \ \ \ \ \theta_j := \theta_j - \alpha\ \left[ \left( \frac{1}{m}\ \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)})x_j^{(i)} \right) + \frac{\lambda}{m}\theta_j \right] \ \ \ \ \ \ \ \ \ \ j \in \lbrace 1,2…n\rbrace \\ \rbrace$ The term $\frac{\lambda}{m}\theta_j$ performs our regularization. With some manipulation our update rule can also be represented as: $\theta_j := \theta_j(1 - \alpha\frac{\lambda}{m}) - \alpha\frac{1}{m}\sum_{i=1}^m(h_\theta(x^{(i)}) - y^{(i)})x_j^{(i)}$ The first term in the above equation, $1 - \alpha\frac{\lambda}{m}$ will always be less than 1. Intuitively you can see it as reducing the value of $\theta _j$ by some amount on every update. Notice that the second term is now exactly the same as it was before. Normal EquationTo add in regularization, the equation is the same as our original, except that we add another term inside the parentheses: $\theta = \left( X^TX + \lambda \cdot L \right)^{-1} X^Ty$ $L = \begin{bmatrix} 0 &amp; &amp; &amp; &amp; \\ &amp; 1 &amp; &amp; &amp; \\ &amp; &amp; 1 &amp; &amp; \\ &amp; &amp; &amp; \ddots &amp; \\ &amp; &amp; &amp; &amp; 1 \\ \end{bmatrix}$ $L$ should have dimension $(n+1)\times (n+1)$. Intuitively, this is the identity matrix (though we are not including $x_0$), multiplied with a single real number $\lambda$. Recall that if $m\le n$, then $X^TX$ is non-invertible. However, when we add the term $\lambda \cdot L$, then $X^TX + \lambda \cdot L$ becomes invertible. Regularized Logistic RegressionCost FunctionWe can regularize this equation by adding a term to the end: $J(\theta) = - \frac{1}{m} \sum_{i=1}^m \large[ y^{(i)}\ \log (h_\theta (x^{(i)})) + (1 - y^{(i)})\ \log (1 - h_\theta(x^{(i)}))\large] + \frac{\lambda}{2m}\sum_{j=1}^n \theta_j^2$ Note Well: The second sum, $\sum_{j=1}^n \theta_j^2$ means to explicitly exclude the bias term, $\theta _0$. I.e. the $\theta$ vector is indexed from 0 to n (holding $n+1$ values, $\theta _0$ through $\theta _n$), and this sum explicitly skips $\theta _0$, by running from 1 to n, skipping 0. Gradient Descent$\text{Repeat}\ \lbrace \\ \ \ \ \ \theta_0 := \theta_0 - \alpha\ \frac{1}{m}\ \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)})x_0^{(i)} \\\ \ \ \ \ \theta_j := \theta_j - \alpha\ \left[ \left( \frac{1}{m}\ \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)})x_j^{(i)} \right) + \frac{\lambda}{m}\theta_j \right] \ \ \ \ \ \ \ \ \ \ j \in \lbrace 1,2…n\rbrace\\\ \rbrace$]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Exercise in Machine Learning]]></title>
      <url>%2F2016%2F08%2F05%2FCoursera-Machine-Learning-Exercise%2F</url>
      <content type="text"><![CDATA[My exercise files and notes are put in Github.]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Notes for Machine Learning - Week 2]]></title>
      <url>%2F2016%2F07%2F27%2FCoursera-Machine-Learning-Week-2%2F</url>
      <content type="text"><![CDATA[Linear Regression with Multiple VariablesMultivariate Linear Regression Multiple features (variables) $n$ = number of features $x^{(i)}$ = input (features) of $i^{th}$ training example. $x^{(i)}_j$ = value of feature $j$ in $i^{th}$ training example. Hypotesis Previously: $h_\theta (x) = \theta_0 + \theta_1 x$ $h_\theta (x) = \theta_0 + \theta_1 x_1 + \theta_2 x_2 + \cdots + \theta_n x_n$ For convenience of notation, define $x_0=1$ $x=\begin{bmatrix}x_0 \\ x_1 \\ x_2 \\ \vdots \\ x_n \end{bmatrix}, \theta = \begin{bmatrix}\theta_0 \\ \theta_1 \\ \theta_2 \\ \vdots \\ \theta_n \end{bmatrix}, h_\theta (x) = \theta^T x​$ Gradient Descent for Multiple Variables Hypothesis: $h_\theta(x)=\theta^Tx=\theta_0 x_0 + \theta_1 x_1 + \theta_2 x_2 + \cdots + \theta_n x_n$ Parameters: $\theta_0, \theta_1, \dots ,\theta_n$ Cost function: $J(\theta_0, \theta_1, \dots, \theta_n) = \frac{1}{2m} \sum^m_{i=1}\left(h_\theta (x^{(i)})-y^{(i)}\right)^2$ or $J(\theta) = \frac{1}{2m}\sum_{i=1}^{m}(\theta^T x^{(i)} - y^{(i)})^2$ Gradient descent repeat { $\theta_j := \theta_j - \alpha \frac{\partial}{\partial \theta_j} J(\theta_0, \dots ,\theta_n)$ (simultaneously update for every $j=0,\dots,n$) } or repeat { $\theta_j := \theta_j - \alpha \frac{1}{m} \sum^m_{i=1}\left(h_\theta(x^{(i)})-y^{(i)}\right) x^{(i)}_j$ (simultaneously update for every $j=0,\dots,n$) } Gradient Descent in PracticeFeature NormalizationIdea: Make sure featueres are on a similar scale. We can speed up gradient descent by having each of our input values in roughly the same range. This is because $\theta$ will descend quickly on small ranges and slowly on large ranges, and so will oscillate inefficiently down to the optimum when the variables are very uneven. The way to prevent this is to modify the ranges of our input variables so that they are all roughly the same. Example $x_1$ = size (0-2000 $feet^2$) $x_2$ = number of bedrooms (1-5) $x_1$ has a much larger range of values than $x_2$. So the $J(\theta_1, \theta_2)$ can be a very very skewed elliptical shape. And if you run gradient descents on this cost function, your gradients may end up taking a long time and can oscillate back and forth and take a long time before it can finally find its way to the global minimum. Feature scalingGet every feature into approcimately $-1\le x_i \le 1$ range. Feature scaling involves dividing the input values by the range (i.e. the maximum value minus the minimum value) of the input variable, resulting in a new range of just 1. These aren’t exact requirements; we are only trying to speed things up. $-3\le x_i \le 3$ or $ -\frac{1}{3} \le x_i \le \frac{1}{3}$ just is fine. Mean normalizationReplace $x_i$ with $x_i - \mu _i$ to make features have approximately zero mean (Do not apply to $x_0 = 1$) E.g. $x_1 = \frac{size -1000}{2000}, x_2 = \frac{bedrooms - 2}{5}$ $x_i = \frac{x_i - \mu _i}{s_i}$ $\mu _i$ is the average value of $x_i$ in training set. $s_i$ is the range ($x_{imax}-x_{imin}$) or standard deviation ($\sigma$) Learning Rate “Debugging”: How to make sure gradient descent is working correctly Make a plot with number of iterations on the x-axis. Now plot the cost function, $J(\theta)$ over the number of iterations of gradient descent. For sufficient small $\alpha$, $J(\theta)$ should decreases on every iteration. But if $\alpha$ is too small, gradient descent can be slow to converge. If $J(\theta)$ ever increases, then you probably need to use smaller $\alpha$. Example automatic convergence test Declare convergence if $J(\theta)$ decreases by less than $\epsilon$ (e.g., $10^{-3})$ in one iteration. How to choose learing rate $\alpha$ So just try running gradient descent with a range of values for $\alpha$, like 0.001 and 0.01. And for these different values of $\alpha$ are just plot $J(\theta)$ as a function of number of iterations, and then pick the value of $\alpha$ that seems to be causing $J(\theta)$to decrease rapidly. Andrew Ng recommends decreasing $\alpha$ by multiples of 3. And then try to pick the largest possible value, or just something slightly smaller than the largest reasonable value. E.g. $\dots, 0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1, \dots$ Features and Polynomial RegressionChoice of features We can improve our features and the form of our hypothesis function in a couple different ways. We can combine multiple features into one. For example, we can combine $x_1​$ and $x_2​$ into a new feature $x_3​$ by taking $x_1\cdot x_2​$. (E.g. $House Area = Frontage \times Depth​$) Polynomial RegressionOur hypothesis function need not be linear (a straight line) if that does not fit the data well. We can change the behavior or curve of our hypothesis function by making it a quadratic, cubic or square root function (or any other form). For example, if our hypothesis function is $h_\theta(x) = \theta_0 + \theta_1 x_1$ then we can create additional features based on $x_1$, to get the quadratic function $h_\theta(x) = \theta_0 + \theta_1 x_1 + \theta_2 x_1^2$ or the cubic function $h_\theta(x) = \theta_0 + \theta_1 x_1 + \theta_2 x_1^2 + \theta_3 x_1^3$. In the cubic version, we have created new features $x_2$ and $x_3$ where $x_2 = x_1^2$ and $x_3=x^3_1$. To make it a square root function, we could do: $h_\theta(x) = \theta_0 + \theta_1 x_1 + \theta_2 \sqrt{x_1}$ Note that at 2:52 and through 6:22 in the “Features and Polynomial Regression” video, the curve that Prof Ng discusses about “doesn’t ever come back down” is in reference to the hypothesis function that uses the sqrt() function (shown by the solid purple line), not the one that uses $size^2$ (shown with the dotted blue line). The quadratic form of the hypothesis function would have the shape shown with the blue dotted line if $\theta _2$ was negative. One important thing to keep in mind is, if you choose your features this way then feature scaling becomes very important. E.g. if $x_1$ has range $1 - 1000$ then range of $x^2_1$ becomes $1 - 1000000$ and that of $x^3_1$ becomes $1 - 1000000000$ So you should scale $x_1$ before using polynomial regression. Computing Parameters AnalyticallyNormal EquationThe “Normal Equation” (正规方程) is a method of finding the optimum $\theta$ without iteration. There is no need to do feature scaling with the normal equation. Intuition $\theta \in R^{n+1} , J(\theta _0, \theta _1, \dots , \theta_m) = \frac{1}{2m} \sum ^m_{i=1} \left( h_\theta (x^{(i)}) - y^{(i)} \right) ^2$ Set $\frac{\partial }{\partial \theta _j} J(\theta ) = \cdots = 0$ (for every $j$), solve for $\theta _0, \theta _1, \dots , \theta _m$ MethodWe have $m$ examples $(x^{(1)}, y^{(1)}), \dots , (x^{(m)}, y^{(m)})$ and $n$ features. (Note that $x^{(i)}_0 = 0$) $$x^{(i)} = \begin{bmatrix}x^{(i)}_0 \\ x^{(i)}_1 \\ x^{(i)}_2 \\ \vdots \\ x^{(i)}_n \end{bmatrix}$$ And construct the $m \times (n+1)$ matrix $X$ $$X = \begin{bmatrix} (x^{(1)})^T \\ (x^{(2)})^T \\ \vdots \\ (x^{(m)})^T \end{bmatrix}$$ And the $m$-dimension vector $y$ $$y = \begin{bmatrix}y^{(i)} \\ y^{(i)} \\ y^{(i)} \\ \vdots \\ y^{(m)} \end{bmatrix}$$ Finally, we can get $$ \theta = (X^T X)^{-1}X^T y $$ ExampleSuppose you have the training in the table below: age ($x_1$) height in cm ($x_2$) weight in kg ($y$) 4 89 16 9 124 28 5 103 20 You would like to predict a child’s weight as a function of his age and height with the model $$weight = \theta _0 + \theta _1 age + \theta _2 height$$ Then you can construct $X$ and $y$ $$X = \begin{bmatrix} 1 &amp; 4 &amp; 89 \\ 1 &amp; 9 &amp; 124 \\ 1 &amp; 5 &amp; 103 \end{bmatrix}$$ $$Y = \begin{bmatrix} 16 \\ 28 \\ 20 \end{bmatrix}$$ Usage in Octave1pinv (X&apos;*X)*X&apos;*y Comparison of gradient descent and the normal equation$m$ training examples and $n$ features. Gradient Descent Normal Equation Need to choose $\alpha$ No need to choose $\alpha$ Needs many iterations No need to iterate $O (kn^2)$ $O (n^3)$, need to calculate $(X^TX)^{-1}$ Works well when $n$ is large Slow if $n$ is very large With the normal equation, computing the inversion has complexity $O(n^3)$. So if we have a very large number of features, the normal equation will be slow. In practice, when $n$ exceeds 10,000 it might be a good time to go from a normal solution to an iterative process. Normal Equation Noninvertibility$$ \theta = (X^T X)^{-1}X^T y $$ What if $X^TX$ is non-invertible (不可逆的) ? (singular/ degenerate) Octave: pinv(X&#39;*X)*X&quot;*y There’s two functions in Octave for inverting matrices, pinv (pseudo-inverse, 伪逆) and inv (inverse). As long as you use the pinv function then this will actually compute the value of data that you want even if X transpose X is non-invertible. So when implementing the normal equation in octave we want to use the pinv function rather than inv. $X^TX$ may be noninvertible. The common causes are: Redundant features, where two features are very closely related (i.e. they are linearly dependent) E.g. $x_1$ = size in $feet^2$, and $x_2$ = size in $m^2$. So you’ll always have $x_1 = (3.28)^2 x_2$ Too many features (e.g. $m\le n$). In this case, delete some features or use “regularization”. Octave/Matlab TutorialBasic Operations Print specific decimals: disp(sprintf(&#39;6 decimals: %0.6f&#39;, a)) // 6 decimals: 3.141593 v = 1:0.2:2 // [1.0 1.2 1.4 1.6 1.8 2.0] ones, zeros, rand, randn (生成正态分布的随机数矩阵), eye (生成单位矩阵) hist (直方图，第二个参数课自定义条数) size (返回矩阵的行数与列数 [m n] ) length (返回向量的维数) Moving Data Around Use load to load data set. 12load featureX.datload(&apos;priceY.dat&apos;) Use who to show all variables in Octave workspace whos for detail information clear to delete a variable 1clear featureX Get first ten elements of a matrix 1v = priceY(1:10) Use save to save your variable 1save hello.mat v By default the data is saved in binary. You can save it to ASCII by 1save hello.txt v -ascii Use A(3, 2) to get $A_{32}$, or A(2, :) to get every element along the second row A([1, 3], :) to get everything in the first and third rows A(:, 2) = [10; 11; 12] to change the value of elements in second column. A = [A, [100; 101; 102]] to append another column vector to right A(:) to put all elements of $A$ into a single vector Computing on Data Use max to get the largest element in a vector 12a = [1 15 2 0.5];[val, ind] = max(a); // val = 15, ind = 2 If you do max(A), where $A$ is a matrix, what this does is this actually does the column wise maximum. 12345678A = [1 2; 3 4; 5 6];max(A) // [5 6]A = [8 1 6; 3 5 7; 4 9 2];max(A, [], 1) // [8 9 7] (get the column wise maximum)max(A, [], 2) // [8 7 9] (get the row wise maximum)max(max(A)) // 9max(A(:)) // 9 a &lt; 3 does the element wise operation, you’ll get [1 0 1 1] find(a&lt;3) gets [1 3 4] magic(3) gets a 3x3 magic matrix sum, prod, floor, ceil, flipud Plotting Data plot hold on, figure, subplot xlabel, ylabel, legend, title, axis print -dpng &#39;myPlot.png&#39; imagesc(A) to visualize a matrix imagesc(A), colorer, colormap gray to be in gray scale. Control Statements: for, while, if statementVectorizationVectorization is the process of taking code that relies on loops and converting it into matrix operations. It is more efficient, more elegant, and more concise. As an example, let’s compute our prediction from a hypothesis. Theta is the vector of fields for the hypothesis and x is a vector of variables. With loops ($h_\theta (x) =\theta_0 x_0 + \theta_1 x_1 + \theta_2 x_2 + \cdots + \theta_n x_n$): 1234prediction = 0.0;for j = 1:n+1, prediction += theta(j) * x(j);end; With vectorization ($h_\theta (x) = \theta^T x$): 1prediction = theta&apos; * x;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Notes for Machine Learning - Week 1]]></title>
      <url>%2F2016%2F07%2F26%2FCoursera-Machine-Learning-Week-1%2F</url>
      <content type="text"><![CDATA[Linear Regression with One VariableModel and Cost FunctionModel Representation Supervised Learning (监督学习): Given the “right answer” for each example in the data. Regression Problem (回归问题): Predict real-valued output. Classification Problem (分类问题): Predict discrete-valued output. Training set (训练集) m: number of training examples x‘s: “input” variable / features y‘s: “output” variable / “target” variable $(x, y)$: one training example $(x^i, y^i)$: $i^{th}$ training example Training Set -&gt; Learning Algorithm -&gt; h(hypothesis, 假设) h is a function maps from x’s to y’s e.g. Size of house -&gt; h -&gt; Estimated price Linear regression with one variable $h_\theta (x) = \theta_0 + \theta_1 x$ Shorthand: $h(x)$ Or named Univariate linear regression (单变量线性回归) Cost Function Hypothesis: $h_\theta (x) = \theta_0 + \theta_1 x$ $\theta_i$’s: Parameters (模型参数) How to choose $\theta_i$’s ? Idea: Choose $\theta_0, \theta_1$ so that $h_\theta (x)$ is close to $y$ for our training example $(x,y)$ Cost function (代价函数) $J(\theta_0, \theta_1) = \frac{1}{2m} \sum_{i=1}^m \left(h_\theta(x^{(i)})-y^{(i)}\right)^2$ Sometimes called Square error function (平方误差代价函数) Goal: minimise $J(\theta_0, \theta_1)$ Parameter LearningGradient Descent Gradient Descent (梯度下降) Goal Have some function $J(\theta_0, \theta_1)$ Want $\theta_0, \theta_1$ of $min J(\theta_0, \theta_1)$ Outline Start with some $\theta_0, \theta_1$, usually all set to $0$. Keep changing $\theta_0, \theta_1$ to reduce $J(\theta_0, \theta_1)$ until we hopefully end up at minimum Gradient descent algorithm repeat until convergence (收敛) {​ $\theta_j := \theta_j - \alpha \frac{\partial}{\partial \theta_j} J(\theta_0, \theta_j)$ (for $j=0$ and $j=1$)} := denotes assignment $\alpha$ denotes learning rate if too small, gradient descent can be slow If too large, gradient descent can overshoot the minimum. It may fail to converge or even diverge. You should simultaneously update $\theta_0$ and $\theta_1$ That is, you should compute the right-hand sides of $\theta_0$ and $\theta_1$, then save them to temporary variables, and finally update $\theta_0$ and $\theta_1$. $temp0 := \theta_0 - \alpha \frac{\partial}{\partial \theta_0} J(\theta_0, \theta_j)$ $temp1 := \theta_1 - \alpha \frac{\partial}{\partial \theta_1} J(\theta_0, \theta_j)$ $\theta_0 := temp0$ $\theta_1 :=temp1$ Intuition If $\theta_1$ at local optima, it leaves $\theta_1$ unchanged. gradient descent can converge to a local minimum, even with the learning rate $\alpha$ fixed. As we approach a local minimum, gradient descent will automatically take smaller steps. So, no need to decrease $\alpha$ over time. Gradient Descent For Linear RegressionWe can compute that $\frac{\partial}{\partial \theta_0} J(\theta_0, \theta_1) = \frac{1}{m} \sum^m_{i=1}\left(h_\theta(x^{(i)})-y^{(i)}\right)$ $\frac{\partial}{\partial \theta_1} J(\theta_0, \theta_1) = \frac{1}{m} \sum^m_{i=1}\left(h_\theta(x^{(i)})-y^{(i)}\right) \cdot x^{(i)}$ Thus the Gradient descent algorithm can be expressed as repeat until convergence { $\theta_0 := \theta_0 - \alpha \frac{1}{m} \sum^m_{i=1}\left(h_\theta(x^{(i)})-y^{(i)}\right)​$ $\theta_1 := \theta_1 - \alpha \frac{1}{m} \sum^m_{i=1}\left(h_\theta(x^{(i)})-y^{(i)}\right) \cdot x^{(i)}$ } And the cost funciton of linear refression is always a convex function (凸函数), or called Bowl-shaped function (弓形函数). It doesn’t have any local optima except for the one global optimum. “Batch” Gradient Descent The algorithm that we just went over is sometimes called Batch Gradient Descent (批量梯度下降). “Batch”: Each step of gradient descent uses all th etraining examples.]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[OS X 10.11.4 on XPS 15 9550]]></title>
      <url>%2F2016%2F05%2F16%2FOS-X-10-11-4-on-XPS-15-9550%2F</url>
      <content type="text"><![CDATA[Thanks to the guide and its participants, I successfully installed OS X 10.11.4 on my XPS 15 9550. The guide is considerably perfect. Just follow the steps and you’ll get a well-done Hackintosh. My Clover directory, DSDT &amp; SSDT and Kexts are uploaded to Github, for reference only. Update: Now I upgrade to 10.11.5, and everything is fine.]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Notes for Code School - Shaping up with Angular.js]]></title>
      <url>%2F2016%2F04%2F14%2FCodeSchool-Shaping-up-with-Angular.js%2F</url>
      <content type="text"><![CDATA[Flatlander’s Gem StoreRamp upWhy Angular? If you?re using JavaScript to create a dynamic website, Angular is a good choice. Angular helps you organize your JavaScript Angular helps create responsive (as in fast) websites. Angular plays well with jQuery. Angular is easy to test. Traditional Page-Refresh A “responsive “website using Angular What is Angular JS? A client-side JavaScript Framework for adding interactivity to HTML. DirectivesA Directive is a marker on a HTML tag that tells Angular to run or reference some JavaScript code. 1234567&lt;!-- index.html --&gt;&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;body ng-controller="StoreController"&gt;...&lt;/body&gt;&lt;/html&gt; 1234// app.jsfunction StoreController()&#123; alert('Welcome, Gregg!');&#125; Modules Where we write pieces of our Angular application. Makes our code more maintainable, testable, and readable. Where we define dependencies for our app. 1234567891011&lt;!-- index.html --&gt;&lt;!DOCTYPE html&gt;&lt;html ng-app="store"&gt; &lt;head&gt; &lt;link rel="stylesheet" type="text/css" href="bootstrap.min.css" /&gt; &lt;/head&gt; &lt;body&gt; &lt;script type="text/javascript" src="angular.min.js"&gt;&lt;/script&gt; &lt;script type="text/javascript" src="app.js"&gt;&lt;/script&gt; &lt;/body&gt;&lt;/html&gt; 123// app.js// Application Name and Dependenciesvar app = angular.module('store', [ ]); ExpressionsAllow you to insert dynamic values into your HTML. 123456789&lt;!-- Numerical Operations --&gt;&lt;p&gt; I am &#123;&#123;4 + 6&#125;&#125;&lt;/p&gt;&lt;!-- String Operations --&gt;&lt;p&gt; &#123;&#123;"hello" + " you"&#125;&#125;&lt;/p&gt; Index HTML SetupControllersControllers are where we define our app?s behavior by defining functions and values. 123456789101112131415// app.js// Wrapping your Javascript in a closure is a good habit!(function()&#123; var app = angular.module('store', [ ]); // Notice that controller is attached to (inside) our app. app.controller('StoreController', function()&#123; this.product = gem; &#125;); var gem = &#123; name: 'Dodecahedron', price: 2.95, description: '. . .', &#125;.&#125;)(); 12345678910111213141516&lt;!-- index.html --&gt;&lt;!DOCTYPE html&gt;&lt;html ng-app="store"&gt; &lt;head&gt; &lt;link rel="stylesheet" type="text/css" href="bootstrap.min.css" /&gt; &lt;/head&gt; &lt;body&gt; &lt;div ng-controller="StoreController as store"&gt; &lt;h1&gt; &#123;&#123;ore.product.name&#125;&#125; &lt;/h1&gt; &lt;h2&gt; $&#123;&#123;store.product.price&#125;&#125; &lt;/h2&gt; &lt;p&gt; &#123;&#123;store.product.description&#125;&#125; &lt;/p&gt; &lt;/div&gt; &lt;script type="text/javascript" src="angular.min.js"&gt;&lt;/script&gt; &lt;script type="text/javascript" src="app.js"&gt;&lt;/script&gt; &lt;/body&gt;&lt;/html&gt; Using Built-in Directivesng-show Directive12345678910111213141516171819&lt;!-- index.html --&gt;&lt;!DOCTYPE html&gt;&lt;html ng-app="store"&gt; &lt;head&gt; &lt;link rel="stylesheet" type="text/css" href="bootstrap.min.css" /&gt; &lt;/head&gt; &lt;body&gt; &lt;div ng-controller="StoreController as store"&gt; &lt;h1&gt; &#123;&#123;store.product.name&#125;&#125; &lt;/h1&gt; &lt;h2&gt; $&#123;&#123;store.product.price&#125;&#125; &lt;/h2&gt; &lt;p&gt; &#123;&#123;store.product.description&#125;&#125; &lt;/p&gt; &lt;!-- Will only show the element if the value of the Expression istrue --&gt; &lt;button ng-show="store.product.canPurchase"&gt; Add to Cart &lt;/button&gt; &lt;/div&gt; &lt;script type="text/javascript" src="angular.min.js"&gt;&lt;/script&gt; &lt;script type="text/javascript" src="app.js"&gt;&lt;/script&gt; &lt;/body&gt;&lt;/html&gt; 123456// app.jsvar gem = &#123; name: 'Dodecahedron', price: 2.95, description: '. . .',&#125;. ng-hide Directive12345678910&lt;!-- index.html --&gt;&lt;body ng-controller="StoreController as store"&gt; &lt;div ng-hide="store.product.soldOut"&gt; &lt;h1&gt; &#123;&#123;store.product.name&#125;&#125; &lt;/h1&gt; &lt;h2&gt; $&#123;&#123;store.product.price&#125;&#125; &lt;/h2&gt; &lt;p&gt; &#123;&#123;store.product.description&#125;&#125; &lt;/p&gt; &lt;button ng-show="store.product.canPurchase"&gt; Add to Cart &lt;/button&gt; &lt;/div&gt; . . .&lt;/body&gt; 123456789// app.jsvar gem = &#123; name: 'Dodecahedron', price: 2.95, description: '. . .', canPurchase: true, // If the product is sold out, we want to hide it. soldOut: true,&#125;. ng-repeat Directive12345678910&lt;!-- index.html --&gt;&lt;body ng-controller="StoreController as store"&gt; &lt;div ng-repeat="product in store.products"&gt; &lt;h1&gt; &#123;&#123;product.name&#125;&#125; &lt;/h1&gt; &lt;h2&gt; $&#123;&#123;product.price&#125;&#125; &lt;/h2&gt; &lt;p&gt; &#123;&#123;product.description&#125;&#125; &lt;/p&gt; &lt;button ng-show="product.canPurchase"&gt;Add to Cart&lt;/button&gt; &lt;/div&gt; . . .&lt;/body&gt; 12345678910111213141516171819// app.jsapp.controller('StoreController', function()&#123; this.products = gems;&#125;);var gems = [ &#123; name: "Dodecahedron", price: 2.95, description: ". . .", canPurchase: true, &#125;, &#123; name: "Pentagonal Gem", price: 5.95, description: ". . .", canPurchase: false, &#125;]; Build-in DirectivesFilters and a new DirectiveFilters {{ data | filter:options }} 1234567891011121314// date&#123;&#123;'1388123412323' | date:'MM/dd/yyyy @ h:mma'&#125;&#125; // 12/27/2013 @ 12:50AM// uppercase &amp; lowercase&#123;&#123;'octagon gem' | uppercase&#125;&#125; // OCTAGON GEM// limitTo&#123;&#123;'My Description' | limitTo:8&#125;&#125; // My Descr&lt;li ng-repeat="product in store.products | limitTo:3"&gt; // orderBy// Will list products by descending price.// Without the - products would list in ascending order.&lt;li ng-repeat="product in store.products | orderBy:'-price'"&gt; Using ng-src for ImagesUsing Angular Expressions inside a src attribute causes an error! Because the browser tries to load the image before the Expression evaluates. 123456789101112&lt;body ng-controller="StoreController as store"&gt; &lt;ul class="list-group"&gt; &lt;li class="list-group-item" ng-repeat="product in store.products"&gt; &lt;h3&gt; &#123;&#123;product.name&#125;&#125; &lt;em class="pull-right"&gt; &#123;&#123;product.price | currency&#125;&#125; &lt;/em&gt; // NG-SOURCEto the rescue! &lt;img ng-src="&#123;&#123;product.images[0].full&#125;&#125;"/&gt; &lt;/h3&gt; &lt;/li&gt; &lt;/ul&gt;&lt;/body&gt; Tabs Inside Out ng-click ng-init ng-class 1234567891011121314151617&lt;section ng-conrtoller="PanelController as panel"&gt; &lt;ul class="nav nav-pills"&gt; &lt;li ng-class="&#123;active:panel.isSelected(1)&#125;"&gt; &lt;a herf ng-click="panel.selectTab(1)"&gt;Description&lt;/a&gt; &lt;/li&gt; &lt;li ng-class="&#123;active:panel.isSelected(3)&#125;"&gt; &lt;a herf ng-click="panel.selectTab(1)"&gt;Specifications&lt;/a&gt; &lt;/li&gt; &lt;li ng-class="&#123;active:panel.isSelected(3)&#125;"&gt; &lt;a herf ng-click="panel.selectTab(3)"&gt;Reviews&lt;/a&gt; &lt;/li&gt; &lt;/ul&gt; &lt;div class="panel" ng-show="panel.isSelected(1)"&gt; &lt;h4&gt;Description &lt;/h4&gt; &lt;p&gt;&#123;&#123;product.description&#125;&#125;&lt;/p&gt; &lt;/div&gt;&lt;/section&gt; 123456789app.controller("PanelController", function()&#123; this.tab = 1; this.selectTab = function(setTab) &#123; this.tab = setTab; &#125;; this.isSelected = function(checkTab)&#123; return this.tab === checkTab; &#125;;&#125;); Forms, Models, and ValidationsForms and ModelsIntroducing ng-modelng-model binds the form element value to the property. So we can have live previrew. 12345678910111213141516&lt;form name="reviewForm"&gt; &lt;blockquote&gt; &lt;b&gt;Stars: &#123;&#123;review.stars&#125;&#125;&lt;/b&gt; &#123;&#123;review.body&#125;&#125; &lt;cite&gt;by: &#123;&#123;review.author&#125;&#125;&lt;/cite&gt; &lt;/blockquote&gt; &lt;select ng-model="review.stars"&gt; &lt;option value="1"&gt;1 star&lt;/option&gt; &lt;option value="2"&gt;2 stars&lt;/option&gt; . . . &lt;/select&gt; &lt;textarea &gt;&lt;/textarea&gt; &lt;label&gt;by:&lt;/label&gt; &lt;input ng-model="review.body" type="email" /&gt; &lt;input ng-model="review.author" type="submit" value="Submit" /&gt;&lt;/form&gt; Two More Binding Examples 12345678910&lt;!-- With a Checkbox --&gt;&lt;!-- Sets value to true or false --&gt;&lt;input ng-model="review.terms" type="checkbox" /&gt; I agree to the terms&lt;!-- With Radio Buttons --&gt;&lt;!-- Sets the proper value based on which is selected --&gt;What color would you like? &lt;input ng-model="review.color" type="radio" value="red" /&gt; Red &lt;input ng-model="review.color" type="radio" value="blue" /&gt; Blue &lt;input ng-model="review.color" type="radio" value="green" /&gt; Green Accepting Submissionsng-submit directive. 1234567app.controller("ReviewController", function()&#123; this.review = &#123;&#125;; this.addReview = function(product) &#123; product.reviews.push(this.review); this.review = &#123;&#125;; &#125;;&#125;); 1234567&lt;form name="reviewForm" ng-controller="ReviewController as reviewCtrl"ng-submit="reviewCtrl.addReview(product)"&gt; &lt;blockquote&gt; &lt;b&gt;Stars: &#123;&#123;reviewCtrl.review.stars&#125;&#125;&lt;/b&gt; &#123;&#123;reviewCtrl.review.body&#125;&#125; &lt;cite&gt;by: &#123;&#123;reviewCtrl.review.author&#125;&#125;&lt;/cite&gt; &lt;/blockquote&gt; Form Validations 101We don?t want the form to submit when it?s invalid. Turn Off Default HTML Validation novalidate: Turn Off Default HTML Validation required: Mark Required Fields 12345678910111213&lt;form name="reviewForm" ng-controller="ReviewController as reviewCtrl"ng-submit="reviewCtrl.addReview(product)" &gt; &lt;select ng-model="reviewCtrl.review.stars" required&gt; &lt;option value="1"&gt;1 star&lt;/option&gt; ... &lt;/select&gt; &lt;textarea name="body" ng-model="reviewCtrl.review.body" required&gt;&lt;/textarea&gt; &lt;label&gt;by:&lt;/label&gt; &lt;input name="author" ng-model="reviewCtrl.review.author" type="email" required/&gt; &lt;div&gt; reviewForm is &#123;&#123;reviewForm.$valid&#125;&#125; &lt;/div&gt; &lt;input type="submit" value="Submit" /&gt;&lt;/form&gt; Preventing the Submit If valid is false , then addReview is never called. 12&lt;form name="reviewForm" ng-controller="ReviewController as reviewCtrl"ng-submit="reviewForm.$valid &amp;&amp; reviewCtrl.addReview(product)" novalidate&gt; Doesn?t Submit an Invalid Form How might we give a hint to the user why their form is invalid? 1&lt;input name="author" ng-model="reviewCtrl.review.author" type="email" required /&gt; 1234567.ng-invalid.ng-dirty &#123; border-color: #FA787E;&#125;.ng-valid.ng-dirty &#123; border-color: #78FA89;&#125; Source before typing email 1&lt;input name="author" . . . class="ng-pristine ng-invalid"&gt; Source after typing, with invalid email 1&lt;input name="author". . . class="ng-dirty ng-invalid"&gt; Source after typing, with valid email 1&lt;input name="author" . . . class="ng-dirty ng-valid"&gt; HTML5-based type validations Web forms usually have rules around valid input: Angular JS has built-in validations for common input types: 123&lt;input type="email" name="email"&gt;&lt;input type="url" name="homepage"&gt;&lt;input type="number" min=1 max=10 name="quantity"&gt;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Notes for Code School - Try jQuery]]></title>
      <url>%2F2016%2F04%2F13%2FCodeSchool-Try-jQuery%2F</url>
      <content type="text"><![CDATA[Introduction to jQueryWhat’s jQueryjQuery makes it easy to find elements in an HTML document change HTML content listen to what a user does and react accordingly animate content on the page talk over the network to fetch new content Document Object Model A tree-like structure created by browsers so we can quickly find HTML Elements using JavaScript. “DOM” How jQuery Accesses The DOM 1jQuery(document); Using the jQuery function to find nodes 1234// jQuery selectors// Use short &amp; sweet syntax$("h1"); // EQUALS TO jQuery("h1");$("p"); // EQUALS TO jQuery("p"); Modifying an element’s text 1$("h1").text("Where to?"); Listening for document ready JavaScript may execute before the DOM loads, so we need to make sure the DOM has finished loading the HTML content before we can reliably use jQuery. 123jQuery(document).ready(function()&#123; // code&#125;); Using jQueryGetting started download jQuery load it in your HTML document 1&lt;script src="jquery.min.js"&gt;&lt;/script&gt; start using it 1&lt;script src="application.js"&gt;&lt;/script&gt; We can find elements by ID or Class 12345678&lt;h1&gt;Where do you want to go?&lt;/h1&gt;&lt;h2&gt;Travel Destinations&lt;/h2&gt;&lt;p&gt;Plan your next adventure.&lt;/p&gt;&lt;ul id="destinations"&gt; &lt;li&gt;Rome&lt;/li&gt; &lt;li&gt;Paris&lt;/li&gt; &lt;li class='promo'&gt;Rio&lt;/li&gt;&lt;/ul&gt; 12$("#destinations");$(".promo"); Traversing the DOMSearching the DOMSelecting descendants 12345678&lt;h1&gt;Where do you want to go?&lt;/h1&gt;&lt;h2&gt;Travel Destinations&lt;/h2&gt;&lt;p&gt;Plan your next adventure.&lt;/p&gt;&lt;ul id="destinations"&gt; &lt;li&gt;Paris&lt;/li&gt; &lt;li&gt;Rome&lt;/li&gt; &lt;li class='promo'&gt;Rio&lt;/li&gt;&lt;/ul&gt; 123// we select the &lt;li&gt; elements that are// inside of the &lt;ul&gt; with a "destinations" ID$("#destinations li"); Selecting direct children 123456789101112&lt;h1&gt;Where do you want to go?&lt;/h1&gt;&lt;h2&gt;Travel Destinations&lt;/h2&gt;&lt;p&gt;Plan your next adventure.&lt;/p&gt;&lt;ul id="destinations"&gt; &lt;li&gt;Rome&lt;/li&gt; &lt;li&gt; &lt;ul id="france"&gt; &lt;li&gt;Paris&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li class='promo'&gt;Rio&lt;/li&gt;&lt;/ul&gt; 123// we select only the &lt;li&gt; elements that are// children of the "destinations" &lt;ul&gt;$("#destinations &gt; li"); Selecting multiple elements 1$(".promo, #france"); CSS-like pseudo classes 123456$("#destinations li:first");$("#destinations li:last");// watch out, the index starts at 0$("#destinations li:odd");$("#destinations li:even"); Traversing the DOMFiltering by traversing 12345678// EQUALS TO $("#destinations li");$("#destinations").find("li");// EQUALS TO $("li:first");$("li").first();// EQUALS TO $("li:last");$("li").last(); Walking the DOM 123$("li").first();$("li").first().next();$("li").first().next().prev(); Walking up the DOM 1$("li").first().parent(); Walking down the DOM 1$("#destinations").children("li"); Working with the DOMManipulating the DOMAppending to the DOM123456$(document).ready(function() &#123; var price = $('&lt;p&gt;From $399.99&lt;/p&gt;'); $('.vacation').append(price); // OR // price.appendTo($('.vacation'));&#125;); Ways to add this price node to the DOM .append(&lt;element&gt;) .prepend(&lt;element&gt;) .after(&lt;element&gt;) .before(&lt;element&gt;) .appendTo(&lt;element&gt;) .prependTo(&lt;element&gt;) .insertAfter(&lt;element&gt;) .insertBefore(&lt;element&gt;) Removing from the DOM123456$(document).ready(function() &#123; var price = $('&lt;p&gt;From $399.99&lt;/p&gt;'); $('.vacation').append(price); // Removes the &lt;button&gt; from the DOM $('button').remove();&#125;); Acting on InteractionWatching for Click 1234567$(document).ready(function() &#123; $('button').on('click', function() &#123; var price = $('&lt;p&gt;From $399.99&lt;/p&gt;'); $('.vacation').append(price); $('button').remove(); &#125;);&#125;); Refactor Using Traversing Traversing from $(this) Using .closest() 1234567$(document).ready(function() &#123; $('button').on('click', function() &#123; var price = $('&lt;p&gt;From $399.99&lt;/p&gt;'); $(this).closest('.vacation').append(price); $(this).remove(); &#125;);&#125;); Traversing and FilteringjQuery Object Methods 12345678&lt;li class="vacation onsale" data-price='399.99'&gt; &lt;h3&gt;Hawaiian Vacation&lt;/h3&gt; &lt;button&gt;Get Price&lt;/button&gt; &lt;ul class='comments'&gt; &lt;li&gt;Amazing deal!&lt;/li&gt; &lt;li&gt;Want to go!&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; .data(&lt;name&gt;) .data(&lt;name&gt;, &lt;value&gt;) 1234567891011$(document).ready(function() &#123; // Only target a 'button' if it's inside a '.vacation' $('.vacation').on('click', 'button', function() &#123; // Reusing jQuery Objects var vacation = $(this).closest('.vacation'); var amount = vacation.data('price'); var price = $('&lt;p&gt;From $'+amount+'&lt;/p&gt;'); vacation.append(price); $(this).remove(); &#125;);&#125;); Filtering for Vacations On sale 123456&lt;div id='filters'&gt; ... &lt;button class='onsale-filter'&gt;On Sale Now&lt;/button&gt; &lt;button class='expiring-filter'&gt;Expiring&lt;/button&gt; ...&lt;/div&gt; 1234$('#filters').on('click', '.onsale-filter', function() &#123; $('.highlighted').removeClass('highlighted'); $('.vacation').filter('.onsale').addClass('highlighted');&#125;); Listening to DOM EventsOn DOM Load1234567&lt;li class="confirmation"&gt; ... // Clicking this button &lt;button&gt;FLIGHT DETAILS&lt;/button&gt; // will show the ticket &lt;ul class="ticket"&gt;...&lt;/ul&gt;&lt;/li&gt; 123.ticket &#123; display: none;&#125; 123456$(document).ready(function() &#123; $('.confirmation').on('click', 'button', function() &#123; // Using slideDown to Show Elements $(this).closest('.confirmation').find('.ticket').slideDown(); &#125;);&#125;); Using slideDown to Show Elements .slideDown() .slideUp() .slideToggle() Display or hide the matched elements with a sliding motion. Expanding on on()What if we also want to show the ticket when they hover over the &lt;h3&gt; tag? 12345678function showTicket() &#123; $('this').closest('.confirmation').find('.ticket').slideDown();&#125;$(document).ready(function() &#123; // Don't add () at the end - that would execute the function immediately $('.confirmation').on('click', 'button', showTicket); $('.confirmation').on('mouseenter', 'h3', showTicket);&#125;); Mouse Event click dblclick focusin focusout mousedown mouseup mousemove mouseout mouseover mouseleave mouseenter Keyboard EventsChanging this “Tickets “input field should recalculate the total price. 1234567891011&lt;div class="vacation" data-price='399.99'&gt; &lt;h3&gt;Hawaiian Vacation&lt;/h3&gt; &lt;p&gt;$399.99 per ticket&lt;/p&gt; &lt;p&gt; Tickets: &lt;!-- When this updates... --&gt; &lt;input type='number' class='quantity' value='1' /&gt; &lt;/p&gt;&lt;/div&gt;&lt;!-- ...we'll update the calculated price here --&gt;&lt;p&gt;Total Price: $&lt;span id='total'&gt;399.99&lt;/span&gt;&lt;/p&gt; Keyboard and Form Events Keyboard Events keypress keydown keyup Form Events blur select change focus submit 123456789$(document).ready(function() &#123; $('.vacation').on('keyup', '.quantity', function() &#123; // Use + to convert the string to a number var price = +$(this).closest('.vacation').data('price'); var quantity = +$(this).val(); // You can pass a number or a string to the .text() method $('#total').text(price * quantity); &#125;);&#125;); Link LayoverClicking Show Comments will cause them to fade in 12&lt;!-- index.html --&gt;&lt;a href='#' class='expand'&gt;Show Comments&lt;/a&gt; 1234/* application.css */.comments &#123; display: none;&#125; 1234567891011// application.js$(document).ready(function() &#123; $('.vacation').on('click', '.expand',function(event) &#123; // The click event will "bubble up? but the browser won't handle it event.preventDefault(); $(this).closest('.vacation') .find('.comments') .fadeToggle(); &#125; );&#125;); event.stopPropagation() The browser will still handle the click event but will prevent it from “bubbling up? to each parent node. event.preventDefault() The click event will “bubble up? but the browser won’t handle it StylingTaming CSSChanging the Style 1234567891011121314151617// application.js$(document).ready(function() &#123; $('#vacations').on('click', '.vacation', function() &#123; // NOT RECOMMENDED // $(this).css('background-color', '#252b30'); // $(this).css('border-color', '1px solid #967'); // $(this).css('background-color', '#252b30') // .css('border-color', '1px solid #967'); // Passing in a JavaScript Object as an argument is a common jQuery pattern $(this).css(&#123;'background-color': '#252b30', 'border-color': '1px solid #967'&#125;); // Same as CSS syntax, but easier to read and understand // $(this).find('.price').css('display', 'block'); $(this).find('.price').show(); &#125;);&#125;); jQuery Object Methods .css(&lt;attr&gt;, &lt;value&gt;) .css(&lt;attr&gt;) .css(&lt;object&gt;) .show() .hide() Moving Styles to External CSS 12345678/* application.css */.highlighted &#123; background-color:#563; border-color: 1px solid #967;&#125;.highlighted .price &#123; display: block;&#125; 123456// application.js$(document).ready(function() &#123; $('#vacations').on('click', '.vacation', function() &#123; $(this).toggleClass('highlighted'); &#125;);&#125;); jQuery Object Methods .toggleClass() .addClass(&lt;class&gt;) .removeClass(&lt;class&gt;) AnimationWhat can we do to add a bit more movement to this? 1234567891011$(document).ready(function() &#123; $('#vacations').on('click', '.vacation', function() &#123; $(this).toggleClass('highlighted'); // Our vacation package will move up and down if ($(this).hasClass('highlighted')) &#123; $(this).animate(&#123;'top': '-10px'&#125;); &#125; else &#123; $(this).animate(&#123;'top': '0px'&#125;); &#125; &#125;);&#125;); Changing the Speed 123456// Default speed is 400$(this).animate(&#123;'top': '-10px'&#125;, 400);// 'fast' equals to 200$(this).animate(&#123;'top': '-10px'&#125;, 'fast');// 'slow' equals to 600$(this).animate(&#123;'top': '-10px'&#125;, 'slow');]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Notes for Code School - JavaScript Best Practices]]></title>
      <url>%2F2016%2F04%2F12%2FCodeSchool-JavaScript-Best-Practices%2F</url>
      <content type="text"><![CDATA[The Sword of SyntaxTernary ConditionalsThe ternary conditional provides a shortcut over lengthier conditional blocks. 1someCondition ? pickThisIfTrue : pickThisIfFalse; Example 123var isArthur = false;var weapon = isArthur ? "Excalibur" : "Longsword";?console.log("Current weapon: " + weapon); // Longsword Caution 123var isArthur = false;// The output is not as expectedconsole.log("Current weapon: " + isArthur ? "Excalibur" : "Longsword"); // Excalibur The + only knows to evaluate a variable and add it to a string, all before the ? gets to check a condition. The ? now looks for a boolean, but finds a string. Turns out, any JS value that is not false, 0, undefined, NaN, &quot;&quot;, or null will always evaluate as “truthy”. Ensure ternaries are isolatedUse parentheses to ensure the conditional is checked correctly. 123var isArthur = false;// The output is as expectedconsole.log("Current weapon: " + (isArthur ? "Excalibur" : "Longsword")); // Longsword More Usage We can use compound Boolean expressions to make ternary decisions, too. 1234var isArthur = true;var isKing = true;console.log("Current weapon: " + (isArthur "Excalibur" : "Longsword")); Any executable statement can serve as a ternary?s response choices. 12isArthur &amp;&amp; isKing ? alert("Hail Arthur, King of the Britons!") : alert("Charge on, ye Knight, for the glory of the King!") ; Ternaries provide a different format for picking immediately-invoked functions. 12345678910111213var isArthur = true;var isKing = false;isArthur &amp;&amp; isKing ? function ()&#123; alert("Hail Arthur, King of the Britons!"); console.log("Current weapon: Excalibur"); // Remember that adding the parentheses calls the function expression. &#125;() : function ()&#123; alert("Charge on, ye Knight, for the glory of the King!"); console.log("Current weapon: Longsword"); &#125;(); Each result option provides the opportunity to execute multiple actions. 12345678910var isArthur = true;var isKing = false;var weapon;var helmet;// Multiple statements within a single ternary response // are grouped in parentheses and separated by a comma.isArthur &amp;&amp; isKing ? ( weapon = "Excalibur", helmet = "Goosewhite" ) : ( weapon = "Longsword", helmet = "Iron Helm" ); A ternary can hold other ternaries within each of the possible responses. 123456789var isArthur = true;var isKing = false;var weapon;var helmet;isArthur &amp;&amp; isKing ? ( weapon = "Excalibur", helmet = "Goosewhite" ) : isArcher ? (weapon = "Longbow", helmet = "Mail Helm") : ( weapon = "Longsword", helmet = "Iron Helm" ); To be continued.]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Tips for Hexo configuration]]></title>
      <url>%2F2016%2F04%2F11%2FTips-for-Hexo-configuration%2F</url>
      <content type="text"><![CDATA[添加README.md文件由于Hexo会将source/目录下的所有.md文件渲染成.html文件，因此需要将README.md排除在外。幸好，Hexo在3.0以上的版本中提供了skip_render参数。 在source/里创建README.md 在_config.yml中修改 12skip_render: - README.md skip_render: Paths not to be rendered. You can use glob expressions for path matching 将源文件托管到Github为了保持多终端撰写Blog的便利，同时为了备份与版本管理，需要将Blog的源文件托管至Github上。目前的思路是在Github Pages的Repo上创建新的分支source。由于Hexo在Init之后，根目录下已经有了.gitignore文件，我们就不需要自己动手写。 1234567$ cd hexo$ git init$ git checkout -b source$ git add .$ git commit -m "Initial"$ git remote add origin git@github.com:corenel/corenel.github.io.git$ git push origin source 针对使用git clone下来第三方主题目录下有.git文件夹的情况，其实是不推荐这样做的。因为我们往往要对第三方主题进行修改，而我们不能直接提交到第三方问题的仓库上，这样就对多终端同步主题造成了困扰。 建议的方法是直接fork第三方主题，而后新建分支来作为给之后对主题修改之用，并且使用git submodule来管理。 123$ git submodule add git@github.com:corenel/hexo-theme-next.git themes/next$ git commit -am "Use themes/next"$ git push origin source 注意的是，在使用另一终端时，需要先初始化submodule。 12$ git submodule init$ git submodule update 第三方主题更新时，可以直接更新master分支，而后merge到自己的分支上。 123$ git remote add upstream git@github.com:iissnan/hexo-theme-next.git$ git checkout yuthon$ git pull upstream master 使用gulp压缩静态资源Hexo引擎在解析md时生成html的代码里会包含大量的无用空白，为了提高加载速度，用gulp压缩public目录的静态资源。 当然你也可以用hexo-all-minifier来精简。 安装gulp及其插件 12$ npm install gulp -g$ npm install gulp-minify-css gulp-uglify gulp-htmlmin gulp-htmlclean --save 编写gulpfile.js 1234567891011121314151617181920212223242526272829303132333435var gulp = require('gulp');var minifycss = require('gulp-minify-css');var uglify = require('gulp-uglify');var htmlmin = require('gulp-htmlmin');var htmlclean = require('gulp-htmlclean');gulp.task('minify-css', function() &#123; return gulp.src(["public/**/*.css","!public/**/*.min.css"]) .pipe(minifycss(&#123;compatibility: 'ie8'&#125;)) .pipe(gulp.dest('./public'));&#125;);gulp.task('minify-html', function() &#123; return gulp.src("public/**/*.html") .pipe(htmlclean()) .pipe(htmlmin(&#123; removeComments: true, minifyJS: true, minifyCSS: true, minifyURLs: true, &#125;)) .pipe(gulp.dest('./public'))&#125;);gulp.task('minify-js', function() &#123; return gulp.src(["public/**/*.js","!public/**/*.min.js"]) .pipe(uglify()) .pipe(gulp.dest('./public'));&#125;);gulp.task('default', [ 'minify-html','minify-css','minify-js'],function()&#123; console.log("gulp task ok!");&#125;); 之后在使用hexo g生成静态页面后，再执行gulp即可对静态资源进行压缩，压缩完成后再用hexo d部署即可。 给 Next 主题添加文章更新时间修改themes/next/layout/_macro/post.swig文件，在&lt;span class=&quot;post-time&quot;&gt;标签后（即对应的&lt;/span&gt;后）添加 12345678&#123;%if post.updated and post.updated &gt; post.date%&#125; &lt;span class=&quot;post-updated&quot;&gt; &amp;nbsp; | &amp;nbsp; &#123;&#123; __(&apos;post.updated&apos;) &#125;&#125; &lt;time itemprop=&quot;dateUpdated&quot; datetime=&quot;&#123;&#123; moment(post.updated).format() &#125;&#125;&quot; content=&quot;&#123;&#123; date(post.updated, config.date_format) &#125;&#125;&quot;&gt; &#123;&#123; date(post.updated, config.date_format) &#125;&#125; &lt;/time&gt; &lt;/span&gt;&#123;% endif %&#125; 而后修改语言配置文件themes/next/languages/en.yml（根据语言环境，文件有所不同） 12post: updated: Updated on 修改主题配置文件themes/next/_config.yml，增加一行 1display_updated: true 之后即可直接在文章开头设置更新时间（默认用文章.md文档的修改时间） 1updated: 2016-07-30 22:52:54]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Notes for Code School - ES2015]]></title>
      <url>%2F2016%2F04%2F10%2FCodeSchool-ES2015%2F</url>
      <content type="text"><![CDATA[DeclarationUsing letUnderstanding Hoisting Prior to executing our code, JavaScript moves var declarations all the way up to the top of the scope. This is known as hoisting. 123456789101112131415161718192021222324function loadProfiles(userNames)&#123; if(userNames.length &gt; 3)&#123; var loadingMessage = "This might take a while..."; _displaySpinner(loadingMessage); console.log(flashMessage); // undefined &#125;else&#123; var flashMessage = "Loading Profiles"; _displayFlash(flashMessage); &#125; console.log(flashMessage); // undefined&#125;// The function above will be hoisted by JavaScript as followsfunction loadProfiles(userNames)&#123; // Automatically moved here by the JavaScript runtime var loadingMessage, flashMessage; if(userNames.length &gt; 3)&#123; loadingMessage = "This might take a while..."; _displaySpinner(loadingMessage); &#125;else&#123; flashMessage = "Loading Profiles"; _displayFlash(flashMessage); &#125;&#125; Declaring Variables With let let variables are scoped to the nearest block and are NOT hoisted. A block is any code section within curly braces, like if, else, for, while, etc. Using let, variables are “trapped “inside their respective if and else blocks. 1234567891011function loadProfiles(userNames)&#123; if(userNames.length &gt; 3)&#123; let loadingMessage = "This might take a while..."; _displaySpinner(loadingMessage); console.log(flashMessage); // ReferenceError: flashMessage is not defined &#125;else&#123; let flashMessage = "Loading Profiles"; _displayFlash(flashMessage); &#125; console.log(flashMessage); // ReferenceError: flashMessage is not defined &#125; Using let in for loopsLoop Values in Callbacks 1234567891011121314function loadProfiles(userNames)&#123; for (var i in userNames)&#123; _fetchProfile("/users/" + userNames[i], function()&#123; console.log("Fetched for ", userNmaes[i]); &#125;); &#125;&#125;loadProfiles(["Sam", "Tyler", "Brook", "Alex"]);// Outputs:// Fetched for Alex// Fetched for Alex// Fetched for Alex// Fetched for Alex Reason variable i is hoisted to the top of the function and shared across each iteration of the loop. fetchProfile is called 4 times, before any of the callbacks are invoked. i is incremented on each iteration, finally it gets to 3. When callbacks begin to run, i holds the last value assigned to it from the for loop. So callbacks prints userNames[3] all 4 times. 123456789// By hoisting, The function above will be changed by JavaScript as followsfunction loadProfiles(userNames)&#123; var i; for (i in userNames)&#123; _fetchProfile("/users/" + userNames[i], function()&#123; console.log("Fetched for ", userNmaes[i]); &#125;); &#125;&#125; Soluition: Using let in for Loops With let, there’s no sharing in for loops. A new variable is created on each iteration. Each callback function now holds a reference to their own version of i. 1234567891011121314function loadProfiles(userNames)&#123; for (let i in userNames)&#123; _fetchProfile("/users/" + userNames[i], function()&#123; console.log("Fetched for ", userNmaes[i]); &#125;); &#125;&#125;loadProfiles(["Sam", "Tyler", "Brook", "Alex"]);// Outputs:// Fetched for Sam// Fetched for Tyler// Fetched for Brook// Fetched for Alex let Cannot Be Redeclared Variables declared with let can be reassigned, but cannot be redeclared within the same scope. Using constIssues With Magic Numbers Magic Numbers: A magic number is a literal value without a clear meaning. When used multiple times, magic numbers introduce unnecessary duplication, which can lead to bad code! 123456789101112function loadProfiles(userNames)&#123; if(userNames.length &gt; 3)&#123; //... &#125; else &#123; //... &#125; // Hard to tell whether both numbers serve the same purpose if(someValue &gt; 3)&#123; //... &#125;&#125; Replacing Magic Numbers With Constants The const keyword creates read-only named constants. Once assigned, constants cannot be assigned a new value. Variables declared with const must be assigned an initial value. Variables declared with const are scoped to the nearest block. 12345678910111213function loadProfiles(userNames)&#123; const MAX_USERS = 3; if(userNames.length &gt; MAX_USERS)&#123; //... &#125;else&#123; //... &#125; const MAX_REPLIES = 3; if(someElement &gt; MAX_REPLIES)&#123; //... &#125;&#125; let vs. const In most cases, let and const will behave very similarly. Consider the semantics when choosingone over the other. Use let when variables could be reassigned new values Use const when new variables are not expected to be reassigned new values FunctionsFunction DefaultsIssues With Flexible Function Arguments Unexpected arguments might cause errors during function execution. 123456789function loadProfiles(userNames)&#123; let namesLength = userNames.length; //...&#125;loadProfiles(["Sam", "Tyler", "Brook"]); // OK// Breaks when called with no argumentsloadProfiles(); // TypeError: Cannot read property 'length' of undefinedloadProfiles(undefined); // TypeError: Cannot read property 'length' of undefined Manual Argument Checks Don’t Scale Well A common practice is to check for presence of arguments as the very first thing in the function. 12345function loadProfiles(userNames)&#123; let names = typeof userNames !== 'undefined' ? userNames : []; let namesLength = names.length; // ...&#125; Using Default Parameter Values Default parameter values help move default values from the function body to the function signature. 12345678910// Uses empty array as default valuewhen no argument is passedfunction loadProfiles(userNames = [])&#123; let namesLength = userNames.length; console.log(namesLength);&#125;// Does not break when invoked with no argumentsloadProfiles(); // 0// Nor with explicit undefined as argumentloadProfiles( ); // 0 The Options Object The options object is a widely used pattern that allows user-defined settings to be passed to a function in the form of properties on an object. 123456789101112setPageThread("New Version out Soon!", &#123; popular: true, expires: 10000, activeClass: "is-page-thread"&#125;);function setPageThread(name, options = &#123;&#125;)&#123; let popular = options.popular; let expires = options.expires; let activeClass = options.activeClass; //...&#125; Issues With the Options Object The options object makes it hard to know what options a function accepts. Using Named Parameters Using named parameters for optional settings makes it easier to understand how a function should be invoked. Omitting Certain Arguments on Call It’s okay to omit some options when invoking a function with named parameters. It’s NOT okay to omit the options argument altogether when invoking a function with named parameters when no default value is set for them. 12345678910111213function setPageThread(name, &#123; popular, expires, activeClass &#125; = &#123;&#125;)&#123; console.log("Name: ", name); console.log("Popular: ", popular); console.log("Expires: ", expires); console.log("Active: " , activeClass);&#125;setPageThread("New Version out Soon!");// Outputs:// Name: New Version out Soon!// Popular: undefined// Expires: undefined// Active: undefined Rest Params, Spread Op, Arrow FuncRest ParametersIssues With the arguments Object The arguments object is a built-in, Array-like object that corresponds to the arguments of a function. Here’s why relying on this object to read arguments is not ideal: 123456789101112131415161718// Hard to tell which parameters this function expects to be called withfunction displayTags()&#123; // Where did this come from?! for(let i in arguments)&#123; let tag = arguments[i]; _addToTopic(tag); &#125;&#125;// If we add an argumentfunction displayTags(targetElement)&#123; let target = _findElement(targetElement); // We'll break the loop, since the first argument is no longer a tag for(let i in arguments)&#123; let tag = arguments[i]; _addToTopic(target, tag); &#125;&#125; Using Rest Parameters The new rest parameter syntax allows us to represent an indefinite number of arguments as an Array. This way, changes to function signature are less likely to break code. 12345678910111213141516function displayTags(...tags)&#123; // tags is an Array object for(let i in tags)&#123; let tag = [i]; _addToTopic(tag); &#125;&#125;.// ...tags must always go lastfunction displayTags(targetElement, ...tags)&#123; let target = _findElement(targetElement); for(let i in tags)&#123; let tag = [i]; _addToTopic(target, tag); &#125;&#125; Spread OperatorSplitting Arrays Into Individual Arguments We need a way to convert an Array into individual arguments upon a function call. 123456getRequest("/topics/17/tags", function( )&#123; // tags is an Array, e.g., ["programming", "web", "HTML"] ... let tags = data.tags; // but displayTags expects to be called with individual arguments displayTags(tags);&#125;) Using the Spread Operator The spread operator allows us to split an Array argument into individual elements. 123456getRequest("/topics/17/tags", function( )&#123; let tags = data.tags; // The displayTags function is now receiving individual arguments, // not an Array displayTags(...tags);&#125;) Rest and Spread look the same Rest parameters and the spread operator look the same, but the former is used in function definitions and the latter in function invocations. Arrow FunctionsIssues With Scope in Callback Functions Anonymous functions passed as callbacks to other functions create their own scope. 12345678910111213141516function TagComponent(target, urlPath)&#123; this.targetElement = target; this.urlPath = urlPath;&#125;.// The scope of the TagComponent object is not the same as // the scope of the anonymous functionTagComponent.prototype.render = function()&#123; getRequest(this.urlPath, function(data)&#123; let tags = data.tags; displayTags(this.targetElement, ...tags); // Returns undefined &#125;);&#125;let tagComponent = new TagComponent(targetDiv, "/topics/17/tags");tagComponent.render(); Using Arrow Functions to Preserve Scope Arrow functions bind to the scope of where they are defined, not where they are called. (also known as lexical binding) 12345678910111213141516function TagComponent(target, urlPath)&#123; this.targetElement = target; this.urlPath = urlPath;&#125;.TagComponent.prototype.render = function()&#123; // Arrow functions bind to the lexical scope getRequest(this.urlPath, (data) =&gt; &#123; let tags = data.tags; // this now properly refers to the TagComponent object displayTags(this.targetElement, ...tags); &#125;);&#125;let tagComponent = new TagComponent(targetDiv, "/topics/17/tags");tagComponent.render(); Objects, Strings, and Object.assignObjectsThe Object Initializer Shorthand We can remove duplicate variable names from object properties when those properties have the same name as the variables being assigned to them. 123456function buildUser(first, last)&#123; let fullName = first + " " + last; return &#123; first, last, fullName &#125;; // EQUAL TO // return &#123; first: first, last: last, fullName: fullName&#125;;&#125; Object Destructuring We can use shorthand to assign properties from objects to local variables with the same name. 123456789let &#123; first, last, fullName &#125; = buildUser("Sam", "Williams");// EQUAL TO// let user = buildUser("Sam", "Williams");// let first = user.first;// let last = user.last;// let fullName = user.fullName;// Destructuring Selected Elementslet &#123; fullName &#125; = buildUser("Sam", "Williams"); Using the Method Initializer Shorthand A new shorthand notation is available for adding a method to an object where the keyword function is no longer necessary. 123456789101112function buildUser(first, last, postCount)&#123; let fullName = first + " " + last; const ACTIVE_POST_COUNT = 10; return &#123; first, last, fullName, isActive()&#123; // EQUAL TO isActive: function()&#123;&#125; return postCount &gt;= ACTIVE_POST_COUNT; &#125; &#125;&#125; StringsTemplate Strings Template strings are string literals allowing embedded expressions. This allows for a much better way to do string interpolation. 1234567function buildUser(first, last, postCount)&#123; let fullName = `$&#123;first&#125; $&#123;last&#125;`; // EQUAL TO // let fullName = first + " " + last; const ACTIVE_POST_COUNT = 10; //...&#125; Writing Multi-line Strings Template strings offer a new - and much better - way to write multi-line strings. 12345678910let userName = "Sam";let admin = &#123; fullName: "Alex Williams" &#125;;let veryLongText = `Hi $&#123;userName&#125;, this is a very very veeeery long text. Regards, $&#123;admin.fullName&#125;`; Template Strings use back-ticks (``) rather than the single or double quotes we’re used to with regular strings. Object.assignUsing Too Many Arguments Is Bad For functions that need to be used across different applications, it’s okay to accept an options object instead of using named parameters 123456789101112// Too many named arguments make this function harder to readfunction countdownTimer(target, timeLeft, &#123; container, timeUnit, clonedDataAttribute, timeoutClass, timeoutSoonClass, timeoutSoonSeconds &#125; = &#123;&#125;)&#123; //...&#125;// Easier to customize to different applicationsfunction countdownTimer(target, timeLeft, options = &#123;&#125;)&#123; //...&#125; Using Local Values and || Is Bad for Defaults Some options might not be specified by the caller, so we need to have default values. 12345678910function countdownTimer(target, timeLeft, options = &#123;&#125;)&#123; // Default strings and numbers are all over the place... Yikes! let container = options.container || ".timer-display"; let timeUnit = options.timeUnit || "seconds"; let clonedDataAttribute = options.clonedDataAttribute || "cloned"; let timeoutClass = options.timeoutClass || ".is-timeout"; let timeoutSoonClass = options.timeoutSoonClass || ".is-timeout-soon"; let timeoutSoonTime = options.timeoutSoonSeconds || 10; //...&#125; Using a Local Object to Group Defaults Using a local object to group default values for user options is a common practice and can help write more idiomatic JavaScript. 1234567891011function countdownTimer(target, timeLeft, options = &#123;&#125;)&#123; let defaults = &#123; container: ".timer-display", timeUnit: "seconds", clonedDataAttribute: "cloned", timeoutClass: ".is-timeout", timeoutSoonClass: ".is-timeout-soon", timeoutSoonTime: 10 &#125;; //...&#125; Merging Values With Object.assign The Object.assign method copies properties from one or more source objects to a target object specified as the very first argument. 1234567891011function countdownTimer(target, timeLeft, options = &#123;&#125;)&#123; let defaults = &#123; //... &#125;; // Merged properties from defaults and options // Target object is modified and used as return value // Source objects remain unchanged let settings = Object.assign(&#123;&#125;, defaults, options); //...&#125; Merging Objects With Duplicate Properties In case of duplicate properties on source objects, the value from the last object on the chain always prevails. 12345678910function countdownTimer(target, timeLeft, options = &#123;&#125;)&#123; let defaults = &#123; //... &#125;; // Duplicate properties from options3 override those on options2, // which override those on options, etc. let settings = Object.assign(&#123;&#125;, defaults, options, options2, options3); //...&#125; Using Object.assign There are a couple incorrect ways we might see Object.assign being used. 1234567891011121314// NOT recommanded// defaults is mutated, so we can't go back and access original default// values after the mergeObject.assign(defaults, options);// Recommanded// Can access original default values and looks functionallet settings = Object.assign(&#123;&#125;, defaults, options);// NOT recommanded// Default values are not changed, but settings is passed as a referencelet settings = &#123;&#125;;// Not reading return valueObject.assign(settings, defaults, options); Reading Initial Default Values Preserving the original default values gives us the ability to compare them with the options passed and act accordingly when necessary. 123456789101112function countdownTimer(target, timeLeft, options = &#123;&#125;)&#123; let defaults = &#123; //... &#125;; let settings = Object.assign(&#123;&#125;, defaults, options); // Runs when value passed as argument for timeUnit is different than the original value if(settings.timeUnit !== defaults.timeUnit)&#123; _conversionFunction(timeLeft, settings.timeUnit) &#125;&#125; Arrays, Maps, and SetsArraysArray DestructuringReading Values With Array Destructuring We can use destructuring to assign multiple values from an array to local variables. 123let users = ["Sam", "Tyler", "Brook"];let a b c [ ] , , = users;console.log( a, b, c ); // Sam Tyler Brook Values can be discarded 12let [a, , b] = users;console.log( a, b ); // Sam Brook Combining Destructuring With Rest Params We can combine destructuring with rest parameters to group values into other arrays. 123let users = ["Sam", "Tyler", "Brook"];let [ first, ...rest ] = users;console.log( first, rest ); // Sam ["Tyler", "Brook"] Destructuring Arrays From Return Values When returning arrays from functions, we can assign to multiple variables at once. 12345678910function activeUsers()&#123; let users = ["Sam", "Alex", "Brook"]; return users;&#125;let active = activeUsers();console.log( active ); // ["Sam", "Alex", "Brook"] let [a, b, c] = activeUsers();console.log( a, b, c ); // Sam Alex Brook for…ofUsing for…of to Loop Over Arrays The for…of statement iterates over property values, and it’s a better way to loop over arrays and other iterable objects. 1234567891011let names = ["Sam", "Tyler", "Brook"];// Uses index to read actual elementfor(let index in names)&#123; console.log( names[index] ); // Sam Tyler Brook &#125;// Reads element directly and with less code involvedfor(let name of names)&#123; console.log( name ); // Sam Tyler Brook &#125; Limitations of for…of and Objects The for…of statement cannot be used to iterate over properties in plain JavaScript objects out-of-the-box. In order to work with for…of, objects need a special function assigned to the Symbol.iteratorproperty. The presence of this property allows us to know whether an object is iterable. 123456789101112131415161718// Objects That Work With for...oflet names = ["Sam", "Tyler", "Brook"];console.log( typeof names[Symbol.iterator] ); // functionfor(let name of names)&#123; console.log( name ); // Sam Tyler Brook &#125;// Objects That Don't Work With for...oflet post = &#123; title: "New Features in JS", replies: 19, lastReplyFrom: "Sam"&#125;;console.log( typeof post[Symbol.iterator] ); // undefinedfor(let property of post)&#123; console.log( property ); // TypeError: post[Symbol.iterator] is not a function&#125; Array.findFinding an Element in an Array Array.find returns the first element in the array that satisfies a provided testing function. 123456789101112131415let users = [ &#123; login: "Sam", admin: false &#125;, &#123; login: "Brook", admin: true &#125;, &#123; login: "Tyler", admin: true &#125;];// Returns first object for which user.admin is truelet admin = users.find( (user) =&gt; &#123; return user.admin;&#125;);console.log( admin ); // &#123; "login" : "Brook", "admin" : true &#125;// One-liner arrow functionlet admin = users.find( user =&gt; user.admin );console.log( admin ); // &#123; "login" : "Brook", "admin" : true &#125; MapsMaps and ObjectsThe Map Data Structure Issues With Using Objects as Maps When using Objects as maps, its keys are always converted to strings. 123456789101112// Two different objectslet user1 = &#123; name: "Sam" &#125;;let user2 = &#123; name: "Tyler" &#125;;// Both objects are converted to the string "[object Object]"let totalReplies = &#123;&#125;;totalReplies[user1] = 5;totalReplies[user2] = 42;console.log( totalReplies[user1] ); // 42console.log( totalReplies[user2] ); // 42console.log( Object.keys(totalReplies) ); // ["[object Object]"] Storing Key/Values With Map The Map object is a simple key/value data structure. Any value may be used as either a key or a value, and objects are not converted to strings. 123456789let user1 = &#123; name: "Sam" &#125;;let user2 = &#123; name: "Tyler" &#125;;let totalReplies = new Map();totalReplies.set( user1, 5 );totalReplies.set( user2, 42 );console.log( totalReplies.get(user1) ); // 5console.log( totalReplies.get(user2) ); // 42 We use the get() and set() methods to access values in Maps Use Maps When Keys Are Unknown Until Runtime 123456789101112let recentPosts = new Map();createPost(newPost, (data) =&gt; &#123; // Keys unknown until runtime, so... Map! recentPosts.set( data.author, data.message );&#125;);const POSTS_PER_PAGE = 15;let userSettings = &#123; // Keys are previously defined, so... Object! perPage: POSTS_PER_PAGE, showRead: true,&#125;; Use Maps When Types Are the Same 1234567891011121314151617let recentPosts = new Map();createPost(newPost, (data) =&gt; &#123; recentPosts.set( data.author, data.message );&#125;);// ...somewhere else in the codesocket.on('new post', function(data)&#123; // All keys are the same type, // and all values are the same type, so Map! recentPosts.set( data.author, data.message );&#125;);const POSTS_PER_PAGE = 15;let userSettings = &#123; // Some values are numeric, others are boolean, so Object! perPage: POSTS_PER_PAGE, showRead: true,&#125;; Iterating Maps With for…of Maps are iterable, so they can be used in a for...of loop. Each run of the loop returns a [key, value] pair for an entry in the Map. 123456789101112let mapSettings = new Map();mapSettings.set( "user", "Sam" );mapSettings.set( "topic", "ES2015" );mapSettings.set( "replies", ["Can't wait!", "So Cool"] );for(let [key, value] of mapSettings)&#123; console.log(`$&#123;key&#125; = $&#123;value&#125;`); // user = Sam // topic = ES2015 // replies = Can't wait!,So Cool&#125; WeakMapThe WeakMap is a type of Map where only objects can be passed as keys. Primitive data types - such as strings, numbers, booleans, etc. - are not allowed. 1234567891011let user = &#123;&#125;;let comment = &#123;&#125;;let mapSettings = new WeakMap();mapSettings.set( user, "user" );mapSettings.set( comment, "comment" );console.log( mapSettings.get(user) ); // userconsole.log( mapSettings.get(comment) ); // commentmapSettings.set("title", "ES2015"); // Invalid value used as weak map key All available methods on a WeakMap require access to an object used as a key. 12345678let user = &#123;&#125;;let mapSettings = new WeakMap();mapSettings.set( user, );console.log( mapSettings.get(user) ); // ES2015console.log( mapSettings.has(user) ); // trueconsole.log( mapSettings.delete(user) ); // true WeakMaps are not iterable, therefore they can’t be used with for…of 1234for(let [key,value] of mapSettings)&#123; console.log(`$&#123;key&#125; = $&#123;value&#125;`); // mapSettings[Symbol.iterator] is not a function&#125; WeakMaps Are Better With Memory Individual entries in a WeakMap can be garbage collected while the WeakMap itself still exists. SetsSets and ArraysLimitations With Arrays Arrays don’t enforce uniqueness of items. Duplicate entries are allowed. 12345678let tags = [];tags.push( "JavaScript" );tags.push( "Programming" );tags.push( "Web" );tags.push( "Web" ); // Duplicate entryconsole.log( "Total items ", tags.length ); // Total items 4 Using Set The Set object stores unique values of any type, whether primitive values or object references. 12345678910let tags = new Set();tags.add("JavaScript");// Both primitive values and objects are allowedtags.add("Programming");tags.add(&#123; version: "2015" &#125;);tags.add("Web");tags.add("Web"); // Duplicate entries are ignoredconsole.log("Total items ", tags.size); // Total items 4 Using Set as Enumerable Object Set objects are iterable, which means they can be used with for...of and destructuring. 1234567891011121314151617181920let tags = new Set();tags.add("JavaScript");tags.add("Programming");tags.add(&#123; version: "2015" &#125;);tags.add("Web");for(let tag of tags)&#123; console.log(tag);&#125;// OUTPUTS:// JavaScript// Programming// &#123; version: '2015' &#125;// Weblet [a,b,c,d] = tags;console.log(a, b, c, d);// OUTPUTS:// JavaScript Programming &#123; version: '2015' &#125; Web WeakSet The WeakSet is a type of Set where only objects are allowed to be stored. WeakSets don’t prevent the garbage collector from collecting entries that are no longer used in other parts of the system WeakSets cannot be used with for...of and they offer no methods for reading values from it. Using WeakSets to Show Unread Posts We want to add a different background color to posts that have not yet been read. We can use WeakSets to create special groups from existing objects without mutating them. Favoring immutable objects allows for much simpler code with no unexpected side effects. 1234567891011121314151617let readPosts = new WeakSet();//...when post is clicked onpostList.addEventListener('click', (event) =&gt; &#123; // ... // Adds object to a group of read posts readPosts.add(post);&#125;);// ...rendering postsfor(let post of postArray)&#123; // The has() method checks whether // an object is present in the WeakSet if(!readPosts.has(post))&#123; _addNewPostClass(post.element); &#125;&#125; Classes and ModulesClassesUsing a Function Approach A common approach to encapsulation in JavaScript is using a constructor function. 1234567891011121314function SponsorWidget(name, description, url)&#123; this.name = name; this.description = description; this.url = url;&#125;// Too verbose!SponsorWidget.prototype.render = function()&#123; //...&#125;;// Invoking the SponsorWidget function looks like this:let sponsorWidget = new SponsorWidget(name, description, url);sponsorWidget.render(); Using the New Class Syntax To define a class, we use the class keyword followed by the name of the class. The body of a class is the part between curly braces. 123456789101112131415161718192021222324class SponsorWidget &#123; // Runs every time a new instance is created with the new operator constructor(name, description, url)&#123; // ... // Don't forget to use this to access instance properties and methods this.url = url; &#125; // Can access previously assigned instance variables render()&#123; let link = this._buildLink(this.url); // ... &#125; // Prefixing a method with an underscore is a // convention for indicating that it should not // be invoked from the public API _buildLink(url)&#123; // ... &#125;&#125;let sponsorWidget = new SponsorWidget(name, description, url);sponsorWidget.render(); Class Inheritance We can use class inheritance to reduce code repetition. Child classes inherit and specialize behavior defined in parent classes. Using extends to Inherit From Base Class The extends keyword is used to create a class that inherits methods and properties from another class. The super method runs the constructor function from the parent class. 1234567891011121314151617181920212223// Parent Classclass Widget &#123; constructor()&#123; this.baseCSS = "site-widget"; &#125; parse(value)&#123; //... &#125;&#125;// Child Classclass SponsorWidget extends Widget &#123; constructor(name, description, url)&#123; // runs parent's setup code super(); //... &#125; render()&#123; let parsedName = this.parse(this.name); let css = this._buildCSS(this.baseCSS); //... &#125;&#125; Overriding Inherited Methods Child classes can invoke methods from their parent classes via the super object. 12345678910111213141516171819202122232425// Parent Classclass Widget &#123; constructor()&#123; this.baseCSS = "site-widget"; &#125; parse(value)&#123; //... &#125;&#125;// Child Classclass SponsorWidget extends Widget &#123; constructor(name, description, url)&#123; super(); //... &#125; parse()&#123; // Calls the parent version of the parse() method let parsedName = super.parse(this.name); return `Sponsor: $&#123;parsedName&#125;`; &#125; render()&#123; //... &#125;&#125; ModulesFunction ModulesPolluting the Global Namespace The common solution for modularizing code relies on using global variables. This increases the chances of unexpected side effects and potential naming conflicts. 1234567&lt;!DOCTYPE html&gt;&lt;body&gt; &lt;!-- Libraries add to the global namespace --&gt; &lt;script src="./jquery.js"&gt;&lt;/script&gt; &lt;script src="./underscore.js"&gt;&lt;/script&gt; &lt;script src="./flash-message.js"&gt;&lt;/script&gt;&lt;/body&gt; 1234// Global variables can cause naming conflictslet element = $("...").find(...);let filtered = _.each(...);flashMessage("Hello"); Creating Modules 1234567891011// flash-message.js// The export keyword exposes this function to the module system// The default type export is the simplest way to export a functionexport default function(message)&#123; alert(message);&#125; // app.js// Can be named anything because it's default exportimport flashMessage from './flash-message';flashMessage("Hello"); 123456&lt;!DOCTYPE html&gt;&lt;body&gt; &lt;!-- Not adding to the global namespace --&gt; &lt;script src="./flash-message.js"&gt;&lt;/script&gt; &lt;script src="./app.js"&gt;&lt;/script&gt;&lt;/body&gt; Using Named Exports In order to export multiple functions from a single module, we can use the named export. 123456789101112// flash-message.jsexport function (message)&#123; alert(message);&#125;export function logMessage(message)&#123; console.log(message);&#125;// app.jsimport &#123; alertMessage, logMessage &#125; from './flash-message';alertMessage('Hello from alert');logMessage('Hello from log'); Importing a Module as an Object 12345// app.jsimport * as flash from './flash-message';flash.alertMessage('Hello from alert');falsh.logMessage('Hello from log'); Removing Repeated Export Statements 123456789101112131415// flash-message.jsfunction alertMessage(message)&#123; alert(message);&#125;function logMessage(message)&#123; console.log(message);&#125;// export can take multiple function names between curly bracesexport &#123; alertMessage, logMessage &#125;;// app.js// Imported just like beforeimport &#123; alertMessage, logMessage &#125; from './flash-message';alertMessage('Hello from alert');logMessage('Hello from log'); Export and import ConstantsExtracting Hardcoded Constants Redefining constants across our application is unnecessary repetition and can lead to bugs. 123456789101112131415161718192021222324252627282930// load-profiles.jsfunction loadProfiles(userNames)&#123; const MAX_USERS = 3; if(userNames.length &gt; MAX_USERS)&#123; //... &#125; const MAX_REPLIES = 3; if(someElement &gt; MAX_REPLIES)&#123; //... &#125;&#125;export &#123; loadProfiles &#125;// list-replies.jsfunction listReplies(replies=[])&#123; const MAX_REPLIES = 3; if(replies.length &gt; MAX_REPLIES)&#123; //... &#125;&#125;export &#123; listReplies &#125;// display-watchers.jsfunction displayWatchers(watchers=[])&#123; const MAX_USERS = 3; if(watchers.length &gt; MAX_USERS)&#123; //... &#125;&#125;export &#123; displayWatchers &#125; Export Constants Placing constants on their own module allows them to be reused across other modules and hides implementation details (a.k.a., encapsulation). 1234// constants.jsconst MAX_USERS = 3;const MAX_REPLIES = 3;export &#123; MAX_USERS, MAX_REPLIES &#125;; Import Constants To import constants, we can use the exact same syntax for importing functions. We can now import and use our constants from other places in our application. 1234567891011121314151617181920212223242526// load-profiles.jsimport &#123; MAX_REPLIES, MAX_USERS &#125; from './constants';function loadProfiles(userNames)&#123; if(userNames.length &gt; MAX_USERS)&#123; //... &#125; if(someElement &gt; MAX_REPLIES)&#123; //... &#125;&#125;// list-replies.jsimport &#123; MAX_REPLIES &#125; from './constants';function listReplies(replies = [])&#123; if(replies.length &gt; MAX_REPLIES)&#123; //... &#125;&#125;// display-watchers.jsimport &#123; MAX_USERS &#125; from './constants';function displayWatchers(watchers = [])&#123; if(watchers.length &gt; MAX_USERS)&#123; //... &#125;&#125; Class Modules Exporting Class Modules With Default Export Using Class Modules With Named Export 12345678910111213141516171819// flash-message.jsclass FlashMessage &#123; constructor(message)&#123; this.message = message; &#125; renderAlert()&#123; alert(`$&#123;this.message&#125; from alert`); &#125; renderLog()&#123; console.log(`$&#123;this.message&#125; from log`); &#125;&#125;export &#123; FlashMessage &#125;// app.jsimport &#123; FlashMessage &#125; from './flash-message';let flash = new FlashMessage("Hello");flash.renderAlert();flash.renderLog(); Promises, Iterators, and GeneratorsPromisesFetching Poll Results From the Server It’s very important to understand how to work with JavaScript’s single-thread model. Otherwise, we might accidentally freeze the entire app, to the detriment of user experience. Avoiding Code That Blocks Once the browser blocks executing a script, it stops running other scripts, rendering elements, and responding to user events like keyboard and mouse interactions. 1234// Synchronous style functions wait for return values// Page freezes until a value is returned from this functionlet results = getPollResultsFromServer("Sass vs. LESS");ui.renderSidebar(results); In order to avoid blocking the main thread of execution, we write non-blocking code like this: 1234// Asynchronous style functions pass callbacksgetPollResultsFromServer("Sass vs. Less", function(results)&#123; ui.renderSidebar(results);&#125;); Passing Callbacks to Continue Execution In continuation-passing style (CPS) async programming, we tell a function how to continue execution by passing callbacks. It can grow to complicated nested code. 1234567891011121314151617// When nested callbacks start to grow, our code becomes harder to understandgetPollResultsFromServer(pollName, function(error, results)&#123; if(error)&#123; //.. handle error &#125; //... ui.renderSidebar(results, function(error)&#123; if(error)&#123; //.. handle error &#125; //... sendNotificationToServer(pollName, results, function(error, response)&#123; if(error)&#123; //.. handle error &#125; //... doSomethingElseNonBlocking(response, function(error)&#123; if(error)&#123; //.. handle error &#125; //... &#125;) &#125;); &#125;);&#125;); Using Promises A Promise is a new abstraction that allows us to write async code in an easier way. 12345678// Still non-blocking, but not using nested callbacks anymoregetPollResultsFromServer("Sass vs. LESS") .then(ui.renderSidebar) .then(sendNotificationToServer) .then(doSomethingElseNonBlocking) .catch(function(error)&#123; console.log("Error: ", error); &#125;); The Lifecycle of a Promise Object Creating a new Promise automatically sets it to the pending state. Then, it can do 1 of 2 things: become fulfilled or rejected. Creating a New Promise Object The Promise constructor function takes an anonymous function with 2 callback arguments known as handlers. 1234567891011function getPollResultsFromServer(pollName)&#123; // Handlers are responsible for either resolving or rejecting the Promise return new Promise( function(resolve, reject) &#123; //... // Called when the non-blocking code is done executing resolve(someValue); //... // Called when an error occurs reject(someValue); &#125;);&#125;; Resolving a Promise Let’s wrap the XMLHttpRequest object API within a Promise. Calling the resolve() handler moves the Promise to a fulfilled state. 12345678910111213141516function getPollResultsFromServer(pollName)&#123; return new Promise(function(resolve, reject)&#123; let url = `/results/$&#123;pollName&#125;`; let request = new XMLHttpRequest(); request.open('GET', url, true); request.onload = function() &#123; if (request.status &gt;= 200 &amp;&amp; request.status &lt; 400) &#123; // We call the resolve() handler upon a successful response // Resolving a Promise moves it to a fulfilled state resolve(JSON.parse(request.response)); &#125; &#125;; //... request.send(); &#125;);&#125;; Reading Results From a Promise We can use the then() method to read results from the Promise once it’s resolved. This method takes a function that will only be invoked once the Promise is resolved. 1234getPollResultsFromServer("Sass vs. Less") .then(function(results)&#123; ui.renderSidebar(results); &#125;); Chaining Multiple Thens We can also chain multiple calls to then() ? the return value from 1 call is passed as argument to the next. 12345678910getPollResultsFromServer("Sass vs. Less") .then(function(results)&#123; // Only returns poll results from Orlando return results.filter((result) =&gt; result.city === "Orlando"); &#125;) // The return value from one call to then // becomes the argument to the following call to then. .then(function(resultsFromOrlando)&#123; ui.renderSidebar(resultsFromOrlando); &#125;); Rejecting a Promise 12345678910111213141516function getPollResultsFromServer(pollName)&#123; return new Promise(function(resolve, reject)&#123; //... request.onload = function() &#123; if (request.status &gt;= 200 &amp;&amp; request.status &lt; 400) &#123; resolve(request.response); &#125; else &#123; // We call the reject() handler,passing it a new Error object // Rejecting a Promise moves it to a rejected state reject(new Error(request.status)); &#125; &#125;; request.onerror = function() &#123; reject(new Error("Error Fetching Results")); &#125;; //... Catching Rejected Promises Once an error occurs, execution moves immediately to the catch() function. None of the remaining then() functions are invoked. 12345678910111213// When an error occurs heregetPollResultsFromServer("Sass vs. Less") // then none of these run .then(function(results)&#123; return results.filter((result) =&gt; result.city === "Orlando"); &#125;) .then(function(resultsFromOrlando)&#123; ui.renderSidebar(resultsFromOrlando); &#125;) // and execution moves straight here. .catch(function(error)&#123; console.log("Error: ", error); &#125;); Passing Functions as Arguments We can make our code more succinct by passing function arguments to then, instead of using anonymous functions. 12345678910111213function filterResults(results)&#123; //... &#125;let ui = &#123; renderSidebar(filteredResults)&#123; //... &#125;&#125;; getPollResultsFromServer("Sass vs. Less") // Passing function arguments make this code easier to read .then(filterResults) .then(ui.renderSidebar) // Still catches all errors from previous calls .catch(function(error)&#123; console.log("Error: ", error); &#125;); Iterators Iterables Return Iterators Iterables return an iterator object. This object knows how to access items from a collection 1 at a time, while keeping track of its current position within the sequence. Understanding the next Method Each time next() is called, it returns an object with 2 specific properties: done and value. Here’s how values from these 2 properties work: done (boolean) Will be false if the iterator is able to return a value from the collection Will be true if the iterator is past the end of the collection value (any) Any value returned by the iterator. When done is true, this returns undefined. Custom Iterator 123456789101112131415161718let post = &#123; &#125;; //...post[Symbol.iterator] = function()&#123; // Returns an array with property names let properties = Object.keys(this); let count = 0; let isDone = false; let next = () =&gt; &#123; // Ends the loop after reaching the last property if(count &gt;= properties.length)&#123; isDone = true; &#125; // Fetches the value for the next property // ++ only increments count after it's read return &#123; done: isDone, value: this[properties[count++]] &#125;; &#125; return &#123; next &#125;;&#125;; GeneratorGenerator Functions The function * declaration defines generator functions. These are special functions from which we can use the yield keyword to return iterator objects. 1234function *nameList()&#123; yield "Sam"; yield "Tyler";&#125;. Doesn’t matter where we place the star, as long as it’s the first thing after the function keyword function *nameList(){ function* nameList(){ function * nameList(){ Generator Objects and for…of Generator functions return objects that provide the same next method expected by for…of, the spread operator, and the destructuring assignment. 12345678910111213141516function *nameList()&#123; yield "Sam"; yield "Tyler";&#125;for(let name of nameList())&#123; console.log( name );&#125;// Sam// Tylerlet names = [...nameList()];console.log( names ); // ["Sam", "Tyler"]let [first, second] = nameList();console.log( first, second ); // Sam Tyler Replacing Manual Iterator Objects 12345678910111213let post = &#123; title: "New Features in JS", replies: 19 &#125;;post[Symbol.iterator] = function *()&#123; let properties = Object.keys(this); for(let p of properties)&#123; yield this[p]; &#125;&#125;for(let p of post)&#123; console.log( p );&#125;// New Features in JS// 19]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Notes for Code School - JavaScript Road Trip]]></title>
      <url>%2F2016%2F04%2F09%2FCodeSchool-Javascript%2F</url>
      <content type="text"><![CDATA[ClosuresClosures help in function “construction zones” A closure can make the creation of very similar functions ultra-efficient. 12345678910function buildCoveTicketMaker( transport ) &#123; return function ( name ) &#123; alert("Here is your transportation ticket via the " + transport + ".\n" + "Welcome to the Cold Closures Cove, " + name + "!"); &#125;&#125;var getSubmarineTicket = buildCoveTicketMaker("Submarine");var getBattleshipTicket = buildCoveTicketMaker("Battleship");var getGiantSeagullTicket = buildCoveTicketMaker("Giant Seagull"); Closure functions can even modify bound variables in the background 123456789101112131415function buildCoveTicketMaker( transport ) &#123; return function ( name ) &#123; alert("Here is your transportation ticket via the " + transport + ".\n" + "Welcome to the Cold Closures Cove, " + name + "!" + "You are passenger #" + passengerNumber + "." ); &#125;&#125;var getSubmarineTicket = buildCoveTicketMaker("Submarine");// passengerNumber is incremented to 1.getSubmarineTicket("Mario"); // Another call to getSubmarineTicket has passengerNumber incremented to 2! // Wow, even though the function's local scope disappeared after Mario's ticket, // it KEPT the progress of passengerNumber!getSubmarineTicket("Toad"); LOOPS WITH CLOSURES: a cautionary tale We have to pay close attention to return times and final variable states. Way before torpedoAssignment isreturned, the i loop counter hasprogressed in value to 8 andstopped the loop. The function’s actual return is the true “moment of closure”, when the environment andall necessary variables are packaged up. 123456789101112131415161718function assignTorpedo ( name, passengerArray )&#123; var torpedoAssignment; for (var i = 0; i&lt;passengerArray.length; i++) &#123; if (passengerArray[i] == name) &#123; torpedoAssignment = function () &#123; alert("Ahoy, " + name + "!\n" + "Man your post at Torpedo #" + (i+1) + "!"); &#125;; &#125; &#125; return torpedoAssignment;&#125;var subPassengers = ["Luke", "Leia", "Han", "Chewie", "Yoda", "R2-D2", "C-3PO", "Boba"];var giveAssignment = assignTorpedo("Chewie", subPassengers);giveAssignment(); // Outputs:// Ahoy, Chewie!// Man your post at Torpedo #9! Several options exist for timing closures correctly 1234567891011function assignTorpedo ( name, passengerArray )&#123; for (var i = 0; i&lt;passengerArray.length; i++) &#123; if (passengerArray[i] == name) &#123; // Now the function will be immediately returned when the right name is found, locking i in place. return function () &#123; alert("Ahoy, " + name + "!\n" + "Man your post at Torpedo #" + (i+1) + "!"); &#125;; &#125; &#125;&#125; 12345678910function makeTorpedoAssigner ( passengerArray ) &#123; return function ( name ) &#123; for (var i = 0; i&lt;passengerArray.length; i++) &#123; if (passengerArray[i] == name) &#123; alert("Ahoy, " + name + "!\n" + "Man your post at Torpedo #" + (i+1) + "!"); &#125; &#125; &#125;;&#125; Hoisting Ensuring that every line of code can execute when it’s needed First, memory is set aside for all necessary variables and declared functions. Then the operations in order. Some examples of the impact of hoisting Function Expressions are never hoisted! They are treated as assignments. Example Solution Exchange the order Don’t use function expression Prototype The Object’s parent is called its “prototype” When a generic Object is created, its prototype passes it many important properties Passing down properties is called “inheritance” Inheritance helps avoid over-coding multiple properties and methods into similar objects. Object Prototype valueOf() constructor() toLocaleString() toString() isPrototypeOf() propertyIsEnumerable() hasOwnProperty() Array Prototype length pop() push() shift() reverse() sort() join() reduce() slice() String Prototype length charAt() trim() concat() indexOf() replace() toLowerCase() toUpperCase() substring() Number Prototype toFixed() toExponential() toPrecision() Function Prototype name call() bind() apply() Though properties are inherited, they are still “owned” by prototypes, not the inheriting Object Inheritance and ConstructorsAdding inheritable Properties to prototypes 123456789String.prototype.countAll = function ()&#123; var letterCount = 0; for (var i = 0; i&lt;this.length; i++) &#123; if ( this.charAt(i).toUpperCase() == letter.toUpperCase() ) &#123; letterCount++; &#125; &#125; return letterCount;&#125;; Build objects using Object.create() Using inheritance, we can create new Objects with our existing Objects as prototypes 12var shoe = &#123; size: 6, gender: "women", construction: "slipper"&#125;;var magicShoe = Object.create(shoe); Examining the inheritance 123Object.prototype .isPrototypeOf(shoe); // trueshoe.isPrototypeOf(magicShoe); //trueObject.prototype .isPrototypeOf(magicShoe); //true Build a prototype with empty properties Determine common properties of a class A class is a set of Objects that all share and inherit from the same basic prototype. Building a constructor function for an Object A constructor allows us to set up inheritance while also assigning specific property values. 12345678function Shoe (shoeSize, shoeColor, forGender, constructStyle) &#123; this.size = shoeSize; this.color = shoeColor; this.gender = forGender; this.construction = constructStyle; this.putOn = function () &#123; alert("Shoe's on!"); &#125;; this.takeOff = function () &#123; alert("Uh, what's that smell?"); &#125;;&#125; Use constructor JavaScript’s ?new’ keyword produces a new Object of the class, or “instantiates” the class 1var beachShoe = new Shoe( 10, "blue", "women", "flipflop" ); Assigning a prototype to a constructor By setting a constructor’s prototype property, every new instance will refer to it for extra properties! 123456789101112function Shoe (shoeSize, shoeColor, forGender, constructStyle) &#123; this.size = shoeSize; this.color = shoeColor; this.gender = forGender; this.construction = constructStyle;&#125;Shoe.prototype = &#123; putOn: function () &#123; alert("Shoe's on!"); &#125;; takeOff: function () &#123; alert("Uh, what's that smell?"); &#125;;beachShoe.hasOwnProperty("construction"); // true Prototypes can also refer back to the instance 1234567891011function Shoe (shoeSize, shoeColor, forGender, constructStyle) &#123; this.size = shoeSize; this.color = shoeColor; this.gender = forGender; this.construction = constructStyle;&#125;Shoe.prototype = &#123; putOn: function () &#123; alert ("Your " + this.construction + "'s" + "on!"); &#125;, takeOff: function () &#123; alert ("Phew! Somebody's size " + this.size + "'s" + " are fragrant! "); &#125;&#125;; Overriding Prototypal MethodsvalueOf()12345678var x = 4;var y = "4";x.valueOf(); // 4y.valueOf(); // "4"x.valueOf() == y.valueOf(); // truex.valueOf() === y.valueOf(); // false The “value “in valueOf() isn’t looking for numbers necessarily, but instead returns whatever primitive type is associated with the object Be careful! The == tries to help us out by using “typecoercion”, which turns a number contained within a stringinto an actual number. Here, the &quot;4&quot; we got back from y.valueOf() became 4 when the == examined it. The === operator does NOT ignore the type of thevalue, and gives us a more detailed interpretation ofequality. JavaScript experts often prefer this comparator exclusively over == for this reason. valueOf( ) on custom objects The valueOf() function for custom Objects just defaults to a list of their properties, just like logging them out. 1234567891011var Tornado = function (category, affectedAreas, windGust) &#123; this.category = category; this.affectedAreas = affectedAreas; this.windGust = windGust;&#125;;var cities = [ ["Kansas City", 464310], ["Topeka", 127939], ["Lenexa", 49398] ]; var twister = new Tornado( "F5", cities, 220 );twister.valueOf();// Tornado &#123;category: "F5", affectedAreas: Array[3], windGust: 220&#125; Overriding prototypal properties Many situations require special functionality that’s different from the first available property 123456789Tornado.prototype.valueOf = function( ) &#123; var sum = 0; for (var i = 0; i &lt; this.affectedAreas.length; i++) &#123; sum += this.affectedAreas[i][1]; &#125; return sum;&#125;;twister.valueOf(); // 641647 Each Tornado’s ‘affectedAreas’ property can be updated outside the object with no loss of accuracy. toString( )1234567891011121314var x = 4;var y = "4";var a = [ 3, "blind", "mice" ];var double = function ( param )&#123; return param *2;&#125;;x.toString(); // "4"y.toString(); // "4"a.toString(); // "3,blind,mice"double.toString(); // "function ( param )&#123;// return param *2;// &#125;" A call to toString on an Array will just string-ify and concatenate all the contents, separating each entry by a comma withoutany whitespace. Overriding toString in the Array prototype is often desirable. Finding constructor and prototypeSome inherited properties provide ways to find an Object’s nearest prototype ancestor 12345678910111213141516var cities = [ ["Kansas City", 464310], ["Topeka", 127939], ["Lenexa", 49398] ]; var twister = new Tornado( "F5", cities, 220 );cities.push( ["Olathe", 130045] );twister.constructor;// function (category, affectedAreas, windGust) &#123;// this.category = category;// this.affectedAreas = affectedAreas;// this.windGust = windGust;//&#125;twister.constructor.prototype;// Object &#123;valueOf: function, toString: function&#125;twister.__proto__;// Object &#123;valueOf: function, toString: function&#125; HasOwnProperty()Searching prototype chains for potential overridden properties becomes easy with this function 123456789101112Object.prototype.findOwnerOfProperty = function ( propName ) &#123; var currentObject = this; while (currentObject !== null)&#123; if (currentObject.hasOwnProperty(propName)) &#123; return currentObject; &#125; else &#123; currentObject = currentObject.__proto__; &#125; &#125; return "No property found!";&#125;;]]></content>
    </entry>

    
  
  
</search>
